{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86402f7b",
   "metadata": {},
   "source": [
    "# **SHAKESPEARE GPT** (3.22M Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1345f",
   "metadata": {},
   "source": [
    "## Read data, Character Integer conversion, Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1699f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1475b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset in characters:  1115393\n"
     ]
    }
   ],
   "source": [
    "print('Length of Dataset in characters: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31bcc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0f9ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63addca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# Tokeniser character-by-character.\n",
    "\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode('hii there'))\n",
    "print(decode(encode('hii there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b77e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ffbe2",
   "metadata": {},
   "source": [
    "## Train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4894dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4bfaa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd315240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":when input is tensor([18]) the target: 47\n",
      ":when input is tensor([18, 47]) the target: 56\n",
      ":when input is tensor([18, 47, 56]) the target: 57\n",
      ":when input is tensor([18, 47, 56, 57]) the target: 58\n",
      ":when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      ":when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      ":when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      ":when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f':when input is {context} the target: {target}')\n",
    "\n",
    "# We use this block size not only for efficient computational\n",
    "# training but also for inference after training. \n",
    "# The transformer need to see a small piece of text\n",
    "# all the way to block size and also in between.\n",
    "# This will be helpful when inferencing because when we're\n",
    "# sampling we can we can start the sampling generation\n",
    "# with as little as one character of context and the transformer\n",
    "# knows how to predict the next character with all the way up\n",
    "# to just context of one ans so then it can predict \n",
    "# everything up to block size\n",
    "\n",
    "# Note that if u train tranformer like this then the input also should \n",
    "# be fed maximum of block size then truncate it and send, if it is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b822597",
   "metadata": {},
   "source": [
    "## Get Batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5802d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "----\n",
      "When input is [53] the target: 59\n",
      "When input is [53, 59] the target: 6\n",
      "When input is [53, 59, 6] the target: 1\n",
      "When input is [53, 59, 6, 1] the target: 58\n",
      "When input is [53, 59, 6, 1, 58] the target: 56\n",
      "When input is [53, 59, 6, 1, 58, 56] the target: 47\n",
      "When input is [53, 59, 6, 1, 58, 56, 47] the target: 40\n",
      "When input is [53, 59, 6, 1, 58, 56, 47, 40] the target: 59\n",
      "When input is [49] the target: 43\n",
      "When input is [49, 43] the target: 43\n",
      "When input is [49, 43, 43] the target: 54\n",
      "When input is [49, 43, 43, 54] the target: 1\n",
      "When input is [49, 43, 43, 54, 1] the target: 47\n",
      "When input is [49, 43, 43, 54, 1, 47] the target: 58\n",
      "When input is [49, 43, 43, 54, 1, 47, 58] the target: 1\n",
      "When input is [49, 43, 43, 54, 1, 47, 58, 1] the target: 58\n",
      "When input is [13] the target: 52\n",
      "When input is [13, 52] the target: 45\n",
      "When input is [13, 52, 45] the target: 43\n",
      "When input is [13, 52, 45, 43] the target: 50\n",
      "When input is [13, 52, 45, 43, 50] the target: 53\n",
      "When input is [13, 52, 45, 43, 50, 53] the target: 8\n",
      "When input is [13, 52, 45, 43, 50, 53, 8] the target: 0\n",
      "When input is [13, 52, 45, 43, 50, 53, 8, 0] the target: 26\n",
      "When input is [1] the target: 39\n",
      "When input is [1, 39] the target: 1\n",
      "When input is [1, 39, 1] the target: 46\n",
      "When input is [1, 39, 1, 46] the target: 53\n",
      "When input is [1, 39, 1, 46, 53] the target: 59\n",
      "When input is [1, 39, 1, 46, 53, 59] the target: 57\n",
      "When input is [1, 39, 1, 46, 53, 59, 57] the target: 43\n",
      "When input is [1, 39, 1, 46, 53, 59, 57, 43] the target: 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum input size that can be fed for a single inference?\n",
    "\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs: ')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets: ')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'When input is {context.tolist()} the target: {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3ef97",
   "metadata": {},
   "source": [
    "## Simple Bigram model using classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7e81ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Loss: 4.174387269895637 \n",
      "Actual Loss: 4.894842624664307\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C) (B --> Batch, T --> Time, C --> Channel) ---> (4, 8, 65)\n",
    "        # Here to do the cross_entropy we need to convert logits from (B, T, C) --> (B, C, T)\n",
    "        # So we're using view() to change the dimension to the suitable one.\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "            \n",
    "        else:\n",
    "            B, T, C = logits.shape # ---> (4, 8, 65)\n",
    "            logits = logits.view(B*T, C) # Now it will be like 1 input for each row. That is (32, 65).\n",
    "            targets = targets.view(B*T)  # Here target for each row of input. That is (32).\n",
    "                                        # B*T can also be mentioned -1. pytorch will guess what will it be.\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets) # But the input is expected to be (B, C, T). So we do the above.\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        # So this context will be generated across all the batch dimension in the time dimension. \n",
    "        # Basically the first generation is (B,T+1), second is (B,T+2) till max_new tokens times.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx) # --> This calls forward(). Since here we cant provide with the targets so making the targets in forward as None by default.\n",
    "                                     # So now it will call forward because forward need only one character.\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size) # ---> This is the Model.\n",
    "logits, loss = m(xb, yb)\n",
    "print(f'Expected Loss: {-math.log(1/65)}', f'\\nActual Loss: {loss.item()}')\n",
    "#  This line we use for comparsion.\n",
    "# -math.log(1/65)} means the loss of the model, if there are 65 possible tokens the model could predict at each step.\n",
    "#  This means that the model is currently predicting all 65 tokens as the next character.\n",
    "#  But the model should have highest probability for a single character that is most likely to occur next.\n",
    "#  It shouldn't Predict the not likely characters. Means the one with less probabiltiy\n",
    "#  Because if the model gives every token probability 1/65, the chance of the correct token being picked is 1/65, and the cross-entropy loss measures the negative log of the predicted probability for the true target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a583127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(xb)\n",
    "print(xb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1306d",
   "metadata": {},
   "source": [
    "##### Sampling from start of the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef3ad37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long) # ---> 0 is a new line character. So its good to start with. Its like we are starting to generate a new line of texts.\n",
    "print(idx)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist())) # ---> Since it work with batches we need to index to [0].\n",
    "# This generate function now takes batches of sequence of inputs but still uses the last character to find the next character for all the batches. So its just a bigram model.\n",
    "# This doesnt use any history of previous generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a7a18",
   "metadata": {},
   "source": [
    "##### Sampling with some starting sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206dc2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Message: tensor([[20, 47,  1, 58, 46, 43, 56, 43,  2],\n",
      "        [35, 46, 39, 58,  5, 57,  1, 59, 54]])\n",
      "\n",
      "\n",
      "Generated Content: tensor([[20, 47,  1, 58, 46, 43, 56, 43,  2,  2, 42, 41, 40, 44],\n",
      "        [35, 46, 39, 58,  5, 57,  1, 59, 54, 32,  0, 31, 28, 43]])\n",
      "\n",
      "\n",
      "Generated Message: ['Hi there!!dcbf', \"What's upT\\nSPe\"]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_message = torch.tensor([encode(\"Hi there!\"), encode(\"What's up\")], dtype=torch.long)\n",
    "print(f\"Input Message: {input_message}\\n\\n\")\n",
    "\n",
    "\n",
    "generate_content = m.generate(input_message, 5)\n",
    "print(f\"Generated Content: {generate_content}\\n\\n\")\n",
    "\n",
    "output_message = []\n",
    "\n",
    "for x in range(len(generate_content)):\n",
    "     output_message.append(decode(generate_content[x].tolist()))\n",
    "\n",
    "print(f\"Generated Message: {output_message}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d651507",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290cc37",
   "metadata": {},
   "source": [
    "##### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c34615b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # A good learning rate is 3e-4, But since the network is small we're using higher learning rate.\n",
    "                                                       # This will take the gradients and update the parameters using the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecfa5f",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19e1b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3944149017333984\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000): # gave 100, 1000, 10000.\n",
    "\n",
    "    # Sample a batch of data.\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # Evaluate the loss.\n",
    "    logits, loss = m(xb, yb) # Evaluate the logits and the loss.\n",
    "    optimizer.zero_grad(set_to_none=True) # Zero (That is None) the gradients for all the parameters.\n",
    "    loss.backward() # Backward pass ---> Getting the gradients for all the parameters.\n",
    "    optimizer.step() # Updating the gradient using the gradient of parameters & learning rate given in the optimizer.\n",
    "\n",
    "# Print then loss.\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81832b7d",
   "metadata": {},
   "source": [
    "##### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e72b684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "KICOMave wap\n",
      "\n",
      "I RO:\n",
      "Banleenoalit-blt\n",
      "INRon\n",
      "\n",
      "UM: nd kngonesll;\n",
      "O: pa heore 'ga llis?-sur inidind;\n",
      "t me rthathine!\n",
      "CEShew s serer Fofow.\n",
      "Houspathe t:\n",
      "Mind fit.\n",
      "DUKINoceamy hun.\n",
      "CKI:\n",
      "Norst onre t ache bar, simed?\n",
      "And me theluse Bel arind-g'sto f w m CK:\n",
      "YCESI fatass mbre lious ave\n",
      "Wer'dor' wod y:\n",
      "\n",
      "Henkns ges wise we me y to elil'doug p in t her spalisusin t wndalu?Y ber lishms vekeang-lumod n odas ine a! thayayor hannd t; frat.\n",
      "OLArZAUSum,\n",
      "s I f pin hondecharvyouk p IVIImere we keicet gs llly ide\n"
     ]
    }
   ],
   "source": [
    "# idx = torch.zeros((1,1), dtype=torch.long) # ---> 0 is a new line character. So its good to start with. Its like we are starting to generate a new line of texts.\n",
    "# print(idx)\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist())) # We dont wanna use idx better directly written inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e841907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're starting to get something at least like reasonable, But certainly not Shakespeare. \n",
    "# Here we can obviously see the improvements in the model.\n",
    "# Obviously this is a very simple model.\n",
    "# Because the tokens are not talking to each other so given the previous context of whatever was generated we're only looking at the very last character to make the predictions about what comes next.\n",
    "# So now these these tokens have to start talking to each other and figuring out what is in the context so that they can make better predictions for what comes next\n",
    "# And this is how we're going to kick off the Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564f0f6",
   "metadata": {},
   "source": [
    "## Bigram (Simplified as one single file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c667462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.7119, val loss 4.7092\n",
      "step 300: train loss 4.3749, val loss 4.3716\n",
      "step 600: train loss 4.0778, val loss 4.0803\n",
      "step 900: train loss 3.8206, val loss 3.8178\n",
      "step 1200: train loss 3.5928, val loss 3.5936\n",
      "step 1500: train loss 3.4088, val loss 3.4153\n",
      "step 1800: train loss 3.2422, val loss 3.2443\n",
      "step 2100: train loss 3.1040, val loss 3.1130\n",
      "step 2400: train loss 2.9904, val loss 2.9984\n",
      "step 2700: train loss 2.8979, val loss 2.9125\n",
      "\n",
      "\n",
      "IUbb3inenl:\n",
      "\n",
      "Yrin'X-&:\n",
      "Wilere .kBZfoTury,\n",
      "ARIVKVin,UXTXQd d pJGHG:RKHpFamesofroy PTUNEY: ZefoRt t;FYk iE:QLOb-3How;Al a oyTalen$Cd,\n",
      "3A\n",
      "Od hay:\n",
      "Were h wPL-H3men eMPwowMbamthe oug'd'd ca wer aythonchRd ceFl:vect?: avicr\n",
      "&t-3ataielD.!k hemyWiIN ICav&k wint,\n",
      "As ll,jUadXJGiJ'y:\n",
      "gDi&wviordot:\n",
      "Xmo kf fterlobs.\n",
      "\n",
      "GEX.\n",
      "SO:U.\n",
      "VFPAnailp,c-lSCHes asun i!'ss&pT.\n",
      "GEBZV!\n",
      "WINoRJo? al:\n",
      "Ju.jejHMfoz? sTWmepunet wal ABXColyTw;us  s rcuhQjun:\n",
      "XCd;3y ioE lpshy:z,jQNAht lVla;L agonUSGBy dura kha$p m yd pive;! Zy d TRI\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 3000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652342b",
   "metadata": {},
   "source": [
    "## The mathematical trick used in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "114efa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider the following toy example.\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channel\n",
    "x = torch.rand(B, T, C)\n",
    "x.shape\n",
    "\n",
    "# We want the time dimension to talk with each other. \n",
    "# The token in the 5th location should not communicate with the token in the 6th or after the 5th location. It should only talk with the token before 5th location.\n",
    "# This means that the information will only flow from the previous context to the current time step.\n",
    "# We cant get any information from the future because we are about to try to predict the future.\n",
    "# The easiest way for the token to communicate is to average of all the preceeding elements.\n",
    "# For example:\n",
    "#   If we take the 5th token, then we would like to take the channels that make up the information at our step but also the channels of the 4th, 3rd.... steps.\n",
    "#   We would like to average them up and that would become sort of like a feature vector that summarizes the 5th token in the context of 5th token's history (Corresponding to the context of 4th, 3rd ...).\n",
    "\n",
    "# But absolutely just doing a sum or average is extermely a weak form of interaction. This way is extremely lossy, we lost a ton of information.\n",
    "# But lets just do this and later try to get how its not to lose the data.\n",
    "\n",
    "# Now lets do the average method for communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f37b2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1: Using normal averaging.\n",
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow1 = torch.zeros((B,T,C)) # bow is bag og words (Just used for the term averaging). This contains the average of every single token information.\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t,C). Every pervious token including this current token is fetched.\n",
    "        xbow1[b,t] = torch.mean(xprev,0) # squeeshing rows and averaging them up.\n",
    "\n",
    "        # x = tensor([[0.0783, 0.4956], ---> The first row will look the same in xbow because there is not previous token. \n",
    "        #     [0.6231, 0.4224]])  ---> This row will get average with the first token. so now this row will have the information of both first and the second row.\n",
    "        \n",
    "        # xbow = tensor([[0.0783, 0.4956],\n",
    "        #        [0.3507, 0.4590]])\n",
    "\n",
    "        # You can see we average every elements by squeeshing the rows.\n",
    "# The trick instead of doing average is the matrix multiplication which is very very efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70ad75d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4021f76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# Version 2: Using matrix multiplication\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "print(a)\n",
    "a = a / a.sum(1, keepdim=True) # This way we actually get the average of the (b) matrix using (a) matrix using matrix multilpication.\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30c8e2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 3: Using Softmax\n",
    "# Again we're gonna write this everything in one more way.\n",
    "tril = torch.tril(torch.ones(T,T)) \n",
    "wei = torch.zeros((T,T)) # This will not be zeros in the real case.\n",
    "wei = wei.masked_fill(tril==0, float('-inf')) # Future cant communicate with the past.\n",
    "wei = F.softmax(wei, dim=-1) # Normalize\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow1, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14fb86e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "tril, wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fca04d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c142d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1) # Exponentitate and divide by the sum. exp(-inf) --> 0 and exp(0) --> 1\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e7fa601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channel\n",
    "x = torch.rand(B, T, C)\n",
    "\n",
    "# Manually averaging. ---> method 1\n",
    "xbow1 = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t,C). Every pervious token including this current token is fetched.\n",
    "        xbow1[b,t] = torch.mean(xprev,0) \n",
    "\n",
    "# Matrix Mutiplication averaging. ---> method 2\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "# (wei) matrix will act as (a) matrix from previous cell.\n",
    "\n",
    "# Using softamx. ---> method 3\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "\n",
    "xbow2 = wei @ x # (T,T) @ (B,T,C) --> TENSOR BROADCASTING --> (B,T,T) @ (B,T,C) --> (B,T,C)\n",
    "\n",
    "# Now xbow1 and xbow2 will become equal.\n",
    "print(torch.allclose(xbow1, xbow2))\n",
    "print(torch.allclose(xbow2, xbow3))\n",
    "\n",
    "# Now we gonna use version 3 for self attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "662727f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long story short:\n",
    "# This entire section is that you can do weighted aggregations of your past elements by using matrix multiplication of a lower triangular fashion. \n",
    "# Then the elements here in the lower triangular part are telling you how much of each element fuses into this position.\n",
    "# so we're going to use this trick now to develop the self attention block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d12cdb",
   "metadata": {},
   "source": [
    "## Bigram model (simply little modified) and how self attention code looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.4613, val loss 4.4477\n",
      "step 300: train loss 2.8872, val loss 2.9076\n",
      "step 600: train loss 2.6843, val loss 2.7065\n",
      "step 900: train loss 2.6005, val loss 2.6059\n",
      "step 1200: train loss 2.5644, val loss 2.5780\n",
      "step 1500: train loss 2.5447, val loss 2.5575\n",
      "step 1800: train loss 2.5248, val loss 2.5332\n",
      "step 2100: train loss 2.5178, val loss 2.5288\n",
      "step 2400: train loss 2.5176, val loss 2.5279\n",
      "step 2700: train loss 2.5119, val loss 2.5363\n",
      "ofy t T a\n"
     ]
    }
   ],
   "source": [
    "# Dont need to pass vocab_size to the class.\n",
    "# We gonna use some n_embd for number of embedding dimesion.\n",
    "# Now logits are not given directly so we change them to token_emb.\n",
    "# Now we gonna find the logits by using some linear layer.\n",
    "# Now we encoding the idx based on the identity of the tokens inside it. But the next thing is not just encoding the idenitity of the tokens but also the positions. So we gonna introduce positional_embedding_table.\n",
    "# Now created a values x which is the sum of tok_emb and pos_emb and passing it to find logits.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 3000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size) # Language model head.\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) ---> broadcast ---> (B, T, C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c996c184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 4: Self attention for single individual head.\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "X = torch.rand(B, T, C)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T)) \n",
    "wei = torch.zeros((T,T)) # This will not be zeros in the real case.\n",
    "wei = wei.masked_fill(tril==0, float('-inf')) # Future cant communicate with the past.\n",
    "wei = F.softmax(wei, dim=-1) # Normalize\n",
    "out = wei @ X\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb34c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4f5c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we gonna make wei data dependent. \n",
    "# Maybe its like a token is vowel and it is searching for a consonant in its past, if there is a consonant then the information needs to flow to the vowel position. \n",
    "# Now I need to gather the information from the past but I want to do it in a data dependent way.\n",
    "# This is the problem self attention solves.\n",
    "# Every single token node in every single position will emit two vectors (key and query).\n",
    "# Query is like a question. Its like what do i look for. (Is there any consonants before me)\n",
    "# Key is like the answer. Its like what do i contain. (I am a consonant)\n",
    "# The way we get affinities between this is we do dot products between keys and queries.\n",
    "# A Single token's query dot priducts's with all the other tokens key vector.\n",
    "# The dot product now become weights.\n",
    "# Id the key and the query are well aligned then they will interact to a very high amount, and will get to know more about that particular token in the sequence as supposed to any other token in the sequence.\n",
    "# Let implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ccd894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 4: Self attention for single individual head.\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "x = torch.rand(B, T, C)\n",
    "\n",
    "# Lets see a single Head perform self-attention.\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16) Now all the elements in X created a key vector. No communication in between yet.\n",
    "q = query(x) # (B, T, 16) Now all the elements in X created a query vector. No communication in between yet.\n",
    "wei = q @ k.transpose(-2, -1) # transposing last two dimensions. (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T)) \n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf')) # Future cant communicate with the past.\n",
    "wei = F.softmax(wei, dim=-1) # Normalize\n",
    "# out = wei @ x # We dont really use x, But instead we use Value Matrix.\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e168ff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4409, 0.5591, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2975, 0.3373, 0.3652, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2211, 0.2898, 0.2236, 0.2654, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1832, 0.2163, 0.1954, 0.2437, 0.1614, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1330, 0.2227, 0.1784, 0.2159, 0.1044, 0.1456, 0.0000, 0.0000],\n",
       "        [0.1283, 0.1367, 0.1385, 0.1522, 0.1083, 0.1341, 0.2021, 0.0000],\n",
       "        [0.1064, 0.1332, 0.1265, 0.1445, 0.0940, 0.1200, 0.1231, 0.1524]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0] # Now the weighted aggregation is a function in a data depended manner between the keys and queries of these nodes.\n",
    "       # Now the last number that is wei[0,-1,-1] knows what content it has and what position it is in.\n",
    "       # Now the token wei[0, -1, -1] creates a query ---> I am a vowel in 8th position lookin for any consonant at positions up to four.\n",
    "       # Then all the nodes, it emit keys.\n",
    "       # Maybe one of the channels could be, I am consonant and I am in a position upto 4.\n",
    "       # That key would have a high number in that specific channel.\n",
    "       # That is how when a query and key when dot product they can find each other and create a high affinity.\n",
    "       \n",
    "       # Say that wei[0, -1, 3] is pretty interesting to wei[0, -1, -1], \n",
    "       # when they have high affinity, then through the softmax i will end up aggregating a lot of information into my position. So I will get to learn a lot about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482a308",
   "metadata": {},
   "source": [
    "#### Notes on self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c299e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAB1CAYAAADa1ELYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAE/zSURBVHhe7Z13fBRF+8C/e3ephARDR+kISC/SBClKs6AiIqA0URARpIjSFAF5EUEBxdcfggKKoICiUpXQO0hHCb33FhLSLlfm98fubPYul4IC+up8/YxcdmZnZmenPDPzzLOa1+sVKBQKhUKhUBjY/C8oFAqFQqH4d6OEA4VCoVAoFD4o4UChUCgUCoUPSjhQKBQKhULhgxIOFAqFQqFQ+KCEA4VCoVAoFD4o4UChUCgUCoUPSjhQKBQKhULhgxIOFAqFQqFQ+KCEA4VCoVAoFD4o4UChUCgUCoUPSjhQKBQKhULhgxIOFAqFQqFQ+KCEA4VCoVAoFD4o4UChUCgUCguapvlf+tehhAOFQqFQKAw0TUMI8a8XEDSv1yv8LyoUCoVC8b/Onxnghfh3D41KOFAoFArF347MBib/4T5jOD2Epum/jhw5ypUrV3A6U/F6vXg8HiIiIggLCyMlJYXk5CQjvI3Q0FBy585NmTJlCA0N/VcLCEo4UCgUCsUtRwgvGIPuzSIHJf3fdHFA/yXMK77h9BByPHfY4EZiEoULFyIpMZGKFStSsGBBQkNDOXToEEeOHCF//vxUq1YNr9dLcnIyW7ZsQQjBli1bqFOnzr9aOLj5t6ZQKBQKhQVN03wccsD+A4KBJNCwbBUGMgoG6cgpb3x8Avny5WPJ0iXs2rWLlStXsmTJEqpWrQrA66+/zvLly1m+/Bc2bdrErFmzAMiXL581un8lauVAoVAoFH+YnOzr52QGnpN4PAJTHBCAI5N7PIAd+GbuPDQN2j/7rOknhJfixUtw+vRpDhw4QLly5Uy/U6dO0axZMzZv3kx0dHSO8v1PRfN49OJWKBQKhSI75IChaZq5vJ+YmMjSpUvZv38/Fy9cwO6wc2/ZsrRs2ZJyZfXB1+P1oGm2DDoDGHG5XG5u3LhBUJCD4JAQMFYAnE4nLreb8LAwwsNC9VUDIUDTSHWm4na5CQ4KwqZpuD0eUlLTCAsLJyw0iM6du/DuuyMpWbwEbo8Lhz2IHTu2U6tWbUqVKsXhw4d9hJJ169YxePBg1q5dS1BQ0L9aOPjjaz4KhUKh+FehD6QaNkMwOHHqFC90e4GCBQvRr98ADhw4SHh4GBfOnWPUiBHcV/4+evfpQ6rTid1mRwhvhm0AOTiPGjWKggULcW+5ctxXoQLVqtegTJkylC5ditKlSjFx4kQf7QM78N6YseTNm4/SZe6lWIkS5M2Xj3uK3sP8+fOwAc899xzRd92l6ykYWxxr164DoG7duhlWK4oVK8bw4cMJCgryuf5vRK0cKBQKhSJHeIXAbtMH2Y8++YT+fV8DAW8Pf4d+/fpxV54oM+zVK5d5oVs3Fi9eQr36DxATs4Lw0FC8Il2hEItwcPDgYS5evMDq1asYOXIkAGXL38fYsWOJiMhF6dJlKFm8GB4BaWkuwkKCuHwtjuYtWrBnx3bCIyJ48cUXafzQQ9SpXZciBfObaXi9bmw2BwBt2z7D998vYPr06XTt2tUMY7Vt8G9eMZAo4UChUCgUOULTNDwCXn65J9M/n0r+QoX55eefqValMgAujxevx0NIcPrMu0LFihyIjaVdu3Z88803EGDw9Xg8OBz64P3jTz/ydOunAfh8+gy6de1ihktxunA47ATZdQHlp0VLaN+hPU+3bs37Y8dwz933AOAFXG43wQ4H4EUzFslTU5MpU+Zezp07z/79+ylfvrwZtz/+efy3obYVFAqFQpEtclbdpXNnpn8+lVy5o9i0YSPVqlTGI8Dp9ugrC44gXB4vTrcHgHfeeQeAuXPnsnPnTp84MRQEbbb0tYSVK2IAsDmCqF6jph7GUEb0eNymYNC7bz/ad2jP9C+mM3vWV9xz9z0IBGluN2lpLjQEXq8HDQ2XKw2APXv2cu7cee6++25KlSplpmlFCPGvFwwANLfbrUpBoVAoFJmgIbfmR44cyahRowBYu3Y9DRo8gEeA1+s19/Q1DR9bA+fOnadcubIkJyfz8ss9+PTT/zNjFkLg8Xiw2+2G8CGoWb06u/fuo2KlKmzdtp3QEDsujx5vkA2uxl2nTZs2nDh5kmXLfua+smXwCvB63NjsdvMYI8Jj6hp4PV6CgoIYP348gwcPpnPnzsyYMcPMhxUlGOiolQOFQqFQZIrXGCxXrV5tCgYvvdRdFwy8uiBgM/QQIF0wkALFXdF3UaRIEQAOHjxkhpPYbBoej77KcOL4CQ4fPgxA3br1CPMTDNZt2EjZsmUpWKgQR48e4b6yZXC7vXg9Xmw2mzmwO2waLpcLt8uFBqaC4ebNmwGoV6+emb4iMEo4UCgUCkVABGC3aXi8gtcHDAQgPDyCYUOH+YbLYrLtsDsIDQ0FIDExyZzZS6EDy2x9165dJKWkAtCwYUMAgu26YDDpo09o2bwFQwYNYe6c2diBNLcHzWbDpml4vWAYZcTtFTjsdhxBQdhsdgC8Xg9r164FoFmzZnpAP9SqQTpKOFAoFApFBqx2DBYu/Im9e3cD8PTTrSlWvKhhpVD/vz+alr5y4PF6uH79OhgDtH9oTbOZyohy8A6y26lWTbdimOby0u3F7rw+oC/fzJnDwIH9wVB+tNvsRjoaNs1m2FHQ822z27FpNq5fj8PpdDJjxkyuX79O3rzRhISEkJKSTFqarouAEgwyoIQDhUKhUGTAerRv/lz9lAFApy6dAHB53IZwkC4MWIUCOdaePHmSy5cvA5A/fwHshr9X6IaMNMO5XWls2rQBgHvLlKZSxfs4dPgo5crey5czpwNw/vwZADxer25rQQOblm6lWQgvCF2wsdvspKQ4ad36aWrXrs17743hnnvuITIykpYtW1Kv3gOsW6fbPFBkRHO5XEpcUigUCkUGNE0j7uplKlaqyKXL18ibLy9Hjh4hd67cpHnchhKibhQpEHYNPvtsKq++2guAXq/25uOPJpGa5sZu17DbbOgHFTQOHz5I9WpVSXW6GdjvNWrXa8CrvXvTokULYpb/zMVLlylftgw7d+0iOCQMr0eg2XQBQYj0LQXNli6geD2Cy1cuARAWFkZwcDAej4fk5GRcLhd58+YlJCRErRoEQK0cKBQKhSIDctXg1OkzXLsaB0DNGjXJnSs3AoHd2Mu3igXWVQN5OnH9Bn01AODxx1vp4cyjiwKP2w3Ab3v3kurUf8/55huGDh7Mt3O+YebMGTRq1AiAA4eOsCJmuRGHEYVcubBZVxCMPNg1ChYsSMGCBYmMjCQ0NJRcuXKRP39+ihQpogSDLFDCgUKhUCgyIAfNC+cv4Da0CCtUqACA16tbOdQsQoRNzuCNsVYDklOcrFyxEoDSZcrSqEljABx2Oxg6AnZD32DDho36jUCxYsVZu24djZroQsErvfSVB4ApU/SjkPp2hHnZ2E5IF1AwhQQ1+P8RlHCgUCgUikxxGccMAfLmzWv+9nqErvonBAjwenWBwHKqka++/JLLly8C8FL37oQ47LgFuL0g0KTGAl6vhzXrdGXEKpUqsn7DRgoWLoQzzY0AHnywIY0bNQBg6c8r2L5tS3oi6FsK1lUDXUlSOl1AyMwpAqOEA4VCoVBkSsGChfwvoQF2uw27TTMc2G3gdrkRXt340dWrcXz80UcAVK5cjZ4vv5x+v9x+MP4+ePAQv//+OwANHnwQzW7XP89st+EylAl6vNxD3s6MGTPN31i2GKTegeLPo6WlpSnRSaFQKP7laJqWYSataRqXL1+hbNmyJCbeoE+f3kyYMBHjoAHx1xP5YcH3hIaF8nSbNgQHO/Aa+gYD+g9g8ieTyRWWixUrV3J/rZp4DcHCazhNgEOD776bT4cOzwEwZ87XtG3bjlS3G2y6ABKEhtuVSrWqVTh4+Dh5oiLZu3c/hYsUxOsBm90iGGhYxA7FH+UvWTmQe1SK/13k8SO9Q1Hi+p1ECK9Z9gpf5EKyHHzSF5YVmSEsfbJ1MV6WW/78+Wjb9lkA1q7Rj/5pGuzff5AHHniA7777nqlTp9GxY0cwdA++/34Bkz+ZDMCUz6Zwf62apKSmyR0IXVfBorS4aaNuudBu06hevTpY0hdoON0uHEGhdOzYGYDr8QnM+upL3d8QaNIVEm/fG7f2e/90/hLhAEshS7OZiv8N5MAEsH79es6ePWtaIMsOa8Pyd4qcoWkaNpudX3/9lePHj6uyC4BXk07Da8yG73R9yyqtO52XzBDCi1cIbJrGuQsXWbd+IwI9T7o+gP4FRoDX+vZD0xzs3beXr7+eA0DPni/z6GOPsnjpQlatXsHxE8dZ8OOP/PjTQtq3bwfA3Lnzad+hPQJwBDlwezy43PpkwqGlD0Dr1q8H4P5atSlTpiwAdpsd4dWVHz1CD/lq79cokDcagOlfTAMEdodehl7hxSu8t0000DSNhIQE0zaC9g+fGN1x4UA2hsWLF3Ps2DHTMpZC5+/ScWSGFATeffdd2rRpg9s4hpRVI/F/lmvXrnHy5EnOnj2L0+kMGOZWYJ1hZ+dk/rO752bILq6s4vQP4x/2119/pUqVKuzduzfTOP6NWFcOPELgAOw2GykpSZw6dZLr1/Ujedpt7Ng1TVewc7lc+lcB/d6hEAK3243T6fQxNHSn8XoFdpuNk6fPULt2bX786SfTQJFE08DlhUoVyzNjpj5Tf+GFLkyY+BEXLl5k3PixZtj6DRrQqWMn2j7ThpIlS7Nt23aefvopPR6jXOw2OzYNnM409v72G1u2bmX48HfYs0e3vhgfn8DK1avZuWcPLlcadrvNvO/kqTPExKwgNVU3r3z0xAk6dezIli2buHrtiqHHcHvXioKCHLz4Yje6d+8Olv4wEP7vPZDzr4PZ9Rn+4W8nd1znQNM09u3bR40aNWjbti1z5uhSqP9eVyA0oxHd6rB3ipzkSdM009Ronjx5IJvwdxKZ/8mTJzNgwAAWL15MixYtMs2f/ilWvfGcPn2a6dOns2DBApKTk/B6BXFxcYSGhvLEE08wbNgwihYtatwXOL6bRdM04uPjmThxAsnJKRQuXJhcuXIhhCA+Pp64uGvY7Q4GDRpE7ty5zY762rVrTPlsCsFBwYSHh6NpGufPnyciIoIBAwbgcDiyzaMsq+XLl7No0SLuvvtuoqP1GU9ycjLnz58nb9689O/fn6CgoPSlUWPwmDx5MleuXOHuu+9G0zQuXryI0+mkT58+FCxYEIA2bdqwcOFCTp06ReHChbPN078BLyA0DbfwYtdsBAFTP5/CuLFjsdnsJCYm8vzznRg//gP/W29J+cn3d+XKFbxeLwUKFDCvAXg8HhwOB263m2vXrhEaGkpERC5sNvstST+nyLaZ6nRSqlQZSpQsyaYN+oxYrhZgCAduj24HMcSusWL1Wvr07s2RQwcAeLZ9e0qVKsXu3XtY/vMvaJrGxIkTeeWVdOXDhYuWEJE7gocaN8JtKCueOnOWRx5pyenTp3HYbESE58Jut+P2eEhxOonOl4+ly5ZRpkRxc7h/oesLzJn9NdF35SE8PAyBxvU4va+c9fUsWrV6ArfHjcOedfu0vo+bRdM0du3aRe3atenfvz/jxo2DAHVHM1YZJkz4kLQ0F/fcc4/Zb1y+fJnLly/Tvn176tWr53Ovpmns2LGduXPnUaRIEcLDw0lOTubUqZM88EB9nnnmGQiQ3u1Aczqdtz8VA9lhjho1itGjRxMZGcmRI0fIkydPjh5W3k8OCkeGzS7cnSSr/Eu/1atX8eSTT+H1elmwYAHNmzcPGP6vQNM0Nm/eTKNGjRg9ejRvvvmmma9ADU4zZlBDhw5jwoQJhIWFMWBAf555pi358+fn2rVrzJ37Lf/5zxgApk//go4dddOs/nH9ETRjUO/VqxeXL19m+/bteL265B0WFkalShUpUKAgM2fOJCoqCmEIB1euXOHZZ9v6nLsODw/n6aef5osvvgj4rP7I9zljxgw+/fRTDhw4YK6SAJQuXZq6desybdo0HA6HMcPUZ0kA3bp14+uvvzbDAzRp0oQvvviCe+65x7xWqlQpQkND2b9/P9yicvtfRhjCgWYsiw57Zzjj3xtLtxc70e7ZdrRo8TgAM2fO5LnndAU4jHKTJec3eb4pNE3D7fZw5eoVxo0bx7Zt23ikZUu6vdiNwoUKc/XqVaZPn86PP/1EnTp1GDJ4MFFRUQQHB9/RdyfrWatWT7B6zRrOnj1HVGSEj2AgsWuQ5tFntEE2jRvJqaxcsYJdu3Zy9OgRbDYbZUqXZt68+UTmjjRNIAMk3Eii/H0VePfdUbz4Qhc8hiKjx+Pletw1AEKDg7Hb9Lrv8XpJTnVidziIypMHm4ap4Hg9Lg63K43g4CDsdgehoWGkpqaSmppKZGQkISEhZjvKjKz64Jwg7//661l06/Yis2fPpm3btuAXn6ZpXL16le7duxMbG8vRo0dNv8jISO69915GjhyZoX/XNI0VK1bQrVs3Lly4YN5ToEABhg4dSi/D3sMfyfvN8pcIB9WrVzePrchGmt3DaprG8ePHmTt3Lv3798/UspVMY9q0aRQvXpzmzZsHDHenkfmfN28e/fr1y5B/me/u3V/iyy+/AqBLl85Mm/Y53KHKkBUyf6VKlSJXrnD27fsNjA+p+DdGGfbQoUO0atWK48eP06ZNGz7//HNy5crlExZgzZo1ZiOZO3curVu3NgdqyR99fmscjz32GDExMdhsNn777TfKlClj+vkPzt999x3PPfcc1atXZ/To0TRt2tT0y2lerGnPnz+f559/HoA33niD//znP6af16vr3chylPdNnDiRQYMG8dJLLzF+/Hiz7KwdyZ49e6hVqxYjRo5g6JChPv7/RgSApmED1m3cSNMmTShW/G6OHD7OocOxVKqof8zn22++4ek2bTh9+jSff/45r7/+OpGRkXi8Qjek4x9xDtE0jTSXm2txccTExLBw4UIWLVpI8WLFmDJlCoMHDWLPvt94pGVLnnmmDQ8//DB5o6N9Vo/+eOoS//fvG5+slnKAW7r0Z5o2fcj8WmIgNC19wT6zhfTWrZ9myZLFbNq8mftr1uTKtTiefbYdBw8dZN++34mOMoQP4cVuNYaQCUJ+fwENzaKfkBleoRtmyo6bbcf+yPsff/xxVq9ezfnz54mMjMwQn7X916lTh127dhEeHk5sbCyFCxeGbPrPvHnz4vF4+PHHH2ncWDce5Z/G7SS78r7lbNu2zRQMMDph/AoyM/bv389///tfXC6Xv1cGvvjiCzZv3gSAEN47uleTGfv372fy5MkB8y9f+jPPtCU4OBiAxx7TZzl3skIEQr6bTz/9lDNnzjB8+DuQTcXetGkjNWrU4Pjx47z99tt888035MqVS/8qmxB4vR5zUGzcuDF9+/YF4OWXXyYlJTlDffD/+2ZJSkoyZ9cPPfSQj2BgHWwBJk2aRNeuXXn33XfZunUrzZo1+9MdSvny5c3fuSLSBaSs4pszZw7NmjXj008/zSAYSKpWrcpDDz3EiHdGcO7cOR+/fx/68CXLaNVK3TLfo489BkCpUqX54Ycf+GHBAh5/XG9be/fuYcb06eY9NtOs7x9DGPvSISEhdHr+OebP/Zbjx48TGZmbFs2bY7PZOX7sGD8s+J7nn3uOkNBQ00LgTaE/akaXDbIZ3bhxgyFDhlK6dGmaNn1I98vCCaH/T3gFbgGeAMmlGLoA7Z59ljZt2lCtShU2rFvDm28OMgUDYQj9IoAxIqvz+hgo0s0uymv+4aTLKfLeP4q8d/jw4bhcLkaOHAHZ9FEVK1YEwGazmf17VixdupQbN26wcOFCUzAgmzRuNXdMOJAPNWvWLEqXLk2lSpXAmDWeP3/eL3RgZOeeXeG6XC7Onj1LZGQUQIYB7K9CCkVBQUH+XmBUuhYtWnDs2DFOnz7NU089lW0l1vwUVrIiO//sGDNmDPnz56dVK8M+eiblGhsby0MPPUxaWho9enTn7bffBgiovCgFhBdffBGA69evM2uW73K65I/kX5bfzp07OXv2LAD169c3/aTCmNzzbdu2Le+/P5aYmBgGDRrkE0d278Ifa/gCBQqY37Q/dPCQJZQv8hknTPiQvXv3MmvWLMikQ5N/DxkyBID//ve/8AfL6X+NjM8oV5rSR8m4a/qydbFixQGw24N47LHHeOzxxwkK0vuQvbt3o2kQHJyzAdqabqA2J99JZGQkSSmpJCanULhgQXMAeeuttyhcqCApzjQEkCcqCs3vREXGYdePrLwFxnCeNbNnz+bixYv066d//ji7qi1tGdo0zQwrhD5bl7cWK6brDJ0+fZpFixZx6dJFqlSuTA9DeY+A7y0wMpTm99sf67VA/reT2rVrU6dOHSZP/oSrV6/6e/u0V7lSkJSUZG4xCCEyKDRqmobT6aRz5868+eabNGzY0Mf/ThK4d79NOJ1Ovv/+ewYOHEjnzvp51cTERH755Rf/oCZSexNjlUE2IjJpnACrVq3i4sWLhIeHW8JlfFT/eKzOH39/zdAc9b+W2b1YVknsduODJX7h5e8CBQqYSmfW61b87w2E9LeGDfQ7J3EtWbKES5cu0bNnT3OQ80fTNFwuF+3atcPr9VK6dGkmTpwEZkPIPI2iRYuaCpirV6/29zbJLp+ZsXXrVvP3gw8+CIZymGycR44coVy5spw/f57Y2APUq1cPzNWR7HUMsiMiIoL8+fMDcPiwr3DgXzfPnz/P4MFDmDx5MtHR0dmm3ahRI0qUKM60adN8vk//d8e//mVXF/39NU03pK8fu7PhFaBpdrM8pX6JHDY0NDxCkOp0mR/++WHBd2h4CTLapDDilSJGoHxZ+yQCtEU5i80VFkpEeBgAeaPzERYWToECBUhOdRIWogsnHmMFLWN85p/GNeOH5fsBPs54yvRr1nz7xoWhC2Oz2UwFt6zRn8d4+gzXPca/vfv0IV++fKZvk0YPsnjxYsJCgvAYefPtAmQp+zsd85nMtAOTnf/tQLbJV155BQxhC+PdBQony0UIYU5SrP5Y7n399QGEh4czevRo0++vwCZnJHfCrV69iitXrtCmTRtatGhhZmLBggUIy+xMOrdb/ySoEIJx48axa9cuoqKiTK1P6eTsEyAuLo4333wTjA5ZhpHIZW39tzy+JkhLS+PMmTOcOXMmQ3gZJj09Lx7jc6VCCDweNzdu3PBJy+v1WGbKgvHjx7N7926ioqKw2/VZqv8zZLyWnj+rk9cSExM5ceIEZ86cweVy+aSd2f0ej9snjvj4ePNIlX9Y6zUp2Dz0UBMz7kDhRo4cyYEDuibzu+++i8PhwONxB3w+q3M4HBQqpJtpPX/+fAb/P+pkvjZt0reY8uaNpmrVqgghzPcwf/58qlatSosWLVm/fj1RUVFGnr2AluFZc+Ik8t6wsDDzNMbVq9dITk5CCGG+N48n/V1169aNqlWr0r179wzxZubq12/A9evXWbduXQa/v6OTz3rp0iUOHz7MiRMnTL+EhBtm+bndXtzGuXghBPHxNzh56gynzpwn1eUBoYsGbq/AI8DlEWhGPOFh+laMzZa+jG0DQoL1/mPC+LHs3ref6Kjc2IN0HSBNyCVsXRHOmmen00lycpLZ7hMTEzO0e5fLjQ3QEFy9foOr13X/XBFR2GxB2OwOwkJ05UO3x6MLqEZ85y6c59DhQ1y8dMGIT3dutwePW/8XTRDwP03gTE3Vfwcob6uLjT3Arl27aNKkCdHRd2Xwz85peBFe3UaCVwg0AW6vl8oVK7Jl6zbmzpvPqtWr+Xn5CgoWKoTLo29HCCHwGP/Krd7MXcZ0/45OTiLkGJaZK1GihFmnjx8/hvDrb2X/uH37r0ydOo0vvvgCYekf/gqnpaampvdktwkpEXXq1InDhw+zZYv+0YzatWuzZ88eQkND+e233yhatCjCKDR5z9q1axkzZgxr1qwBICoqiubNmxMcHExCQgK1atVi0KBBJCYmMm7cOCZPnkxycjIYio+VKlUiKSkJm83GoEGDqFKlChgDqM1mx+12M/6D8UybOg2boSQTERFBz5496dmzJ5JRo0axatUqQkJCuHjxIh988AFNmzalb9++7N27l7i4OMLCwujatSsvW2yIr1mzmjFj3mPtWv2jInny5KFp06Y4HA4SExOpW7cub7zxBgBTpkzhm2++ISIigtOnT9G//wBeeOGFDGWi7/sPZ+3atURERODxeLDb7XTv3p3evXuD5fn27t3L0KFDcTqdpKamcvfdd/Ptt9+yZMkSJk2aREJCAvHx8VSvXp2RI0dStmxZMz2ZptfroUKFipw6dYpz584FPF2iGQqXNWrUIDk5mVq17je1/a3CWyBsNjsul4tatWoRGxtLhQoV2LFje4YlN4l/2pkhy+vatWvUrFmTc+fO0aBBfVauXGWGefvtt5kyZQr/93//d0uPCcm0hWWlq1OnTsybN4/g4GAOHjxIkSJFzMbvcNix2ewsWLCADh06sG/fPsqWLWvMKjOuelnRNI2ZM2fy8ssv88Ybb5gzjpw8h/9M58+S0zSPHj3KwIEDOXz4MPny5cPtdpEnz12GUqiNhQt/BEM4cDhsnD51hreHD2ftunVERd2FMIzqdOnahZ49exJsA7cxq35vzHj2//4bhw8fZO+eXVSsXIH7a9XkypWrtHr8SUqVLM2I4e+wabNePwtE56Zhw8bYg8OIS7jBww83pd9rejv6z3tjWbVyBXabjStXrjB27FiaN2/OwIED2bVrJwkJCYSEhNChw3O8+uqrACz9JYbPv5hOQnw8l69coWaNGrzWuzctmrdgyZLF3H+/bgHQIwR2TePwkSO8/fbb7I+NRUNw7dpVypcrx5ChQ3moycM+5TDn6zks/+VnChUsSFhYGB6PB6fTyWuv9eHu4sXZsG4dc+fN467oaNxuF+fOnadSpSoMHDjAKH1dH6tXr14MHTqEd97Rtzuyfm3pnsJ4f/7BM5u9u72+isVGq7A4//v0laA/w5+7O+doxopimTJluHjxIhcvXjSPSvuH27t3L3Xr1sXj8dC796t8+OEEsLQXWUZVqlSmUqXK5hF/2Y9b8Y//dpF1r3MLSU1NZenSpaaJTYAnn3zS9Fu4cCEE6KxOnjxJgQIFTG1263EwYUhWGNsTV65coXXr1ubyrc1mw2bTsNlseL1eU2gQxl5PYmKiqcz1+OOPs3XrVnbu3EmpUqXo27evqSQHEBoaitPpZM2aNcTGxrJu3ToaNWrEwYMHGTZsGFOmTOHGjRu89tprvDf2PfO+U6dOU7BgQZo1awZAWloamqbnCSA5OcknDa/Xy4oVKzh48BDHjh0z/SRr1qymdOnSLF26lEmTJrFly2bWrl1L27Ztef3112ncuDFOp9OsUHa7ncjISPbt28e2bds4dOgQ77//Pj179qR58+bMmDGDjh07smDBAurXr8/p06czvIOzZ89x/Phxqlatai79W5HhZ82aZZbxU0+1hkyUFgMRHx9vHt2Jjr4rQ4P4I8hGtG/fPlNZr169BwC4fPkyLVu2ZNy4cdSrV89neVULsMwtXU7wDyfzUbSofgQxLS3N3HeUdUEKSD179mTgwIGmYJAdMq2qVXUt/L179/qFyBx/3Q9hzBiyQ4bLaXgrmqbx+++/U6lSJcLCwoiJieHnn39m5cpVPPnkkyxf/gsnjh83wzscNjZv3sJ9Fcrz888/899P/su6detYtWolrR5/nDf696V5s2ZcvZ6AQwOvF0JCg/F4PSQl6m1LtrmQkBBcLhenTp6mZMkSPNxY3891pbnIFRGBw+EgOCiYNEsfExoaSmpqKmvXruX3339n8+ZNNGrUiKNHjzJ69H/49NP/IyEhgQEDBjBx4gTmzpvHSy92o3q1qnw0aRId2j3Lz8sWE3f9mqHXkF5edk3jt/37qXl/TdA0Fi1axMZNG/nyy5ns2bObR1o+ysSJH4JRDgDJKSmcPX+eiZM/Zsy493n/ww9YuXoVdoeux+RyuZg6bRrvv/8+H344gRUrVhIfH2+miaWOVKmi15k/i75SoiOMbRXd6ToKUnBI36zBtMCYLgz4/pb+N+tkKncKTdOoWbMmLpfLNORkbf/yd+HChQkL07eYzp3z1bGTYd4b+x6HDh3mk08+AUvf+Wfa258iNTVV3G7ndDrF7NmzBSCOHz8unE6ncDqdYufOncJutwtANGzY0Lwu70lJSTavLVu2TACidOnS5jXpUlKSzXucTqd44IEHBCBmzJiRIazVdejQQQCiV69eGfwqVaokAPH111/7XH/sscdkDRc9enT38Vu9epUAREREhLh8+bKP39KlS3Oc/9atWwtAvP3228JpKY/ff/9dACIoKMinHKX76KOPBCCaNWuWwW/lypVmvgsWLCh+//13H/+mTZv6pGlNV5Z9hw4dfPys79fpdIpq1aoJQISEhIjY2FgzXEpKcpbO6XSKmJgYM3+tW7fOkH+r869fWTmn0ylGjx5txr1z506xfv16UaBAAfNaSEiI2LNnT4Z0MnP+afg7/7CJiYnC6XSKDz/80Ezzq6++Ek6/Ov7yyy+LAgUKmH/L8vGP3985nU5x5swZAYhy5cqa1/zD+Tun0ynOnTsnqlWrJvLnzy+KFi0qihYtKooVK5alk+GkK1KkiChQoICIiYnJMl35XO3btxeATzlZy6Bo0WIiNVX/e+/e34TNZhMRERHi4MHDGcJP/Ohjvc43b5nBr1+/1wUgRr47MoOf0+kUi376QQCi/L2lMvglpThFspEHp9MpWrRoYb67Pn36+IS11t3IyEgRE7PS9LuecEN8Nm2qWPrzMpEnz11i927fevZijx4CEA0aNhTXExLM6xs2rjPj3L17t3A6nSIxMb2u/LrtV5EvOq8AxIjhw33irF69uggPDxfr1683ryWnpPs3btxEAGLXrl3C6XSKlFRfl+rnrHHn1OnvXMaRXgdSUlNFqtPp4zLca3HJqb7O/95Azj8+f+dfL/+ok/H17v2qAMTHH38cMA2n0ylu3LghihYtKgDxwAMPmOFk+z9+/LgAxKeffupzv39cd9JlP6X7k0ipaPbs2TRs2JAiRYqYfhUrVjQ1xzdu3OhjKEII4TPjjIvTzZ5iSMdW9KXIdGlNfq8hKSl9Vu7PsmXL+OabbwgODjaX9a3I5fkZM2b4XJeKgnnzRjN27PtgWTYvUaIkNpuNxMREHwMWGDNjidRFkPjPrPPn15VX5DPJf/v31zWLBwwYYJajVZrs2bMnZcqUISYmJoPlyXz58pnxDBgwwOcoH0CFChXA0DT258yZMwDcdddd/l4m586dIzY2FoB7772XEiV0DfGcHiHduCnd4JCsE5nhPzMPhFVpbL1htz1//vxMnTqVVq1a8fHHH5tKRE6nkylTpvjcnxVagBUFq/PHbtffb6lSpcxrspy9xuHyzZs389lnn5mGj2T9968bmREWFkZYWBhnz54zV29yQlBQEE2aNKF58+Y0btyYxo0b06hRoyzdQw818XHNmjWlRYsW5M2bF3Lwfi5fvgzAokWL/L1o2bIl+fLlNZXoXn99AF6vl4FvDKREiWI407ykuXT9AoBePV+mVOl7iVn+MzMN875SR8Hp1I/WpTn19ubyeHB5vKS59PaakJKiX0cjyVjBc3k8uI13IoyPBAEUKKS3+0IFC/HuKH3bRqZTpkxpwnPps8JOnTvTsGEDPS6XhyuXL/Hkk08Q5LDjTE3h5IkTxN9IJilV78Pi43X9ig3r1nPmTLqiWq3761C9mj6z37xZ34b1CoHb7UUIqFK1Cp9/MR2AEaNGsXjxYjCO4cbGxrJp0yZq165t3Kd/dwDAmeY2+1lpsRMphVh+g/6Vw2xeZabobUG/39o2fFcSAm8BWP3smq/zvzeQyw7/9pqdywyzbzVWqmW9DkRwcLCpd3Dq1CkSExPBYn65a9eu1K1b1zy1JbmjKwV+OO5E4pcvX2blypWMHTsWIYShA6ARFhZOq1atWLduHR6Ph4ULF9KvXz8IUCjy78yWWPTOVH+RgRTxMCqF5NtvvwWgfPlyAU3PVqtWDYwlaafTaR6flNsazZo1Jzw8PEMaEqmIJrHmPzM/SVqa3nFY442NjWX58uVg6GoEShNDc/3IkSN89dVXdOjQAYx4rEqHTZroSoVutxu73Y6maebzWeOV/0pb5lKxy+qnGftuZ86cMcumatWqPsthWSGPEC4xOjcgW8NVWflJZNopKcns3LkTjHoYExNDTEwMlStXRghBsWLFOHXqFLNnz2bIkCEUKFDAP6o/hcyHEIKSJUua169cuYKwKEV2796dZ555hoYNG+ao3PxxOBzkzp2bS5cukZqaatbNrBBCkDt3bt57L30b7M8iFXWzokqVKqxcuZJnnnmGtm3b0qRJE2rUqEG1atV45JFHKFAgP0II9u37nZgYvc7fd999enk5NNxugc0ycDdo0IBjRw+zYMECunTpjN2eroCIMagKQxnOXNYWArdUAjWWovUwXmxausAui1CGbdSwIaFhuvKibA+aTcNtTFiaN2umx+32YtNsREdHs3LVcjp16kRqahrPtmvHFzO+5JHHH0cIwYDXBxIUFMQjLVtSplRJPQ8CbiTcIDJS38JLSU4x05EKfXYHtHykBe+MGMnIEe/w2muvcenSJUaOHMmMGTMoX768PokyTnPIZ/Z6dR2F0NBQQkND9WuWaiIsA6xmg7hr8fz2+28+wracfGU2iGZ1KsnrFbhcaXi9evlJ4diKPM0lkX2MTEO+1+ywTkz0/kg3Ga1bo8w4aZHvXKaXlpZGwYIFKVeuHGSRbkSuCPBr64EoXrw469ev5+rVq1y7ds20XTJ37lzWrl3L3r17s7z/TpOzw71/kvXr1+N0OvnPf/7D5MmT8Xo9eL2CoKAgU4LCsCInhYPM8Jfksqow1mv+9x0+fBiA8+cvmIOoFCpCQkJISEgAY2BMS0vLYFtBmrCVqwA2m95BZ0ag/ElkZZQECittPADkypV+RNM/rJwNHDhwgJSUZMLC0sNiSLDyzK0UDORvAqzKYHnG0FB9dmRFNtpLly6Z10qXLm365YRt27bx66/bAXj00UcpW1b/KtvNohnKk263x3xfu3fvNiX6li1b8sMPP5jhbDY7L774Iu+88w4JCQnMmTMn2/r3ZyhQoACRkZEkJCRw6FD6ccYxY8Zw8uRJNm5MV+DMboD1x263ExERwaVLl3Jc7lje361AjyvzfMu0Xn/9dZYtW8aBAweYP38+8+fPB6BMmTL07NnTXLXbty9dfyIiV27zt0N+hc/Y774rj76iFRsbS2JiEhGGkSn5XDbLv1ZjOdbnlvm2aRoOu34sMlAxFi6itx0wZtZ2/euBHqPvkPpOHo8H7OBxe6hZ837Gjn2Pgf0HMm7c+zRs+CBejxeXsFOjSkVmfD6V5NQ0PpgwkdWr1+B0puFKS2Pfnl0AuNx6m3TYbQi7ni+XC4KDYMjgQezZs5sff/iBV155heHDh9O6ta7vY7Np5sAvn88rBG5P+imq9H81c5VA0zAlr99+/53OnTvh8XhM+yz+9cU3nuzRAszIs+r/rHU00L3yb//7/NEC9JeBkOHi4uLo2rULH3yg631kRkSELhzIY8SZpSNXDlJSUjhz5jRFixYlNTWVHj16MGjQoD/c790uMm/JtwD50r788kvq1KnDzJkzGTlyJCNHjmLUqFEMHz6cyZMnU6vW/QDs2LGDPXv2+MXii8hkJcBKZtclLpcLl0t/kWXL3ku3bt3o1KkTHTt2pGPHjrRv355evXqxZs0aVqxYYb58K9atASkpWytx+hlrnZxW4Mywnl+323UhJFBcMl8pKSnmCoQV3w4x/XeguPyRwk+gsFZFRWlfQqJpusKdv5Kh/Pujjz4yr7311luQSRrZIQxFU6spWnkyBuD1119H0zTcbrc5Y+nYsSMhISFgmNz23/L5s1jLOCQkxFyZkAqS58+fZ9SoUXzyySdERkaax3dvFq/Xa67wZFf/Jf7n9f8seqeYcUZmxev1kC9fPjZv3kSfPn0oVaqUOegcOXKEgQMHmvbjXa70d5HernTni/4ur1+Pw20MpGRRDlJYkAQK5/91QjmfFpYth/S1i3SkP+grhCEhwZw9c5b7a9Yid+7cNGvWjHz5otE0jSAjjVGjRxN9Vx7eGjqEggUK0rdvP6ZPn06dOnXAkj/N6LBtmv5HqltP6/339e1N/BS2Me7Vnf63zVDMdDqdpqDk//zCWJURQN26ddm1axd79uxhx44dbN++nV9//dXHbd++ne3bt7Njx44cOf845P3bt283JgoZ45e/t23bxtatW33cli1b2LJlS4br/i4nYWS4LVu2cOjQIUaOHGWUScZ3LZF9s3+fL5H3SsER4MKFiwC8+uqrREVFMXLkSJ+wfwduvhe6SS5cuMDy5cvp27cvTZs2pW3btrRr14727dvTrl07nnjiCbp06WqGl/uQGStsxkITQvDOO++wa9euDOGxNipNY82a1YwfPx6MfVZpPTE8PBfNmjXj0UcfpVWrVrRq1YpHH32U5s2bU7duXfPoo3+cch/ZugQWKA/+WMMIIRgxYgS7d+/O9l7r4OsxJH+J9d7ERH0P0+FwZFiew6jAclkwEIHyIYUjGbc1jPx9zz33mL/lapBcxtOMARmLQCAH5y1btvD9998D8Oabb1KjRg2feG8GzVgR8HjSjcrI45T58uUzt4r0Eyy6dH/33XfTrt2zABw9etQ8NXMrkYN9rly5zNmDXGnp2rUrDRo0MI2CBXpnOcHr9ZKUlERISEimFjj9kSd2RowYQZ8+venfv/8fcn369Oa1117j4MGDGQRAK5phiTImJoaUlFTGjx/Pnj172LdvHwsWLOCJJ54AYPr06ezYvoMilll6uuBjWdY2/NLS9AExNDSE0FBd0NPR65i/aV35d6A+RdM0hg4bxuat23DY9P16Hf2H3ZQahLmPr2P0NeaSukAIfQXr0uVLnD5zBmw24q7HI4BcoQ7cQPvnOzNm9GgKFszL3r2/Mf2LqbR6rAWlSxUnV7i+AuIx2k6q00lyqhOPVx/AQ40VlHHvjyNfvnyEhYXx/vvv88033+h5MbdG0m2e2Ox28yNjqal6ufmXg7Tx4PHqpySioqLIkyeP+e+tdtZ4o6Oj/xYub968REdHBzya6M+NG3q/KCcZmWHVt0tISODAgQPMnj3bfF/ZpXOnue3CweLFi8mVK5dp9EhY9mVkYTz66KPmbHPZsmU+90usBSc7fo/Hw+rVq02jOxLZeVg72rNnz7JkyRLz72qGss/+/fsDLqVLVqxI/344llUCObhpmhZwpuc/uMnGqYdP91u1apWpyCfxvxcw970wtkIy4+pV3WRs+fLlfVY85NFJf2S5Sv9AFVQqYV6/7nskCkv4YsWKmd8PkGai5UAxfvx4HnzwQZo1a8by5cux2ew4HA5SU1N56aWXwNCVGDUqo5QeKD+ZzU5lWLnCER8fz/bt+nZFjRo1yJ07fWkaSz2x2qWYOnWqJURGAucn4zUr1vd59913g3HP6NGj2bx5s3l0Kbt4ssLtdhMfH0/hwoUytWBpRebJ6XTyww8LmDt3nrnE/9133+XIyfDz53/Ht99+G1CZNRBvvPGGuVoUFBREiRIlePTRR5k3bx59+vQBYOWqVdSpU5eQEH0r6/LlKwB4PMJ8/7JUT5w8AUCNmjV8tr4yqfIW0t+LLA9N01i3bq3lqKmvf3o78ZK+cmB8lcjnXQvTX28HmqHgZ8Pr1VNe9vMqfvx+HgDTpn5G2bJlzFWRNJc+gADYjInIoEGDOHr0CA4byB3Mz6Z+ztx589i2bZupVNuzZ08OHTqEFmB5O9hhN631Xbqkb7cJITJVPBSGMGXts2+3+ysQhj5GIJcdKYZiq9yuzYwiRQqb9WfLli08//zzdOnSJVsF7L+K22IhUSKEYPr06Tz11FMZlPesrnDhwjz66KNg2VqQ8cgwuXPrA53T6TSVuOx23YhR3rx5feKTgkZaWpp57caNRB+LiZ07dwFDaFi1alWGPAkhWLRoEc8995yPlSopCPhbaRRGfqyDsNVPDky6DQJdWQ9ji+Ouu3SjQtZ4/NMoWbIkTz/9NBimjOX91vuuXLnCihUrADJY15N78JqmmeVnjUPmWy7JW51UpDt48GAGP2GZlUhTosuWLeP06dMIIRg+fDiffPIJY8b8h+eee46XXnqJq1evIoSgefPmHDlyhPr1HzBNY0sLjtb87dixnbZt25ofOrEqO/o7SFdGi42N5eJFffmuadOmZl6lv6bpz16jRk1atmwJxrc+fv311wzxpsevf6ehbdu2jBw5wlzFkf5er9d0/vcKY6UC4/TN6NGjGTlyBOXKlcs0fE6d1KEpXbpMwLrp72Qeo6Oj2b17D+fP67Ysjh8/zrFjx3LkZPjTp09z/vw5Hn744Rw9R1hYGIsWLTL/9njcZhuTn1G22ezkzp3L3D9fsWIlQgjsdl3ol/devnLFNDDW7tlnfdKRwqndUHrVNF1TXvrnMhTJUlOdaFK5EHC53UQbZqultUVhCp4ybS8C/VmtbT44WLYfXXgQQuBKc+ntT9MnF3ZNv/6rIbjmiY7igfr19TQMP1daGoePHDHi1C0qrli5gsSkRD1NBKvWrGXQ4Df5/PNpFC5cmGeffZbOnTvhdDpp3749KSkp2G027MY+hNtQZpQ6QQcOHtCf0RAi/g4O4/349wN3wsm+Qxfd0p1/uPTwel6lPljx4sUzhLG6okWLmRO2GTNmcPHiRT788EPEX/S82blsZeubxTpL+vzzz9m5c2cWezHp12vVqmX+DjR7K1dOn5WePXvWVOY6fvw4J04c57777vMJe++99wLw66+/mtfWr1/vo4leuXJl3ntvDAAvvNDVx941hmb7Sy+9RM+ePX1m4HLJXEr1WJ45KSnJXD63+mOZ+Z85c4aDBw8CmJ1s2bLpqwJY0rAqa2LMwPPkyWPO3PAr7379+pGQkEDbtm159ll9qVwil77S0tIyxAuQkKCvCliPXMq4S5UqSdGiRdm9e3cGgypWunfvTsOGDUlNTaVPnz44nU4WLlzIzz//TOPGTejatSvNmzdn0KBB1K9fn23bttGmTRtiYtL1OqxLoZJBgwazaNEixo0bZx4tDbS6gt/1hQt/Mn9btyvkqo9VU1oa2QIYN26c+TsQgwYNYtGiRbz33li+MI6T4ZfnzJDCQUpKClWrVjU/fJPZ8+SUbdu2geU5bxa5mvNHXVbbCf4ULlyY/fv3M3PmTLCkDbBs2c9g+f7F8OHvEBkZxfz537Jw0RLsGgTZNVMnYPCQwSQnJdGhQwfat38Or0if6ck6L9ui3TyFoN9c9B7dnPXZU6c4clgfiE+eOsWZ02d8TpYA3DDiiLt+HQCbzWEMuhAff91chbpxQw8XEhKGEIKEhHjKly9LamoK1+Ouc+HCBXO9oug9+jLz9WvxHDQ+xiX9/m/KFM5f0PVSkoz26vV4KGj0Yd//uIBHW7agbt06PPnEE+YWxwcffECx4sXYv38/nbt01s0bA3YbuI08Vq5cGYCjR/Vnzlj1hMXdOWQbWLBgAffdV4HmzZvzyCOPZHAtWrT4Q65ly5a0bNnSJ67GjRvz6quvmluRgVaBs0IIwbZt2wgKCjLHMP9+QD5XREQu87gvxifZ5bbFzaZ7R0hOTha3yqWkpIiUlBTRp08fkSdPHmsNE7lz5xZffvmlGUa6qVOnikqVKomgoCCf8KVLlxZNmjQRmzdvNsP27dtXAOK+++4T8+bNE+XKlRVdu3Y1/WUe9u3bJyIiIgQgRo0aJUaOHCly584tNm7c4BMuJSVFvPfeGAEIu90uRo4cKRYvXizeeustERERITp27GiGe+ONN0TFihV98lipUiXx0UcfiWPHjolWrVqJwoULm37h4eGiWbNmYvv27RnyX6FCBfH999+LMmXK+KQxbNgwUbVqVZ80qlSpIhYvXmyG2blzp6hQoYIARPv27cX8+fPFjBkzRJUqVQTgUx4pKSli8+bNokmTJiIqKsqMM2/evKJZs2biyJEj4qOPPhJVqlT2SbNChQpi6NChPvG0a9dOAGLdunUixShDq0tKShQpKSni0qVLokkT3chKkSJFRFRUlNi1a5eIj48Xa9euFfXr6waqChQoIGbMmGHGHxcXJ86dO2f+bX1Hbdq0MfPWoUOHDGGsYWfOnClq1aplGmSSrmTJkqJBgwbio48+8nmunTt3isaNG4vg4GCf8Hnz5hV9+vTxiTtQfp577jmf/GTlUlJSxE8//WTeu2XLlgxx5yQe/zhTUlLECy+8IACxZMmSm47jTjmZV1kHgoKCRI8ePcSiRYvE4sWLRffuLwlADB8+wqc8du3aJ8qW1et8u/bPi5lffS0+/WyqqFqjhgBEpy5dxfX4BDP84KFDRCW/Ol2lanXxWKsnxJ59v4uUlBSRZIQdOGiIAMR9lSqLr76eLcrdV0F07NzFEtdb4j7DIJp0NWpWEx9PniRiD/wmWj3xmMifP9r0C88VIlo+0lysXr1CXLl6SZw6dUKcOHlMVKumt8/KVSqLI0ePmvE/ahhVi8qTR3z2+Qzx06Jlov1zXUSZsveJjyZPFo4ghwBE9WpVRKvHHxWvvNJTROTO5ZOf+d/PM+MbM1bvz6SLuitKNHukpdjy669mmI2bNwtAPNaqlXktMTnZdEl+zv893i6XkpIikpISRYECBURUVJQYOXKkGDZsmBg6dKiPGzJksBg6dKjpN2zYMNNZ//a/L5B7/fXXxccff+yTvn++AjlZbrGxsQIQ9erVM6/5h7WGb9CggcAw9Cav5TTNO+205ORk4S8w/FGkhPTJJ59w8uRJChcuTFBQEGlpaZw+fZpWrVrx8MO6rXDJ8uXL+emnnyhZsiRhYbq0nZaWxoULF0hLS+O1117zMR4jvz+QlpbGgw8+yOjRo81lN4mmaRw8eJDRo0eze/duihQpwptvvsnDDz+cIRzAoUOHmDJlCtu3b0fTNKKiomjfvr25xInxTEeOHKFo0aKEh4eTmJjImTNneOihh2jcuDFjx47FZtMoXFifDVy8eJH4+Ot0797DlNQBw9DNLJKTU2jUqBHjxo0zZ02fffYZ+/fvp3jx4oSFhXH9+nXOnDnDCy+8wP33328evwOYPftr5s6dR1zcNTTNRvHixenV6xXTPLAujeqmaqdNm0ZUVJSpLSvLdvDgwaxbt46YmBhKlixJREQESUlJnDp1itKlS/Paa6+Z+V68eDFt27bljTfeCKgbIJFlOmfOHD766CMOHjxI3rx5CQkJITU1lfPnz1OlSmU2bNjoozjXoUMHatWqxYABug14GbemaVy4cIH58+ezfv16goKCTONF1jCSH3/8kUWLFlG4cGGio6NxGLoNycnJXLx4kaZNm9KmTRuf8vnssynkyXMXefLkwWbT8Hi8HD9+nJIlSzJgwIAMs/pLly4xb9481q5dS1BQUAaDU5mhaRpHjhyhcuXK9O7d21SQ9Se7eKxoxpJwuXLlSEtL49ChQxnaw98FWY5vv/025cuXo0KFirz33ntcunSJsLAw8uTJQ6dOncwtRqk3a7dDqtPDrFlfs2jRQuKuxyGEl1KlStKtWzcaN3wQr6FD4rDbmfb55+zavZtiRYuSO3duXC63acirX78BFL27EC4PBBmLHf/9v8+YO3cuqSkpPNCgPu+NeY+wkCDcXr1NHjx4kGJF7yE0JITklGROnz5N8+bNqVevHhMnTsDj9VKwQAEcjiAuX75McnIyLVs+woUL51m27GcWfP8dJUuV4r///S/9+/fn2LGjPNGqFc+0aUOjRo1ZvnIVPy5czMmTpwkJCaFM6dIMGTKIUsXvYfGyZcya+SVFChdi8ODB/LRwIUeOHiU6bzR2h4P4+Os80vIR6hvt/sdFC9m0ebPZ1uOuXyc1JYUXur1I5fLlTamhdu1aHDp8mMOHDlMwf3481n7RsoJxJ9E0jRkzZtCrVy/mzZtnfhr+TiCESNdlycEsXtblr776ipdffplJkybx8ssvZ3oMWYZ/9dVXmTVrFnv37qVEiRI+Og2B7vsr0ZKSkm55L+LfmVqxdlpSmz07ZAFmFjbQC5F5sA6oBOh4/fOa5mfTQMbtH+5mCJR/OThJ/+zSsD6jNZz/88lr+r58zso3M6yDr8vlolSpUgjh5fjxEz7HBf2x5i8hIcG0Flm06D0880xbduzY4WNBcu7cubzwwgts27aNSpUq+Tyr9RlmzpzJ8uXLMx2Mc/q8brfbNMAiBbPM8H831vc2c+ZMYmJiMggrmSHvu3DhgvkFykBkF48VTdNYvvwXnnqqNQMHDmTUqFE3df9fgX89d7lcOBwOn+v6YGW0D6Evi8sWnuYBh91Xm9plGCkCCDIU+DLD5cFcSjc+WQCk200ASHG6sNlthDgyr0/W8P6cuxjHmDFj2LlzBy1aNKdnz14UzBfJ5asJTP1sCr/8spTa99/PW2+9RZ67DGNHbj1foUaSqZ7039mh59dOiPWB/HB6vNjtNhzAtC8+p2+f15gwaRI9e/TAC6Zdh3SzSXcO+e7vvfdegoODTaVm66BtRfZvV69eIy4uzvyAXNWqVcmXL1+m91nxHzNuBpnfhg0fZPv2HZw+fZq8efMGHIskmqaZX/GUx5ZttpvfyrhT3HHhgJvs/PzxjzuruKxhswrHTcb7Z7iV6dzKuLJCpjNhwgTeeust5syZw1NPPZVlev55k7Ru3ZpffvmF7t2707VrV1auXMnw4cNp0KCBaQHSv4HJuJ555hlq167Nm2++GTBtzTzKqHeC0gqbROoYZGXBLRCBhDJykJ9A+NdJ/zjl9Zwg733iiSdYsWIFR44coUiRIjm+/69C5jvQ8+t758L8iA6GcR6B7uzGVYy/AxjYy/D8Wgat/fRz/xKrXQOP8almArxzjHRldMKrWxLUNP2apoHXA9fjE/F6PeTNG0WQDVLSICUlmVzh4YQEQWJiCok34gkJCSFX1F3YDGFHA9xG/PJUQ7A9PU1rOmZ+LAabZFkFQtP0NhBk00hISqRUyVIUL16cHYZuljRJ/VcJB/PmzaNr16588cUXdOjQwWdW7Y/NZmf37t20atWKq1evmtdXrlxBvXoPILIRDqxt2vqu/etOZmiaxrZt22jcuDG9e/c29ZT8+y4r/pMX+Xxy8pHTtO8U/3PCgeKvQb7TkiVLEh0dzY4dO+Am3qW8/9lnnzXtwFvZvHmz+WVB/8aqaRpbtmyhU6dObNq0ifz5dfO6WeHf2LLqKLLDvyOR+Xn++efZunWrOVO502iWT8EOGTKYt98eDjfxTv6uCHN4k/1IZv3JH31O//iyi8c/fNbIAdzt9ujfErDZsNnSY/EKabtAV0TT7PYMOZBdqBCGiOQnDFixhs0aPYAQAofNxvSZM+ndqxeLlizl4SaNcXv1FRphKDHeCaxjReXKlUlNTc1wDNO/7crBNCkpicOHDzNv3jwmTZpE7ty5OXToEFFRug2b29UOZJ6ffPJJYmJiuHDhApGRkbctvb+KwCKOQuGHrPgzZkwnNjbWPFOdnSDoT926df0vMWHCBFMw8EfTNK5du0a7du148aUXfayMZcatFAz80TSNq1ev0q5dO1566aW/RDAQFsuGL7zwAiVLlmTYsGGG353Ny+1AM/+Tawf+H+a1fqD3j7ibjcc/fNYOIbBpEBxkx+GwYbfpI7eQR8Q0CApyEBQUhN1hRwhPhvzIpRIN/Q95r/5+fV1m1zM6if67W9euNHjwQTp27Ehyappu9CnQUsxtRNbXRYsWcfToUQYPHpyh/erCQLqT9+XKlYtq1aqZJ0vq1q1rCga3m59++omYmBimTJlCZGSkv/c/AiUcKG6Kxo2bMGbMfxgwYABr1qz2984U2dj79+/PoEGDqFWrFq1bt+bHH3+gZ8+eZphAg9uOHTt46qmnGDxosBkuK/z9A3Uuf4Zdu3bRunVrhgwZ4u91R5BLk927dyc2NpZFixZhM87yK/4eWAdz//eSlR8ZBJNb7xy29JWK7+bPR3i8PPXkkwDYbVIsuzNIIXfEiBHky5ePLl10+zPZYZ2UyJXI+++vaQlxe9A0jdjYWDp06ECPHj1My6aB3uP/OlpiYuJtfSp/KVDxv41slEOGDGHGjBns2rUr4FctA+G/52Yl0F6dTEtY9qbl75yklxU3s5qQmc4BmeT7diLzMHnyZAYPHsyaNWsyPV+t+PsjZF2Udcz4v29Nu7Xv1dp+NE3jxImT1K/fgO7dezBixNtwB+uSpmnExMTw1FNPMXHiRHr06JFt2tZ2mJKSTOnSZYiPj+fnn3827WNwG55B0zRSUpKpXr0GDz74INOmTYPbkM7fhdsuHCj+ecjGuX79eu69914KFSp0Uw3Ef5DN7l6rYPB34K/Mj0x7w4YN5M+f38es9l+RH8Wfx/+tZRRBby+apnHhwkWOHztGvQfqwR2qS7Iu169fn0OHDnHixIksv2Xg329gtIMWLVqQJ08ejhw5bH6FNrM4/gyappGQkMDGjRt55JFH4C+YHNxJ/plPpbityIb34IMPUqhQoSy1igMhsllW9Sen4e4Uf2V+hGEDvkGDBj6CgeJ/F83P/RUUKlSQeg/Uu+N1e/Xq1ezevZu33hqWqWCgWb5Hs3btGt4f9z5ff/01WCyD1qpVyxQMbhfCOIL4bxAMUMKB4o9iHdz/yQ3k70hm5R1oZqVQZMfNCOq3CllX33tvDOHh4fTo0cPnun+4rVu3Ur58eZ59th2x+2MZP3483bp1Y+vWrWAxt327+Tf1e//sp1Mo/qFk1pH7d64KxZ1CzvA1TcuRTs+WLVvYuHETb775ZsDtAFmX582bx0MPPcSNGzfYsGEDM2fOZMuWzezdu9dURrR+mwcwT/TcbJ4U6Wg3btwI3MsoFIq/NZkJApkJDgrF7cCqaPzll19StWpVqlWrlmk9lPW2TZs2/PLLL5w9e5aoqKiAgsGmTZvMj6Lt2LGDcuXKGbN2jS+++IK+ffuSL18+9u7dm+FI4fr169m4cSMOh4OOHTvetG7Uvx21cqBQKBSKP4zNZiclJZn27dvz6quv8tZbb0EWwivGNsEvv/zCG2+8kUEwkAghzO+79Or1iqljI1cAUlJSAKhTp04GwQDjC7hTp05lxIgRJCcn+3srskEJBwrF/yiZdagKxZ1ALtdv2LCBWrVqsWTJEgDWrFlj6gL4IwWGCRMmgPEhosz4+uuvOXDgAAAdOugfwRNCmKsUa9euBaB27dqWu9Lp0KEDXbp0oUSJ4j4f71PkDCUcKBT/AKSSlEJxp9myZQvdur3Izp07CQsLA+Dzzz+HTFYPDh48yJIlS+jduzf58uXz9zbv+f777wEoX7481atX9wmTkpLM1q1bIAvhAEOAaNSosfm3VQdBkTVKOFAo/odRQoHir0LWvYEDBzJgwADuvfde8zPLP/30E8ePH/cJLwfkDz/8EIB+/fpBJqtdKSnJ7N27F4AGDRqY12UcGzdu4tq1OCIjI6lQoYLpb20PN27c4MCBAzRq1Mj0V+QcmyxM5ZRTTjnllPszrlevXgAkJyfzf//3KcIYqKX/sWPHmDNnDj169KBgwYJ4PG6f+2XYtDQXcXFxYHyQyT8duW1Ru3ZtoqOjuXTpEnPmzMHlcplxbNu2jaSkJOrWrYsQgqNHj/LWW8N45ZVXzC/AWvOmnK9TKwcKhUKh+MPIwQSgZs2atGzZEoB58+abn1P21zXo06ePcd13CJLx2Gw27HZdt6Bo0aI+YTBOMWAoIwLMmDmDqVOnEhQUZIbZsGEDHo+HokWLsm7dOrp160ZISAhz586lXbt2piChCIwSDhQKhULxp5ED+yuvvALAlStX+Oqrr0z/c+fOMXPmTNq3b0+JEiXM64GIiIigdOnSAAQHpw/4ADNnzjSVER944AEAlv+yPIMhpM2bNxMeHs4nn3zC22+/zWeffcawYW8RHBxMnTp1fAQJRUaUcKBQKBSKW8ZDDz3E/fffD4bdAzlDnzx5MgB9+/aFTHQNrMjVhVmzdFPJAJMmTWLEiBEULFgQgFy5crF9+3b27dtHhw4dzHCJiYn89ttvJCcn891337F06VLKlSuHpmns2LGDBQt0Zcfs8vBvRktISFClo1AoFIpbgqZpzJo1y9Q/mD17Nk888QS5c+emZcuWzJ8/H4yBWcvkC6tyG2LkyJF88MEH1K5dG5vNxpkzZ5gzZw65cuWiefPmhIeHk5SUyMCBb9CnTx+8Xg82m51NmzbRokUL8ufPT3BwMLVq1eKtt95SHyq7CbT4+HhVQgqFQqG4JWiaxo0bN6hTpw5nzpyhadOmVK5cmYkTJ7J+/XqqVq2a7cBstbp4+PBh1q5dS+HChWnWrBnBwcEAXLt2jRUrVnDPPfeY2wuSsWPHMmbMGObNm0ehQoVo2LAhJUuWZNeundhsdo4ePUrx4sVxOBzZ5uXfihIOFAqFQnFL0TSNSZMmMXz4cPNaq1atmD17NtzErD2QPQK54pAVjz/+OOvWrePYsWPky5ePOnXqcOzYMS5fvsyGDRuYMGECCxYsgJvIy78NpXOgUCgUiltO586diYqKMv8eOPB1uMnBWJ6EkPdY/xXG58v9wyQkJLBu3TrKlCljGlkSQpi/P/nkkwzKi4qMKOFAoVAoFLec6OhounTpAkDTpk2pXr0GZLIakBMCCRX+RyEB8/hkmzZPm9feeOMNkpKSaNKkMblz56Z///6WOxSBUNsKCoVCobjlaJrG2bNn6du3L2+++aaPmeNAA/2tQNM00tLSOHHiBCVKlCA4ONhUUjx79izHjh2jfv0HsNns5vbE7crL/zra9evXVckoFAqF4pYTaJXgdg/G1jS9Xg8YX460crvz8E8g45qMQqFQKBS3GKtewO3EqoOgaTY0zWame6fy8E9ACQcKhUKhuC1YB+q/mr9DHv6XUMKBQqFQKBQKH5RwoFAoFAqFwgctLi5OrbUoFAqFQqEwUSsHCoVCoVAofFDCgUKhUCgUCh+UcKBQKBQKhcIHJRwoFAqFQqHwQbt27ZpSSFQoFAqFQmGiVg4UCoVCoVD4oIQDhUKhUCgUPijhQKFQKBQKhQ9KOFAoFAqFQuGDdvXqVaWQqFAoFAqFwkStHCgUCoVCofBBCQcKhUKhUCh8UMKBQqFQKBQKH5RwoFAoFAqFwgftypUrSiFRoVAoFAqFiVo5UCgUCoVC4YMSDhQKhUKhUPighAOFQqFQKBQ+KOFAoVAoFAqFD9rly5eVQqJCoVAoFAoTtXKgUCgUCoXCByUcKBQKhUKh8EEJBwqFQqFQ/GMRgLD8J69k7ZRwoFAoFArFP5J0wUDTQNO0nLtLly4phUSFQqFQKP5x6IKBV/OShhs3HjRsgOYTJhD/D+/O1992g40nAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"self_attention.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb3cef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE 1:\n",
    "    # Attention is a communication mechanism, where we have a number of nodes in a directed graph where you basically have edges pointed between nodes like.\n",
    "    # What happens is every node will have a vector of information and it gets to aggregate information via a weighted sum from all of the nodes that point to it. This is done in a data dependent manner.\n",
    "    # So depending on whatever data is actually stored that you shouldn't at any point in time. \n",
    "    # Our graph doesn't look like a simlpe directed graph.\n",
    "    # Our graph have 8 Node because our Time dimension is 8.\n",
    "    # The first node point to itself.\n",
    "    # The second node is pointed by first node and the second node itself.\n",
    "    # The third node is pointed by first, second node and the third node itself. \n",
    "    # All the way up to 8th node. which is pointed by all the previous node and itself.\n",
    "    # This is the structure our directed graph has or happens to have in Auto-Regressive sort of scenarios like language modeling.\n",
    "    # But in priciple attention can be applied to any arbitrary directed graph and its just a communcation mechanism between the nodes.\n",
    "\n",
    "# NOTE 2:\n",
    "    # Attention has no notion of space, so attention simply acts over like a set of vectors in this graph and by default these node have no idea where they are positioned in the space.\n",
    "    # That is why we need to encode them positionally and sort of give them some information that is anchored to its specific posiiton so that they know where they are.\n",
    "    # And this is different than for example from convolution because if you're run for example a convolution operation over some input there's a very specific sort\n",
    "    # of layout of the information in space and the convolutional filters sort of act in space. \n",
    "    # So it's not like an attention, In Attention is just a set of vectors out there in space they communicate and if you want them to have\n",
    "    # a notion of space you need to specifically add it which is what we've done when we calculated the relative\n",
    "    # the positional encodings and added that information to the vectors.\n",
    "\n",
    "# NOTE 3:\n",
    "    # The elements across Batch dimension which are independent examples never talk to each other and they're always processed independently.\n",
    "    # In our examples there are 4 batches and 8 nodes so 32 nodes in total. But only every 8 nodes talk to each other not the whole 32 nodes talk to each other.\n",
    "\n",
    "# NOTE 4:\n",
    "    # In language modeling we have this specific structure of directed graph where the future tokens will not\n",
    "    # communicate to the Past tokens but this doesn't necessarily have to be the constraint in the general case and in\n",
    "    # fact in many cases you may want to have all of the nodes to talk to each other fully. \n",
    "    # So as an example if you're doing sentiment analysis or something like that with a Transformer you might have a number of tokens and you may want to\n",
    "    # have them all talk to each other fully because later you are predicting for example the sentiment of the sentence\n",
    "    # and so it's okay for these nodes to talk to each other and so in those cases you will use an encoder block of self\n",
    "    # attention and uh all it means that it's an encoder block is that you will delete this line (wei = wei.masked_fill(tril==0, float('-inf')) of code allowing all the nodes\n",
    "    # to completely talk to each other what we're implementing here is sometimes called a decoder block and it's called a\n",
    "    # decoder because it is sort of like a decoding language and it's got this\n",
    "    # autor regressive format where you have to mask with the Triangular Matrix so that uh nodes from the future never talk\n",
    "    # to the Past because they would give away the answer and so basically in encoder blocks you\n",
    "    # would delete this allow all the noes to talk in decoder blocks this will always be present so that you have this\n",
    "    # triangular structure uh but both are allowed and attention doesn't care attention supports arbitrary connectivity between nodes the next.\n",
    "\n",
    "# NOTE 5:\n",
    "    # thing I wanted to comment on is you keep me you keep hearing me say attention self attention Etc there's actually also\n",
    "    # something called cross attention what is the difference so basically the reason this attention\n",
    "    # is self attention is because because the keys queries and the values are all\n",
    "    # coming from the same Source from X so the same Source X produces Keys queries\n",
    "    # and values so these nodes are self attending but in principle attention is\n",
    "    # much more General than that so for example an encoder decoder Transformers uh you can have a case where the queries\n",
    "    # are produced from X but the keys and the values come from a whole separate external source and sometimes from\n",
    "    # encoder blocks that encode some context that we'd like to condition on and so the keys and the values will\n",
    "    # actually come from a whole separate Source those are nodes on the side and here we're just producing queries and\n",
    "    # we're reading off information from the side so cross attention is used when there's a separate source of nodes we'd\n",
    "    # like to pull information from tha source into our nodes and it's self attention if we just have nodes that would like to look at\n",
    "    # each other and talk to each other so this attention here happens to be self\n",
    "    # attention but in principle attention is a lot more General.\n",
    "\n",
    "# NOTE 6:\n",
    "    # Refer the image.\n",
    "    # Scaled self attending.\n",
    "\n",
    "# NOTE 7:\n",
    "    # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437f092",
   "metadata": {},
   "source": [
    "## Self attention added code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549414eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.3263, val loss 4.3209\n",
      "step 300: train loss 3.0875, val loss 3.1149\n",
      "step 600: train loss 2.9221, val loss 2.9380\n",
      "step 900: train loss 2.6395, val loss 2.6416\n",
      "step 1200: train loss 2.5518, val loss 2.5447\n",
      "step 1500: train loss 2.5003, val loss 2.5032\n",
      "step 1800: train loss 2.4662, val loss 2.4752\n",
      "step 2100: train loss 2.4606, val loss 2.4679\n",
      "step 2400: train loss 2.4377, val loss 2.4557\n",
      "step 2700: train loss 2.4422, val loss 2.4528\n",
      "step 3000: train loss 2.4343, val loss 2.4273\n",
      "step 3300: train loss 2.4149, val loss 2.4327\n",
      "step 3600: train loss 2.4182, val loss 2.4227\n",
      "step 3900: train loss 2.4050, val loss 2.4295\n",
      "step 4200: train loss 2.4065, val loss 2.4142\n",
      "step 4500: train loss 2.3942, val loss 2.4040\n",
      "step 4800: train loss 2.3989, val loss 2.4021\n",
      "\n",
      "\n",
      "IUbree, I tt ors the,\n",
      "Hinlere Thad famy th th mith, chere amprast wim; mewinorof yofou huref ht t; ce isthe.\n",
      "S:\n",
      "OMus sa od,\n",
      "LINou st prth hay fiere how,\n",
      "T:\n",
      "IT: et wow bam be ougr ow ca ter ay fo ch de fol:\n",
      "Bu kl aveirdet-latanel ame hemy wilef an, fou torf, lf, nadXLHindy fo, have rdot:\n",
      "Tho kthe lelobed med thilikes.\n",
      "\n",
      "Anou per bullestasun icely pr.\n",
      "\n",
      "fr reefiughe praller areg te ou sTakepe Mad al Athan yowrus is rcon, hanco many ior lpshy t, the tal, ads agoe ithe ds, mecrte mfod pis frofy der a\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # perform the weightes aggregation of the values.\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.sa_head = Head(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.sa_head(x) # Apply one head of self attention.\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2195e7",
   "metadata": {},
   "source": [
    "## Multi headed attention code added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c945ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.3016, val loss 4.2970\n",
      "step 300: train loss 2.8283, val loss 2.8341\n",
      "step 600: train loss 2.5938, val loss 2.5937\n",
      "step 900: train loss 2.5009, val loss 2.5000\n",
      "step 1200: train loss 2.4624, val loss 2.4561\n",
      "step 1500: train loss 2.4174, val loss 2.4202\n",
      "step 1800: train loss 2.3842, val loss 2.3911\n",
      "step 2100: train loss 2.3725, val loss 2.3773\n",
      "step 2400: train loss 2.3519, val loss 2.3690\n",
      "step 2700: train loss 2.3452, val loss 2.3598\n",
      "step 3000: train loss 2.3373, val loss 2.3309\n",
      "step 3300: train loss 2.3161, val loss 2.3359\n",
      "step 3600: train loss 2.3102, val loss 2.3181\n",
      "step 3900: train loss 2.3007, val loss 2.3173\n",
      "step 4200: train loss 2.2934, val loss 2.3061\n",
      "step 4500: train loss 2.2801, val loss 2.2903\n",
      "step 4800: train loss 2.2745, val loss 2.2814\n",
      "\n",
      "\n",
      "IUSS: now to or nrour:\n",
      "Wheere you for hyou themiin, corent hof sef sont mes iphy Poon Yourefrrt thare isthe.\n",
      "Sy own lovery, len wand prou hay fiere how,\n",
      "Whimen erow with the ouge ow ca ter ay for whit fol:\n",
      "But low, is\n",
      "Ot-y taielle!\n",
      "Cow, While dan, lou torfrill, nadXRHinty fors mat root:\n",
      "Goo kthe lall.\n",
      "Thigh thillkes.\n",
      "\n",
      "Ive lo, hing eotasuo is my prou frereefiugh, pralle bereg thou ounckepe Mar:\n",
      "Yerelfely brus is rount hours many ish las you, thert lous.\n",
      "\n",
      "Boresit wirn, mourte mond pive; of ther a\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # perform the weightes aggregation of the values.\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultilHeadAttention(nn.Module):\n",
    "    \"\"\" mutiple heads of self attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x)for h in self.heads], dim=-1)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.sa_head = MultilHeadAttention(4, n_embd//4) # i.e. 4 heads od 8-dimensional self-attention.\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.sa_head(x) # Apply one head of self attention.\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3bde7",
   "metadata": {},
   "source": [
    "## MLP added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e15259e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.1778, val loss 4.1788\n",
      "step 300: train loss 2.8120, val loss 2.8172\n",
      "step 600: train loss 2.5690, val loss 2.5662\n",
      "step 900: train loss 2.4688, val loss 2.4658\n",
      "step 1200: train loss 2.4251, val loss 2.4173\n",
      "step 1500: train loss 2.3806, val loss 2.3793\n",
      "step 1800: train loss 2.3444, val loss 2.3507\n",
      "step 2100: train loss 2.3286, val loss 2.3332\n",
      "step 2400: train loss 2.3051, val loss 2.3203\n",
      "step 2700: train loss 2.2904, val loss 2.3056\n",
      "step 3000: train loss 2.2901, val loss 2.2742\n",
      "step 3300: train loss 2.2637, val loss 2.2829\n",
      "step 3600: train loss 2.2540, val loss 2.2629\n",
      "step 3900: train loss 2.2410, val loss 2.2566\n",
      "step 4200: train loss 2.2421, val loss 2.2562\n",
      "step 4500: train loss 2.2212, val loss 2.2341\n",
      "step 4800: train loss 2.2134, val loss 2.2333\n",
      "\n",
      "\n",
      "I bree, I to or I' amencell et.\n",
      "Bur ame thy hame it, here ampfarst shat mestiroy your Yourefy. Whar,\n",
      "Nitthelbfy owus sa of alence ithis of to fiere how,\n",
      "Thime: eore with the of my wheanter ay for whit fol:\n",
      "But low, is\n",
      "O ENIS:\n",
      "Whis krow, Whiles and for tor sply, nadsterety forshave rint:\n",
      "Tho kiseterlobs.\n",
      "\n",
      "GENLALO:\n",
      "If farvailf, his lettas of closty may arrestiand, prallesberelfie ou sTake hast tale thas your you srous, soncond.\n",
      "\n",
      "JIUENCY EN:\n",
      "Thissht lelads agondit.\n",
      "\n",
      "GCUD Chat lefod pis frofy tho b\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # perform the weightes aggregation of the values.\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultilHeadAttention(nn.Module):\n",
    "    \"\"\" mutiple heads of self attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x)for h in self.heads], dim=-1)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # This is a token level and all token will do independently.\n",
    "        return self.net(x)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.sa_head = MultilHeadAttention(4, n_embd//4) # i.e. 4 heads od 8-dimensional self-attention.\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.sa_head(x) # Apply one head of self attention. (B, T, C)\n",
    "        x = self.ffwd(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab824d",
   "metadata": {},
   "source": [
    "## Added Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c701ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAAHoCAYAAACo6RjPAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAP+lSURBVHhe7J11vBVFG8e/G6frwqUFFBUVMVBB6UZCFFEULEAxXjGxO7C7EwWkMQkVRQUBwQIEC4OUrpunz+7O+8eePfecc4MQLiD35+eRc2dnZ2dn5zfPxDPPSIZhCKpQqZAkKfX7scce46677sq4bmHq1KmcddZZCFH1iaoAcnZAFSoXH374YXZQCmPHjoUsclfh4EUVWfcBLE05ffp0Fi5cCIDX601dz8nJAeD999/njz/+SIVX4eBGFVn3ASxN+fjjj9OkSRPmzp1Lu3btUtd79erFpEmTyM2tzptvvplxTxUOXlSRdR9h48aN/O9//+PHH3+kXbt2GWRUFIX+/fuzbNkftGzZkkgknHFvFQ5OVJF1H0AIQd26dbnkkkvweDwAGIaRup5IJACoWbMm559/Pi6Xu2qSqQpVZN1XEELsNAF3Nl4V/tuoIus+hBAl2rQ8VBG1ChaqyLoPIUklxZ/eDU5H1cRSFSxUOlklSaqSNLGgKErqt6qqqd9Uldl+KdZ3qUxIe9uCqaIXisViqUoqy5nxdpSt7PjZ2N/vt6AoCrqu06NHD7766isAzjvvPCZMmEAiEccwRMazLG28oy50utauwu7DKmen01VuXa6socpeI2v2iy1dupSlS5fwyy+/smnTJjZu3EgkEkldT3/hnX357GdYOFDuNyeZDAxD8Ndff1FUVARAjRo1OPLIIxFCoGkalPGsHT0jO34Vdg9WOefk5FCzZk0OOeQQjj76aE477TSOP/74jHLe0Tf5t9grZLVeYMuWLUyYMIF3332XX375hWAwmB21CmmQJAlZltF1PftSFfYzuN1uTj31VPr27cuAAQOoVasWpDXAe6VnYxiG2BOi65qwsHnzZnH33XeLhg0bCqBKdlJkWRaKopQKr5L9W+rXry/uvvtusW7duhQHDMNI/bunZI9pVkubjhs3jrvuuou1a9dmRwGgdu3aHH300dSvXx+n04ksl90CHSzdOEmSEELw6aefsn79egCOOeZounbthq7r5Y5Nd9Ryl3dfFXYdhiEoLCxk48aN/PHHH2zZsiU7CgB16tThvvvu4+qrrwZMLWt93z2CbPbuqlgoLi4WQ4YMKdXqAKJp06Zi2LBhYurUqWLVqlUiGo2m7quCiV69eqXK69JLB2dfrsI+hq5rIhqNiuXLl4v3339f3HbbraJZs2al6jog+vXrJ7Zs2ZK6N5szuyv/SrNa2m/58uVcfPHFfP/99xnXmzRpwrBhw+jbty81atRIhcfjcQzDSGqO3X78fwI2mw1ZlunTpw8zZswA4JJLLmHMmDHEYrHUBFMV9i1kWUKWFex2e6reb926lSlTpvDKKy+zdOnPGfGbNm3K+++/zzHHHANJLftv8a/Junz5crp27cqaNWtS4Yqi8MCDDzD06qFUr16dRCKBYRhompbKtCRJGIaxR17iQIbNpiLLCmeffTafffYZABdffDFjxowhGo2gaVWTTfsbpORaq91ux2azUVhYyFtvvcXDDz9MQUFBKt6hhx7KlClTaNasGewBwlY88KkAkiSxbds2+vbtm0HUBg0aMH36NO65+x5ycgIEg0Hi8XipJYh00h7cIiMdJOPz/wrMGV9BNBqluLgYn8/LzTffzJQpUzjyyCNT8dasWcPZZ5/N8uXLM+7fXewWWa3KddFFF/Hrr7+mwk8++WRmzpxJz569CAaDhEJlb+2qqpxVONCRriVDoTChUIgOHTowc+ZMTjnllNS1NWvWMHjwYNgD9X6XyWo98MEHH2TmzJmp8CZNmjB58mSOOeYYQqFQRtydQbq2qQyU1nCZsq9h5qNK65aH7O+1p2VXYRgGwWCQRo0aMXHiRI4//vjUtfnz53PPPffALnIiG7tMVoDFixfz0EMPpf72er289dZbHHnkkYRCIWQ584V31FfPLqidEROlJuJ2SrLT2h+kIkhJY4kqKRGS9ao82RcQQlBcXEzjxo2ZOHEitWvXTl177LHHWLRoUTLe7i2r7dIEk1WpBgwYwOTJk1Phr776KldffXXKo4FhlC6w7AopkmtQqqqiKErK/nVnbV9N4v0bVEyQf5/+jmA+X5ZN2+gzzjiDTz/9FICBAwfyzjvvpGJaZbUryC7/Aw26rqPrOpqmYRhGme+/v76jJEl4vV7Gjh3LwIEDU+G9e/dm+vTpsJt532myCmEgywoLFiygXbt2qS1d3bp1Y9q0aSiKgqYlyiQqaWS1Kp7lIaGgoIBwOEwsFktdT49fPkSyvpd+FoDY4WvtqFNhaeLdhyRLZebDbJDM97Maq8GDB/PFF18AcP755/PKK68QiUTKNT0sq4x3Bf/2/r0Nl8uF3+/H4/EghCAUCu33eU6Hqio4HA7OPbcfU6ZMSYVPnz6d3r1779a77DRZy9KqTqeT2bNn07JlS4LB4E5pAJvNhsPhYPbs2bzzzjv88ssvbN68mWAwiLTL1h7lE2rH6Ug70K7W/TtKp2zsqByyG4tIJEI8HkdKLgk4nc6M69nYcfoHLoQQ+P1+6tWrR8eOHRkwYADNmjVL1bEDAdY7fPvtt/Ts2ZPCwkIAzjzzTKZNm5aKsyvYKbJaFeO3337j1FNPJRw2u7v9+/dn4sSJhMPhlKatqBLZ7XbsdjtPPPEEd99zN3rVGmIGJAl28fsdFMjNrc5LL73MBRdcQCQSPiDWnoUQKIqCx+Ph8ssv5+2334bk/M78+fM54YQTdpmsO+oLZmDBggUpogJccMEFSEnjBnZAVEWRsdvtPPjgg9xxxx1VRC0Du/jtDhps357HRRddxMSJE3G53Eg7MSm3r5HOi759+6bCg8EgCxYsSIu589glzXrllVcyYsQIABo1Ooz58xdQu3YtQqFwuYVndW29Xi/z5s2jffv2GddPPuUojj32aBRVKWdS6d91RytG+d3oki5y2e+1p7CjMXp517P//i9BkW3EYgYL5n/PqlUbU+F16tRhwYIFNGjQIGMv9P4Mp9NJYWEhHTp04Pfff4fknIQ1lNwV7brTZE0kEnTp0pl5874B4Nxzz2XixIkYhpFynVkeFEXG5XIzcOBAxo4dm+ru3XDjEB56+E58HjeCOAIdCSmLQBWRNZtQFcWtCGXdl5529nP+LQSizIYiO/3yrxuU1bCRyq9cKq09gbLKac9DwoaEg81b8rn88qF8PH1O6tpzzz3HjTfeeMCMX2VZxu12M2jQoNRxKE2aNGHRooW4XG7YBcLuNFnXrVvHaaedxoYNGwB49NFHufPOO3dqls7pdJKXl0ebNm1SplenndaML76ahs8DxZGtgJGsBOlpVVQ5LBLJWcs9VhrZaVUMSZZKa3ZRFmGTITu9xAQgpWaAzY3JEkLoZCjHVHuT/CGl59+aVS7JR+a7psOMU7KFLvv6v0FF32PXUHGdUUDY8Xvq8feKFbRp3YWtW0xNeu655/D++x8QjUZ3qCT2F/h8Pp5//nmGDRsGgN/vZ+HChTRu3HgH5ZCJnR6zbtu2jby8vNTfDRs2zLheEWRZori4mGg0mgo7sdlx+DwuikLb0fVYUuJZkkiKVkrMXTsGsVgCr9OP11kPm+pE1yQMwxwvGIa+QxHCQAgDr8OPx+lF1wwMXZhiGGWmo+sabqcLr9Nf6lp5AjIepw+fqy5eZ3WcTjdCgK4nn6HrGLqGYSRM0bVkmI6e3ADhc+XicwUQwqzsJaKniYHfXQ2vy5MsqwS6Hi9J91+JlpTS77dnJYEhooRim6l3SA2ObVpibxuOhIjHY3ukwagMWMOVBg0apMIikQjr1q1Li7Vz2CFZrYfl5W1PrYUCBAKBtFg7hizLGR783G4HYFawEq1almYsS5Its5ConpPLV1/PZtgt/+O33/7A5fKCKFnH3BFkxdTMTz77FOMnTsLpdFe4sVuSJFwuN+998D6vvPEyimJLGTaUzqcpTqcLRVaZMGkyQ668hNvvupU///gbnyuAJClJ8pmNRllit9vZti2Pm28fxqixY/C6A8iyLe0dJUCgqAqSBM+//AwTJk/E5XIlrX3Kqtil81kZYr1Tdnhp0REiAeiotpLvIUk7P16XZRmbzbbT8fcmLLsCAE3TiEbNnsKu5K38WpmEpaZjsViGyrbb7Wmxdgxroin9bwNzRtgQRlIEhjWhsiMR4LDbkYCHhj/E889MZfSod3CobhRZRRjW7GqpOzNEVWxIksJzz41i6pRPcKpeQE5qrHTSiNQ9DsXLtKmf8NxzLyFJKrJsy9J0JaKoKomExjXXXMf//ncvK1as4tNPZ9K58zlM++RTvG5fWtplw2lzkre9gGefnM5lAx/h228X43NVT95T0jApstnwPPPMm4wZMxa74kRWlLTGx3pv63flY1cqJ8lemZLmTUQIgbQDz5KqquDz+fB4PASDwdSOr/T6V1mwnhkIBFKcEUIQDJr287uCHZLVQkXaZndhTiZl02cnCjVJQqfDybx589iwfj3n9juFD97/mFWrVuB2eVKpWaQxYYZJkpISkEHIVMtx4vPlmElnwTSol9MaAIHX68fvyzHHmBU0Cl6Hj/fefZdRo+YwccLLfP3V9/yy5Fe6dmnNjTfeRH5BAQ57xQYQApBlFW+yM3PLLXcQioRxOsyGxXyW+a8E5AQUvB4/AglJWHmx4kkospr8niVh6ZBSSyPm2NeS7HeTJDktrfR0Kr5vV1CeRVw2pKQxic/nw+Vys3LlSu6//35GjhyJx+Mp1564MiCEwOFw4HK5UmGWae6u5GHPM3AXYM6IlkASJVIxJBRZQcLB22+PpHHjo3jppZcoKoIJEyciSwqyJCfTksz0DIEiy/g8PvzuGvjdufjdNXGqXmRUZFQkoZjzqMKs5LJkxg94qhHw5JLjq47f4wdsmXGxnpMpiqwAKt/Mm88Rh0v07NGdhJ4POLj4oovYsB7W/rMWp92BLCXTKUcMXUeR4cZh57Hs9zXcf9/DOFQ/kpDN0YMBGBJysgEy86cgWe8lJOyqnYCnGl5XLn53bQKemnjdXrOsrKZTCLxuD3abDVmS8LsD+N01cdgdSEj4PX4UWcXldON35+J1VcfvNtNJ9ucJePzJMjbL2eX0gCGl5qh3ja6ZsDSzRTZJkvD5fHi9XoQQfPbZZ1xyySU0bdqUJ554gi5dumCz2VAUBZvNNO1MF1U1xSJzWc/a1d5AOtLTSE/HmtfdlbRL57DSkcz0DgmaCZfbxfoNq5k5cwHnn9+funUac/rpJ/HRhx8SDBVjs9lTrycE2O1OvK4AP/6wmDvuuo0BFwzg/gfu448//8TtykGW1JJqJMy1Pr8nlxUr/uGJJ5/iwosu4MabbkwuXbmxqXZSE8Hl5d0QgEGTJk3Yslmwdu06bIodUFiyZCkBH9SsUdPspglRiqDpFVsYgnAIunXtygP338IzT0/iyy+/wO+tgRBShpY0tamcnFWVEULG6w2gKg6mf/wxV141hPP69+WxJx7hjz+W43Pnoip2FNmGocPLL7/G0p9+xeeuwceffMoVV17KV19+jYzK0qW/4rC52bh+G8Mfeoj+A87nrrtv568/VxLw1iHgrcXXc+dz9TVXccGF/Xn9jdcIFoXxenOSjYaVz92DpYlU1Ybf78fr9bJ+/XpeeeUVOnfuTM+ePRk3bhzRaJThw4en9pY6nU5cLjcejyclbrcbp9OF0+nC4/GkSJ+uhdP/3RvYlbT3A7JSQW0vG7IsoUheJk6chCxD586dAZ2LL76YRYu289NPP+F0uJKvJ2O3O1FkG9ffMIxOnQbx7YKFJBKCeXMX0KPHmYwZOxafL5CsRIrZ5fRUZ9TosZza/CzGjX2PYDDK33+t5OKLr+T+B25BUVVUtWTCrCwYQhBPhLns0suoU1vlkYcfBaozb95nPPXkm9xy61AOqVffnLjbQRFIkoRhQDBUxI033kzz5rW5/PLLKSgswOP2I4RkKjZDSpFXCPMev68aW7cU0rNnHwYNupVVq9YhDJnJk96nTet+vPjSy7icAWyqG1VxMWHC+yxe/Du33HoHAwfext/L1+B2B9i4MY9Bg65k5MgJnNn7fGbN+haEg0mTpnDqqeew4NuFvPjiCK4degvr120jGIxz550v0KFDNzas34rL5ccQCghltwmrJRKoig2bzcbcuXO59tpradmyJddeey3ffvttKp7dbmfBggVcccUVDBw4kIEDBzJo0KAMGTx4cOr3PffcwwcffMDatWtTxLXZbBnP/rfYFWKWiWwPamWJEEJ8+uknIskqAYjPP/9cCCFEMBgUxcXFFYqua2LVqlUZfoSH3XS50MV6URD8QeQVzRH5hSVSUDy3QglFvhex+BLRvmNdcdX/ugkhVot4/C+xdeuPomFDxFX/6y6EWCWKg4tEUfH3Qoi/xTPPDRWAePXVW4UhVgoh1ghDrBST331CHH98QHi9iGuu6SOEWCWEWCXmzhstAPG/q3uJ4uJfhRD/CCHWiIWLJotupx8pDqmPaN/hUBGO/CxC4cWioOhbUVC0IE3mp34LsVr88ONkUaMm4vzzW4kmx/rEPfcOFJq+XITCS0VR8feiqHiBKAp+k5R5GWKIX8SPCycI1YYYOepeIcQ2sXDRe0KSEFcP7SmE+EcUFf8oQpFFIhhaLI473iXO7ddCGGKNSGh/Ck3/S3TufISoUwfx48L3hBArhBD/iIT2u7j7ngECEBMnPSKE2CCKg0tEnz7Hixan1hJduzUWS3/+SAixUgixWvz62zRRqxaiybE+MXHiU0LTVgkhNoht2xaKU06pLRQF0bnzMeLv5bOFEJuFEFvEkqUfCrsDccONZwshVoui4h9FQdECkV/8jcgvnluOzBP5xd+I4sgiEYwsE926l3gR7NK1kxgzZrRo376dkKTUYrSQJEkoiiJkWf5X/pcPOeQQMXToUDF//vyUd8KioqLdluLiYmEYhli8eLEIBAKp54waNWqXPR/+a82aPWDf2dZDksxRktWXl+QS2RHcTi8Lvv2BhT9upF+/8xFANBqlRo26XHTRhbz//uds3LQRh8ONze5k/Ya1PPLwq9w4rC9XX30dkUghBUUbCYfzOP+8gQy76TqCQTBNOe0INO6/bzinnlaHl156HpfbRnFwC8HQVk45uRXPPf80G9aDnuF5MP2blyxFuZxOIMbKlauIhOHdd7/lkksG8tDwV4lGw8RiEWx2O7KiJie8SmDNjovkkgeAWT/zOeXkU3ju+aG89uoM3n1vAj5vbhkaS6AqfsaNG8esWSuYPHk0zU9pTSSWTyiyEVnRefihx+h7zvE88vBjRKJFOOxutufls3LlFt54/VVOOL4ZoXAeBkFUFbZuhe7dT2fAgMFEotspKFpNbm5trrzqMnQdrrhiCEcecSzhyAai8Q2ceEJL+vVryYIF80loMdSktpIov9tfUQ1QFZVYLE4oFM6oa9bv7LHhrmL9+vW8+uqrdOzYkUsuuYQ///wTn89X5pi2srHbOaioQHaWsLsDWTK7eGPHjKd9uyZ07XI+Ejn4fHWAXK4eei3RCEyb+jE2NYDT7ubHHxdh6HDZZUMwRJhYPIwQCeKJCAltCz179qBGDXP9C1Q2bFjPz7+s5NLBl6IqbsLhIIYw0PQEofAWmjY5lo4dGxG27FNTRWGR1fztcjkxhODSywZz1VV38OprD3HVVWcwYsSbrF+/FLfbg64L8vMKSSS0jGpqLWGVhsBAIxzdxtChV9K+wyHceOMdbN6yCbfLm7ZcJZBQgDATJkzgtJZ1aN2mFdH4JnQ9CuiEw8WAztChV/PnX0Hmf/MtNpuTWCxG794dOPzwJgRD20hoMcAgocXJyYHu3bsDhWh6FNCAIC6Xk5wcaN7iFDS9kIQWQ0tEgWK8XjfhUBhdN5JWW6KkmHYRsqxw+eVXsGDBAj799BMGDRqUcnNrbVg3DANFUTjxxBNo2bIlzZs3L1NOPbUFzZs35+STT85wlUvy9Plx48bRs2cPvvzySzwezw6HPXsbe4WsexMul5v1G9YyZcocNm/ZzqOP3s29997MPffcwf33X8+bb7xFOAzvv/8hmhYGPCxb9ie1ajmpV7cu8UQiI+8JLYHH46ZGDV9Se6ls3LgRLQFHHHEEAtMQxFzDtHZSqDRo0CC1q6IsmDONdm677Tamf/wtn3wyioGXDOXlV56jerUAZ57VBwkbW7cUcmbvvvz153LcbtNWtCxIspQyCJCQSCTi2FSFN954lW3bSJqy2VFVe5p+kgmGgqxcsYJWrVqhKm60hGkNZRimz+aEFqRJkybUqwsbN20EJOw2O0cffQxgxrXKSwiBw2FO1hhklqOua1SrrmK32zGyNswrioq2h3xEG4ZONBpFCEHPnr0YNWoU3333Hc888wwnnXQSJPMZj8c599x+fPvtt8yePbtMmTXL/HfOnDn88MMPTJo0ibPOOivjeatWraZbt26MHj0al8u9Twm722Td6xAk1zCtdUzzb1X28fnnMwmHwOfzMmPGx8ye/SVff/0VM7+YwbxvvuaUU2rz/Q9/sHjxT4AvRSqzsmRWGCFMc7+0EDMsFc28RwjDXF6RSHZzy4csSTidLr7//gdef/0rXn31Idq0Pp3C4pUoCkyb/hHbt23jssuG8Ntvf7ByZT4ulyfLiKN8SEjIskRhcQHHHH08r7xyKxMnfM/48aNxOmqk2TSDJKVracugIO26LOF0OpMkS76XZJKvLIikqWNZEIYoSQPrMVYXvux7ykbp75SNRCJBYWEhsViMI444gptuuolZs2Yxffp0Lr74Ymw2G4899hhLlizB6/XicDhS+6ktsRwhOBwODj20If379+eDDz7giy++oE2bNhnPu/TSS5kyZUpqi96+wP5J1oxKmxQBdrsDXUR544236NrtWOZ8PZs5cz/j6zmf8PWcT5g37zO+nv0ln30+FZsNJk2eCEgcduhhRKNRwpEQiiyZlTY5tpFlGU1LEAqFUBQVSODzeVEVKCwsREJNs7AykBUZEITCIWxZhx5bMIRAlZ0s+WkJgQC0PK01mp4PGBQVF1CvbgPe/+BdPp/5BZcNuZHOXU6jceOjicUSJUSroK4KRNL+WRCKbOWKy4dwdt9juf6G+1i9ehlujy9ZbgYOh42aNXPZtGkjoGUZKoAq21i7di1r/olTvXq1tPF22RBiV3pVVkO3O1rVImzZ91l5iMfjFBUVUVxcjMvlonfv3owdO5aFCxdy2WWXMXPmTGKxGPF4nFgsVkqi0SjRaJRQKEwwGETXdbp27cqnn36a4T8J4IorrmD58uV4vd6M8MrC/knWUtrF/NvlcLNg/vcsWVrAoEGXADrRWDHxRChNCsitXotzzunEu+9+SCS6mhObNWPjJvjh+++xqTkZ2sHlyOGPP/5k7VoDm00FNGrVqkWNGjZmfDYDcGBL61q6nT6CoSLmzV2E3W4v07LLHFfrKKpKNAKRSBRVcUHSoioYyqNF8+5cf901FBdBi+an4nTURNeMZMOU/f7ZMK9JkkQ8HkMXMV586QU8HrjiyisJhyLYVBugoSpuTj+9G59//h1r163F7ayGMMwlHVlWAS8ffTQFjweOO+5YNL0sI/nySbNjVEy6PQUhBLFYjKKiIkKhECeccAIvv/wyl156KZFIBCN5+oMlZcHqPhcXF+P1enj77be55pprUte3bdvG8OHDIemeqLJRuqbth5AlOWmZ42DMmLEcdqhEt9O7EQrnk0gk0kQzbZiJctHFF7J+HUybNp3jmnaie/fjufba21i7bgXVAo2pFqhPjv9wNm9dx5133gWAosqATvVqNRk46BJGvv0lM2dOxe06lICvDgFffcDGnXfezZYt4PF6MYyyPV4k9DgdOrRHkmH4cNNta8BXhxx/Pbyeenz73aeMGjWKatXguedeYuGiOeaMbsq4oTRMrZb5ySTJ3NHU4JAjefXV5/jyi7/49dcCXG4XAgNIcPkVl2PopHzX+ryHEfAdisfViG/mf8HwBydwySW9adToSGIxc9Is09jehDDSJojKgTmjLycbrBIYeokB/05M+O8UytPwuq5TXFxMMBjE6/WgKEopgqYTtywpLg4iyxKPPvooHTt2TN03btw4Pv/88x36yNob2IdktbRHmlhj1CwYQuD2eFi+chlvvz2XM888g4AvB01PlKo4hjCIxiK0bnUaxzRReeihB4F8XnrpBfx+lRYtOvLEk3cxdvxbPPbEHXTq1Jljjjmadu0bsnnzBsAgGg8zbNgNDLjgVM7o/T+uHtqft0a+ytPPDKdtu5YsX76ca6/rRUHBdgwja19qMr/RSISjGx/NM8/cwoTx39G8xUk8+/zjvPX2Kwy9ZhDdul3AKc2b8cefP9K8xXGcccb5/PzLQlwuF5KcJGyyPCQkdC2BloBYPIJUBlmCoS30PuNMht1kuhApKspDwiAULqRh/cN4971XmDp1Hi1bncqLLz3MO2Ne5dbbhtCp0xDO6H0Ud955G5peDBgEg0VEo6G0LrH5PCEMtueBrseSeSjJRywWoaBQT3a107vSEuFwkIJCHUkSKRLLspx8P9M2u2R+Ir1OWP9kvm95JE2HEOYWx0RyQm1XIUkSwWAIv9/PI488kur6CiEYMWIEhqFXunZV7r///geyA7MhSRLLl//N+PETUmEDBw7k8MMPJx6PZ8S1kF6gNpuNgoJCRo8enfLy1rLVyfTo3oVYPGh6iBBkkTcTqqqycuVyqlXTGTR4IP6AB10va/OxhDAMHE4HRxx5OLm51Ti6yZHUr3cYF1x4PkVF25g0aQJTp85j44YVXHnlldx37z24XA5OOKEpRx55GOFwCFVVOO+8c6ld286nn37MRx99xd9//8zpp3fjueef5dBDG1K7Vg2aHtcUhJHc6lcCAWh6glanteT0Hqfw999/8/7705k58xvC4e08OPxm7r/vbnxeH506tyEay8fjcXFU48boupbUQsmySI6vAzkarVu3pGat3OS7l1RCQxjIssFppzXH4QrSqXN7GjduhKbFicZCNG1yEmf37ciSJT/x3nvTmTHjG7ZuW8vtt1/JE08+jtPlIBwJIWFQrXqAE088jrr1amAYWsqGW5Kgdh07rVu1wOW2JyehTGNuCcFhjWpy8iknoqoSup4wJ+VkcxviySc34bjjm5oNgJRshCQ5uaHCMvpPbppPiiyrKLKNSZM+YOXyzQAc0fhIBgy4wCyf5Ph5b4oQgkaNGvHLL7+kjorZtm0bZ555FnXr1i23/luQkhsMNm3axDvvvJPaZnr22WenDqzaWey0p4gZMz6lV68zUmFffPEFXbt2Lde9hpRGVrfbxerVa+jQoUNq0+2wm67k2Wceoyj0D4aIIJUxU5sOIQQ2mw2PK0AkVkwsFst4RiaSRvheP2AnFCkgkdCx2xy4XT7CkSKCoSJyAn7sNjeFxXmplrO4uDiVivk8P5oRoyC/AI/Xi8sRIJ4oRpIkFFVNxrfyXjr/siTh8wYAlfzC7eiaTk61AKrsIBIrJh6PoygyXncu8UQxkWi0zHRUVU2+e5BoNJJ898x4Qph7Z12OAIIYobD5bQxDIEsyHq8XGZn8wnx0TcPv92O3eQlFCojH46mF/4AvgGaYEzeWA3bDEMk8VCMcLSAej6X8IgshcDicuJ1uikNF6LrV0Jh58vv9KJKT/MKtqEq24Yb1u+RdBKaCVRQHDoeXM3r144vPzCMVu3TrwsfTP8Ew9Epzuufz+fjkk0/o3bt3Kuytt95iyJAh5dZ/C1LSR/aSJUvo1KlTSlmNGjWKwYMHV3hvNiqlG2wY5gdL3yK0YMECQtEifB7TOkRRFVRVLVesLkcoUohhGNhstlJxSkRBURXC0TDhaAGSBHa7DFKcSCwfu0MiN9cPkkY4mo/NJhGNBolEilBVgc0mYbNJgEYokoemRcmp5kNRzNnXhBYlnogQiRSjqqCqUnL3RnY+VGRFIRQpJhzNw+u1EchxoukRQpHtGEYcVQVJMlLplqQnZwjohCJ5GEYcu11Jhps7SSyx220YhkYosp1wJIgkmXbUqiojyQbhcCHhaAFer42cam6Q4oQim4E4druEqgpUVRCKFBCLhXE4bKiqnEoDDEKR7Qihm2Usl+TBMDSC4UIkSaTyZn23aDRCKJKP3a6iqDKKKiX/tX6T/NcMt9L2OquxYsUKFi4sOfvU7/fjdDhKjd33JhKJBM2aNaNx48apsJ9++gmylNLeRqVoVlVVcTqdKYdpFm4cNpgnn34QmywQZI8/d1QIFV1PbfhKQ/aShPXb/Dd7u15plN09L0FF1wWgl/F+5cWnjGvZWtT8d+cri0hKdjlQTl7KCitB6U+etrcxYxeQec3qCZRsBCT5b/p3SA+3kVeYz0UXDeSzT5Ymw+G5F57jxutvJBQOZa7p7kXYbDaEMDj//P58/PHHkOzGTp48eYcOA/ekZq0UspJ0bvzll1/SrVu3jPDmLY6j6bFHoWmRjHFfxX7IJHP7VwWVqXSFzP7bCssOL6lgpZFe0dLvrbhimygrvfJQXlrpz9sdpBMjG7uSZnlxdzV/JfHSq4skyxgCFi5czN9/bUCSzfpQq1ZNFi/+ibr16hHeCUd9ewrWURiDBg1m3LhxkDw2ZurUKciyUuG49YAkq+WO9M477+Txxx/PuFaFKuwMxowZwyWXXEIoFKrQ1HNPwyLrwIGDGD9+POwjslZax1/Xze7Cgw8+yN13373LPpz+65AAVTalCplwOu289tprXHLJJUSj0UolqgVZzvQmYW4aqNx87DXNShna1Zw1NG00v//+e8aNG8fs2bNZt24tsmQulmcsWaTBSst8loQhTGOJsq9TTlcvO54lpa/r5VQIa50w892s39l5MJdUyoKVd+t6OBRGSxrA22yq6ZlQklPXs+OnQ047dFnPMtJILyPKuZ8dpE8Z6ewtGEnndD6/n0MOOYS2bdsxePAgjjvuhErXqBZUVclwUg+mw4OpU6dis9kqTbPuVbKWB1mWU64Zi4qKks6jMtOwjkosP+1MMu8+ykt/V7F7+VFtpn3x+eefz9dfm57nzzuvHyNGjDC1SLL1LqvhO5Bh7c8tC4YQqIqKx2t6bNA0PXXGUnY5VAas+jpo0CDGjBkDaWRVVbXCCSaS8zVLly6lc+fO5OfnAzBy5EguvfTSXfqO+4SsFiy/rmVt7LXS3N20DxTYkn5te/Toweeffw7ApZcOZuTIUZD0MWutc2bjv1w2Qgh0XUPTzP2pZdWRysKOyBpPHtVZHvYUWfddCQCGYRCLxYhEIqXE2g3x3xfzXdO7d9ZYyIoTDpcuj/96GcVisdTRjvuSqPsT9vtSqKjF+i/AWtzfF2OxvQ+xB4cZByb2ZP3dp2S1psSdTmeF4nK5/rNivWO69rA+cHY5lFcm2df2D0n/rjv+xmWJw+E4YLWqlGVjvCewT8as6RNMeXl56EmXH+np7KkX3F9hvauqqkiSxODBg5k+fTokN0m8/vprRCLlL1PsaEy/78svO187nx+RdCVjt9tTZyql22xXNnZnzGr9LaXNBv/bMWulk9Vut+NwOJgzZw4TJkzgl19+Yfv27alKa8H6nU3i/xqs9wyHQ2ia2WiZbkdsGUdHZFYGCbUcLxUWzBnKknKr/DLMJmfm87MrtwUpudNFCEGNGjVo06YNl19+OccccwyRSDg1jq1MHJRkdTgcqKrC/Q88yMMPmRuyq5AOq8tXtjY9WBEI5DBy5EjOOacvoVA42dvYuTq3J7C/kLXSBgSyLGO327n33vvSiFp263rwwqgiainIFBYWcG6/85k4+X08Hneax+H9A9lE3VuoNM3q8/mYN28eHTp0yIh/XMvWHHvciUiKmuZRkApbTkGZDiWyYH3Q7IhiJ2cps++zwiQkIZAxUh4bJEkiPfOWQ8aSnTzZaZWVrz2LdIujbKsk68k7c77Q3sylNTZNrw+SZB7xGE/E+G7BAtb+8TPIdjDi1K7bgO+++45DDqlHNBzciW+4Z7AjzVqWUcTe0KyVQtayzLUABl9/I7fceTe+armYvsJ2rmqkqLZz0Uu+6c7G3xFESZdEkkzHBukKUZDBXSAZB3P3iJDAmuQsL0v/JssidTSl+a+Vl3TfRzv4ZDv7KcpFeemnpytntnGpMABFhi0bN3LlZZeyZNbnINlAJHjmuZe46cZrCQZDFVpB7UlURNbyzA0PWLI6nU62bdtGx44d+euvvwA4pX0Hxr77PqrbRzASQ0NOdm92DhU/ce/D8kFk+eQ1fQpbWiKNjSmY8YUQmd04UZqQgjSWlnF9Z2CVpfVtrH+zNVlF2JW4u4IddRul5HAgN8fPmuV/07trV2Kb1gLQ7/wLmTRpPLFoJOv4kr2H/YWs2TVqr0CSpJSfVgsnNGuGP6c6BcEwUc0goRlolugGif1adDTDAEVFUhQkRUFWbUiKiqzakFUVSZaRZBndMEhoGglNJ5F6Tz0pZb+rpu+ZstAMUFQbhpDMNHWDhKaj6Qa6ISqU9Li7KlYahqBUulba2WEZ1w3QDEFeURH1GjTguGYnpupNflEB8XjmaQAHCyqFrCTXExWl5OgBXTfMnS2SjJDkZH/S1Cim+62KJRW5QikP2fHKk7IhSebm6FgshqGb/o1EmhtLI8s/bfq1ZAoVpv9vIZInj4OEphnJXTlmz8USI9k9Lk+yy3tXxOyrmUdQli5TU4R57nKZYggwJDOteEJDS+v8SZKE2JnB9n8QlUZWIGOMsWP1X/oD75rsCNnxs6V8uF0u1qxaxZDBl3J61660b9uulLRu1YrWrVqxeNFiAn5/dhJ7FVJyPXv7tm0MuuQSvv/uO7weL7IkVZr8W6TXD5FmGGIIUan+l/YnVOpbZw6PyyJFdlg2gXZWdnT/v7uuKApFhQX8PXcOxx3bhIsuGMC555yTkn7nnEO/c/tx3nnnUbNGLlpCK6MC76ix+ndQZBk9kWD5/Pls27wZVTF7BP8GopIk83mm03ALJV8ouzz/+/h3X+9fQ0JCRkp38LzDoyN2FqVJlik7Qnb8zHtlySy9ywYP4on7buHB4XfxwPC7uP9BUx5++B4eGn43jQ4/nFDY9BckJSei7DYVp8OB3aakOo9lVVlZNm2nHQ4HiqxUmHtJMtexHQ4HiqoAwjzXx+VElSRk6wS6lI/e3RfLr+9eEzmtWy1lvbEhzAOwUhN1Bw/2IVnTCzqLDP+asFnplSvlITtelljNvwRFhflsDWps2VzAli2FbN1qypYtpiTicVOrGgK300luNT8YgkQ0isvuILeaH5tiklaWSP4r4fd58fvcGJqGnkjg87jxe30pDZ2eI4/bTbUcD1oiQSQUwuNyUT1HQcYcAMpl+HrcEbKbDuuV0zXf3kDmYdrm77KfmV4CBwf2IVlNZHd9DhSYHuFLcl7Rie3CEAT8fiKhMI89/AQ9up1O29at6d61G6NGjMLrcuFzexC6gSorVAv4+P2XX7jxuuvp0LYt7du0Zsjgwfz4/XdUy/HisNmQECgSVM/xsXXzJu6+/W56dO1KhzZtuKh/f779Zil+ry87KzuFdGJmy96G5SGkCqWxT8maqhRpyqo8ZFeafSlIJZXK7XLj9ah43R58Hi8+jxevx4vH7UFVVIRhegrYtnUr555zLuPGjeOMXr24adhNtGrViicfeIArrriScCiEw24nJ+Dl048/5YKePVn593IuHTSIK4ZcTiQSZkj//kwYPwmX04EkBH6vl58WLaF7hw589dWX9D//PG644Qbq1K7NpYMHM37cOGweD5KczHfaW5j/lX43M17Jv1XYf7BPyQppZoPlK6aMCrS/iLUMtXbNGpb/uYYVf/2dIX/+8SfB4hAOuwNZkrn9jjvIy8/jy6++5LHH7uaqq4fw/AuPMG7KVBZMncqbb7xJ7Zpu/lm9lluuv55u55zL559/yp133sCtt13HlCnvcsn/ruKh66/n5yVLya0WIG97HlddcQX1D2vEnDlzuP++m7n+hqsY8faLPPf8c4ybMI7Epg04HPZk+Zq5t8wgs98pXaqw/2Gfk5WdrBw7E6cyYVNVkGUeu/12OrVtx9k9e9K3Rw/69ujBOd260f/07sz6ahY1ajhZtHARP8yazeuvvcYJh9cmFIZoWKe4CM5q14yr772Pj6dNI1hk8O6kyTg9Xp579lncTggV60SCOuhw71130fCEE5k8cSLVXPDVl18SXLuWp556Cr/fyfqNRWzclM/mTUX07t2Rc849B7RgVtmVELUKBxb2C7IeiEgkNNANbh4+nA8/ns7bEycxYvJk3nr3Xd764ANGTplC6zaticfh559/BrsdFZkFi//i16W/8Nfvv7Psl5/57pfVNKxXj62bNrNu9RqWLFxEkyMbs27Var6du5hfflrCLz8tYeF3i1izfBWHHlKfX5f+TAJYtGgRhzRtStOmTcnPC6GnORYrKjbo3KkTuHJS5nCVZUtbhb2D/YqsqS5YBV3i/QXm3JLMkUcexUknn8gpLVpwclJOad6C5s2bU6dOHSQJ8vPyYOM6Bg4YwJldutCvVy/O7dWTfr3P4PQOHbjzuusgkSAvL49IJMJPX35Jj27dOO/svvQ/5xxTzj6bbp07Me/Dj3A6nUSi5tGDgUAAIYwMf8FG8mzSOnXqgtNV7oHP+x/K7oQfANWhUrDfkFWQttSafXG/hHkIcDSmEY4YhEJhQsEgoWCQYChIUbCYaCyGrEJxKAS16jFm0iQ+mDGDCdOmMnbaVMZNm8qYjz7g3S9n8vUP39HwiMNZv2kjbc7pyydffsGk6VMZP/UjU6ZPZewH7zPj5yW8OfJt4ppJSJtNRVHUkvFmWhkmtASIpLnhbm4IqHRIJYSVMv80IUuI5JrxwYb9hqwHGgTm3jiBaSiQbh4nSclilSCRgIYNG4Is07hxY05ufhzHn3giJ550EsedeCKntm5O/UMbsuTnn1FtNurWq0c8HqdZsyM58aRmHHfiiTQ98USannACp7VuTigS4fc/luF2S9SrV5f16zcQi8VQVTVjj6+qKGzauAlisQPS6Vh5q6gHRkO+d3DgfcX9AGYP2Nx4UFZPIH1sGIsJWrVqBYWFfPTRh8gyRCNRioPFRKNRnDZ49NFHufnmm3E6HJx+ejd+/Oorfvv9H+x2CIZMTY0kEQzFuOCCAUycMAGXDG3atGXb0qUsXLiQ3BpuFFlGkiQcDgd+r8SUKR9BZCsOhyMjf1U4MFFF1t2AZBE0nkiavZma1tSoJTpBIBGORDj22CacfsEFPHnrrXz4wQyqVfNwSO0AtXI9TJo4jY9ffoWrrrwSf8DGWX3OBr+fyy67jLX/bKZO7QC1awWwqQr33nMvic1bGDp0KNuDgo4dO9K4Y0eGXnMNP/7wK7Vr+alV04/T7uCZ595k9uzZUL0BsUQcS9lX4cBF1SfcTaiKCg6HaWQukzQ2zySqQEI3BLGExvCHH6Jp1y4Mu/hi+ve7kKuGXE+fnudyx5DL6fO/q7nqyqvYvCVInXp1GT12LOvWrqVjhw4MvvhKrrxsKJ3ad+CTiRN54s03OP74phQWFWFzOnh9xJvk1silf48eXDjgUq4Ycg09unfnzddf45GHH6LhMUcTi8eS296qcCCjiqy7gWAowhGNj+TVD97nuGYnEorETHWbMdIqkVAkgt3lYsy48Tw1Zgwuj4fVa9ZQu04dXp0wkcefeJK4liCh6xQUFXNKixbMmjuXG268kYLCQjZt3ETXLl2ZPvtrzj77LPILihFAMByiRq1aTPv4Y+59+mkSCY0NGzfSvXt3pn38MT169eKB4cNp1aYNxUHzYKcqHLioIutuQNcNnB43bdq3IVC9GtFEvML9uZIkE4pE0YGeZ57BG2+N4MPpU3nxjVdo17ULBeEQMU0HWUZIEoXBIIHq1bnymv8x8b3JvPvRh9z9wL00aHQ42wuD6Ijk5mwoDgVRbDb6XziA0ePG8t6HHzLs1pupXrM2RaEIp7Q4jZq1aqeOk6zCgYsqsu4mNF2noChIXNMgSZwdSSyeIL8wSGEwTEEwzPbCEPnFQRKGwEDKkFA0Rl5hiMJgmKJQmLzCEMWhELoAI+mvyoobicXJKwhSHApTHAqTXxgyGwcBRaEw0YSW0TWvwoGJKrLuLrL232YTs7SUkEVL81GUHp4thgBNF2h6WXHNZaMSkSqIW1oOFGS6wzm4UUXW3ULpcakp5SFz0qmEMLsmpe+Xk1I6btnxs6UKBxKqyFqFKhwgqCKrhWyls7dlnyC7c16FAwlVZMUkT3Y13tuyrwhrdYoPXGSU4kGFKrJiGoXLpQ6/NSuEaS+eTbU9JXsb5nPKG7XuCBW5qtl3qKyy2/9w0JLVqrA5ATe1ariomeuiVoZ4qJXroXYNN36PB8kwkIXYY1JZ9S19imlnDygRwsDtcVMj17WfEvbgxEFJVinpplOVJSZPfI9bb76PYdffwU033JmSW268g1tuvIMrh1zLmNGjcdhtpqF8qTnW3RFLs2Vr2j0j2c+zwkriWCg7vtvl4ofvvuPZZ15DT8RRk65Nq7BvcVCSFUBRZFRF5s03XmP6qy+z8q8/+eu3X/nz11/467df+fv3Zfz9+zKW/fwrm9etR5XkLEfdpUmSKZnI7oJmEwSEuXkzuYEz+/qui5E6llLKco5m5ic7vql5FQn8HoUFc+bw1sMPkYhGsaumz+Iq7FsctGQluRlbkSXa9z+fmTM/4uPp05k2bSrTpk5l+jRTvvnma+68807isRiGrqXOPTXHtsmESkmJQ23SxoeyJGdoVIskKaJm/c4mU1mSfmRF9jXzupWXErpZY/Ky0jDPiwSPywmBAIqE6X94n2JfP3//wMFL1iRURSUaixEMQ1EkTDAaJRiJUBQyzfwKisKEIhEzsgBd03A5neRW81Grpp8auQFyAgHsNltJ91YIhGGQE/BgU1TsdjvVcnwEAh7cbg8ul7tkg3oaHA4HLpc74yBkC26PB6fTlbLmsak2cgI+alT3UKO6h5yAB6/bgyKXHP4F4Pf7sdvtpuNwv4+aNX04HI5UOm6Xm5yAh1o1PdSs6cHr9SFLIIRuHjpr6GCUHBxdhX2H0rXiYEFav06IkuMGDQE6oAthCgJDGObREUDNGgG0eJyxo8dzxaVXc8VlVzFx7Dj0eIKA14ciSbjsDsLFQZ58/Cnyt2/HZXfw/nsfccvNt7Pgm/msXbPG1FiS6SlfAuyKwtZNm1m7ejUK5jWSWlBVFNavXcuaNatRZBmv241dVfhk+idc/b/rufiiS3ns0Sf4688/8XvcqLKMKssIQ/D6a6/z57Jl1KzhYdZXs7nppruYP/8bPG431XN8BIsKGfXWaC4d9D+G3XAn38ydi98OLrsdhJ4kaRVR9wcctGQVJE17hUCRFWw2CVVVkWU55XFBVpK/k25RAn4fPy36hR7dTufR++6neHs+kYIinnj4EXp06cpPPy6kms+Px+kgEixmzNtv89vPSxl40UXcf+edRMMRFv7wA2ef0Zvly/7A53QiIXDabNglmeuuuopzO3emYOtWPE4HsgQOuw1d17jowgsYO3oUh9TxsmXTJi7s3587brmVDWvXUpifz9SPPqJ/99MZPXIkXqcTu6oiCcHEseP449ffuPfO4Qy75mp+/+UXDC1BrRyVb76eR48uXXnlhRco3LadNcuXc+uNN3LDTfchtERyQg2k5PEb6VKFysdBS1ZIDg8xjxRUwDzASYAsQEn+1jUNQ9Nwu1ysWLGSC886i/r1DuGb777j3fcm8dGUicydO5e6deowcMAA1qxajdctYVdtVK9WjZdeeIEaudWZPWcuY0e/yBWXXw7RCLNnfYXLYRLK6bCzeuUKVv+9HPLy+Pmnn3A7bSAMPC4Hy//6i+KVK+napQtCwL13382K5cv59NNPmDHjIz79dAoLFsznjAsG8PQ997B61SrcLieKLFO3dm3eGTmKnxYv5qOpU5kxYzo9e3Rj0U9/cdXFF3P00Ucxe/Yspk17j+nT32PS5En89tuvjBs3DrfLhZzWrd5/iLp/5KKycdCSVUp2NQOBAN9/+imtT21D57btOb1jJ7p17ETXjp04rXlzHrjnXtwOJ16PzPPPPQ82OyNHjaRmvRpsLSpi/bYiqtepyehxY8Fm47nnnkOVwW63kbd+A3a7nRdeeJE6tWuxaXOEmjUDtO3ajXlz55GI69gUFYddZtZXszjiyCNpc24/pnw0BS1uYJMU7CrM+vIrAo0a0b59e/7+ax0//PgDd955J02bNmL79hAFhWHcHoWrrroKFIVVK1ehqKAoKvl5+axds5o3Xn+d4447mqKiEIYBL77wAo6cHEaOHoW/ejU25RWxYXsRRx93FC+++gr5W7cQiUSyZsD3Bxy8+v2gJasFLZHA1/BQzu7Thz5nncVZZ57JmWeeyVlnnsm555xL69atsdtsrF+7jQXffMPgIZdRvbqXbXlF6EhoAvIKi6lVO4f+Awbw2aefsm59IYosgyJx7jnn4HZJFBYXE9cSGAL6ntOX1atWsWLFclxOB1pCsHDhj7RseRr9+vXj999/p7CgALfLRag4xpyvv6ZDhw44nSqyojBixAjO6H0GCQ38fg92u41YFJYvXw6RCIahm0dSCkFCS9Crd28aNqxDXl4QSZIoKixm8cJF9O3bF3/ARX5RYWqMvr0wRIND69LtjDPQNS1j0/r+MXo9+Ehq4aAlq0hOLBUXB2nR4lQee/g2hj9yFw88fDcPJuXJp4czYMD5IEmsWbOG6JYtHH/8CcRiAFLS0beEEIK4BqeedhroGgUFeSAJVLebRo0OIxpNHgQlSYRjOic3PwW7w873332Hx6OyYf06/vrzTzp17EDr1q1JxOMs+ekncgIKf/35F2uWLaNXz15EQjFyq1Wj5+ltyNu+nRFvjuT2227n9ptv4arLh/Dc00+BLJlGDAYYuo7T7uCYo48hngDdEKg2O4WFRRRs207TY48lEjVSTt8kScLQdTQNjjj88NReUkkyF2/SpQqVj4OSrFZlE8m1z2g0ypZCwZZtYbZsLU7J5q3FFBQVl9xoCBQl00ewCQlNA7fHjeywQ3IcLCHQEnGwjoKSIBqLUat2LU5pfgqfz/wcmwpLflqMokgcfcwx1KlbjWOPa8rs2bNRgblz5uDMyeG4pk0RQmC32XniqVc586wzmTJ1KrIsceyxTbjyiisY/uCD4PcRj8eQTE+pSIBhGGkEkzAMA3QNRVVLXiHZeKX/tnRY9tvuaxyMDr45WMmajhLtUXYFEIBuGOTk5IDTSd72PFzO0s6CHQ5YtmwZRiiMy+Uyj7AoRWrMLqoCHTp1YsnSJWzbGuK7b7/lyMZHkVuzJpoBrVq3ZtHixeQXGcyePZvWrVuTm1sdj9vJtOnTeOmRR3hw+IN88OEHPPn04/zvmv/Rpl1L6tStC7qOoZd/po2uafh8XjzVqrN92zZUNd3IwywDIaCoqMh0AidJGCKd7PsepRvLgwMHPVnTYWk/y1uLkQyLJeI0POwwDj36KD784AMMHRx2u6l5hMBhs2HoMGPGDOo2akTNmrXQNC2VZromF0AkqtG2XVsURWX2rFn8+ceftG7dGtWhEIokaNe+HXl5eXwzfz7/rF1Lt27dkGRzxfOrr2ZRv2lTBgw4l0g0yuYteWzfno8sw+o1q6GwELvdXspPsNUUabqO3++nbr16zPjsMxQZHKoNSQjQDdwOB5IhmDd3LkI30pZvKhdWWZllV/L0ys7H/oSDnqwpbZIlBmBIpsR1DYdb4fIrr+TXLz9hxJsjqV3DQZ0aPurU8FO7hpO33niLv2fN4Nprr8PrlUkkEskHpDUAybSjsRiH1K9Pi1Nb8Owzz7JlyxZatWlNPK6h6RqHH3kEuTVq8NBDD1Gnbh3atm9PMBQGGXKq5bBuxQpWrFxLzZpeatWqTv161fjrr9U89thjkCjG7XHjUku6wYpcctaNoevY7AoXXXwRv3/xGePemUCDWh7q5QaoXyuHXK+D1198mXU//0K1nBxzCSub+ZWAbBPJdOx/M9SVg8r/CvsZCgoLKSwqMjVRUnsJMsklgLyCMH36ns3ge4bz5G230q/fYMaNnczECe8xcODVPH3jDVx0+/2cfc45FBYbaIaBnredWEJDJL0fWjAtpgw6d+3G2h+/xuvzcUyTJkRjcRK6RiDHyyktmvPPt1/Q/NRTqVUnl1g8TjSmM+DCCwE444zevPzy20ye/AH3PvAEZ5/Tl7bt21OjWUtuuvlmvpj9Aw6nk4LCQiLRKKROP4fiYJSz+51Lr6uGMvzqoVz1v1sZM3oio0dO4MIB5onplw4bRiQaJR6P71fkkCg5df5gw0FLVsPQ0Q2Dy4YMoU/fs4nG4ujJiZiyzq/RdY1oLMZdd9/K/a++xsZNm3jg9ju47/bbWbVqNQ+OGs3td99FKB6jOBrG7fcx8OabOfSIwwlFk7bFSRhCEI3Fad+hA32vv5Mrrx4KkoJuGBgCwpEE5/TrR7crbqR7z54EwzEMyXTqfdQxR/P62DEcdfRRPP3QQ9xzw/V8OuNTrrn2Ou66524ef/IJjjrmGNZt3IghwcAhl3LCKScTjMTNWV8J4loCzTB47MknuOPlF1m05Cfuv/suHnrkYdxeD2PGj6P32X245NLB2J0O4lqyl7Af4WAct0qGseNmSpIkZsz4lF69zkiFffHFF3Tt2pVgMLjDgnO5XGzatIm2bduyZs0aAC4Zej0PPf0cm4tCxA2rw1bSgmenmP33v0PJjhO/14cQwjz8KXU1818rV2aXUsHjdqPrGtu3mYc+BXKqoagShUVBdMMc6SqKTLVqPoLFESLRGJKkZKUnsCkKubkewmHz+ZJkLgMJIfB4PdhtCkVFIRKahkh+B0WR8Xo8SMDWLZsRhiCnWg52h4NgMITb5cLlUiksCBONRsnJqUY8EScSjaXSMPMhUFUFr9tDPBIlWFyMLEnk5uaSSMSJx2MEcvwUFBajGWBaCWdr2Oy/Lezm15JI9WUEAoeqYEdw2QUDWPrlJwB07d6LaVOnmI2tplXKBgNZlvF4PAwaNIgxY8YA0LlzZ6ZOnYrNZksdVp0OqwsvSRIej4clS5bQuXNn8vPzARg5ciSXXnrpDrmTjn2uWcs6NzSdLJbsaVjpFoVCFIfD5hg1KannZo01DUATgqJQkEgiQSC3Bk6vj2A0wvaCYjTDXEsVkoymC7blBYkmdEgSNTM9ibhusGlrkMJgEF1g+hMWYCBRHAyTVxhEEwJJUZCS3vo1Q1AUDFEUCuMNVMOfW4OEAQVFQXQkiiNRtmwPEtV0UG0UhkKEY3FEcma3JB8SmmZQGAySANyBAA6fj8JwmOJYnDgSWwuKiRvmxgaB9bGsLXw7QHrcnZWd/NLpWwIPJuxTsmaTNB17/TOkZnzN/9J9dltiIT3MwEBHkNA1wrEo4ViUhK6XIraQpNTyTcXplVzPFut+y2jBgpEc80bjcXNcqZnj4lT8tDTLSj89H4YQxLUEkXiMaCJOQhgYUnLnUXKSTUhJ8qXeLlMLlpLUM8q4tlNScnf6v5koO/S/jEolq1zlz+c/hDI04y5qyJ3BnkvpwEelkjV9eKxknMZtjh+tltUaT5Z0TPe0ZLfk+0IOZGS/S3myuzDvlZIWZrJSsvPHMPSMw6oPJlQKWWVZIpFIlKw9AggDRQKENSLKdkmSfVTTHhZRRliliTCfL0SVlCkkT/CRsKt2YpFYqtoktDhGFVn3HnTdwO/34/V6U2HfLviGwvzt5FYL4FDlLJFMscl7SSRTSj23smRvvltlSbIMy5Xs+LsmTptKrVw3f/7+G8uWLk3Vmxq5NXA5nQeldq0UssbjcXJzcznjjOTSjyzx50+Luf22YWzZ8A9+pw23TcaVLnYZt03aSyInJTu8smRfP3//Fq9Dxa4IflnyK7fefAMUbkpV1TPO6IUEFdo//1dRKeusAD6fj99++4127dql1poAcg49jEMaHAYSGIa12C0Q0o7T/Hf4t+OqfwNpB3PhBwIqKr9/+X6SREJLsPKvvyFvGygO0GM0Of5E5s+bg8vpJFHG2ubewv6yzlppZJUkCa/Xy2uvvcbQoUOzL1ehChVCsdn55OOP6X56N4qL07YtVgL2F7JWSjcYTI0ZiYS5+uqrGTVqlLnlrApV2Ak0adKEL2d+vk+Iuj+h0jSrBVVVcLnc/P3334waNYoFCxawfft2dF0vd5fFwQDD0FFVGyQbNgvWb6tsdqWsD2TIskxubi7nnHMOF110Ebm5ueYe27SyqCzsL5q10slKWpeY5ORTLBbb5TT+a3A4HLzyyisccsgh9O7dm2g0ihAlm+LTK+h/uaykpH20qqq43e4UGSJJR+tllcfexkFNVguSZPrqVRQl9ZEORthsNgxDp0WLUznqqKOYOHEiiUQCLbnbpSzv/f91SJKEYehoml5mvTgYybpPa4EQgkQiQTQaJRKJEI1GD0oBmDHjMxYvXswnn3zCr7/+iqLIxGJx4vEEsVjsoBKrt5VIaLtUmf/r2KdkrYI5hgf48MMPASguLub9999HlhXkDJPMTEhZhz//l6QKZaP82lCFSoHL5WbFihV89NFHqbB3332XYDCI3W56SqxCJg5WQleRdR/CqnQTJ03MMBRZtmwZX3/9NU6ns8yKaYVla6SDRfYnVGY3vYqs+xAOh4OCggImT5qcCrMq49tvvw2AkrbjpAr7FukNRWWS1EIVWfchbDZbakLJglUJZs6cyU8//YTb7U67I1OrVqFyIMvWzLTpXhZAVdXUN6gs4laRdR/BmliaMmVK9iUAwuEw48aN2y+7fgcbZFkhFouxdevWVJi1BlyZu3+qyLqP4HK5+fnnn5k6dWoqLJuYkyZNYuvWraW0axUqF3a7na1bt/H777+nwho3bozdbkfXjUprTKvIug9gLcm88sorJBIJhg0bRsuWLRFJz4Y9e/bksssuY8OGDYwfP36fdLmqYMJqQOfNm8e6detS4W3atAHMc4QqC1Vk3Qew2+2sXLkSm83G/PnzefbZZ6lZs2bqer169Xj77beZOnUqhYWFFBQUpAheWa14FUw4HA4MQ2fcuHGpsNq1a3PiiSdiGJVrz15F1n2AWCxGIBDg8ccfp3Xr1miaRsw8RxIgZdV01llnccsttyDLcqW24FUogc1m46uvZvHZZ5+lwjp06ECjRo2IRMzvVFmoIus+gBACp9OJqqrEYjH0tAOLSWpPIQSxWAxZllK207IslxrXlgerS12e7AjZ8bPlvwyrjH0+H+vWreP6669LXXM4HNxwww1QyV1gqsi672AYBolEIlXx0wloVRbLkL2yK0UVwOv1Eo1GufLKK/njjz9T4YMGDaJ169ZEIuGM+JWBKrLuJyhLW0nSzmvSbFj3lSc7Qnb8bPkvQpIkXC4XXq+XlStX0r17d2bMmJG6fuKJJ3D//fenGtHKRhVZ90NYa7AOhyMlTqezSvaCOBwOXC4XPp8Pr9eLpmlMnDiRDh06MHfu3NQ3ycnJ4c03R1CvXj2CwVDa16o87NP9rFUwJzAkSaJPnz58/vnnAAwYMICRI98mFouXGs9a2JF2q/omOwdFUQiFQvz999988cUXfPLJxyxd+nNGnBo1ajBx4kS6du1KcXExIs0pQHmwrkt7cD9rFVn3McoiayAQoEGDBtlRM7CjylL1TXYeW7duZfPmzdnBADRv3py33nqLE088MUVUdqL8q8j6H0Q2WaWD2GPG/oSaNWty/Q3Xc/X/riY3N5dgMIhh7Ly10t4ga9WYtQpVSMLlctGqVSseffRR5s+fzz1330MgEEh5VNxZou4tVGnWfYxszQrQtGlTzjijVyn/Q9ZYqSztu68r0t5G9vvuKUiSRLXq1WhyTBOOPPJIjjzySDweD0IIwuFwatmsrDKvCHtDs1aRdR+jLLJefvnljBgxIjtqFSoBlv+nf4sqsv4HURZZL7nkEsaMGUM8HkfXS/ZQVoSd+IwHNLLP9t0T75vda9mT2BtkrRqz7scwDAPDEDslogyTwP+S6LqRIdnX/60cCNinmtVms2X4DT6Y0atXr5S1zKBBgxg9ejSUav2NlFXTfx1CCHRdT9lOH2jvvDc06z4hq81mw+l0Yhg6GzZsTO0yYS90R/Z3WI3VZZddxldffQVJo4hnnnmGcDiMrmdOMklJg/6DwV7Y5XJRr149VFUlFAodUO98wJNVCIHb7UZVVaZNm8Ybb7zBDz/8QCKRqNBH7n8ZVtmlO/x2OBylvENYY7ad+Fz/CQghUBSZnj17MXToUFq1akUsFiMajSIdAPbJBzxZXS4Xuq5z9dX/Y9Qos5tXhSrsCLIs8fTTzzBs2DAikTCJhHZQkrXS1Jk1Pr3xxhuqiFqFXYJhCG666SZeeeUVXC73QdsLqzTN6vP5mDlzJt27d88I73fe6Zx8cjOEMDCEgZw6hMlMU8qasi9B9jPT40kgyrsvCUmUkcauY/daeClNyoKVt4ryt6Prexc7+uYVl0tF7w6yrFKQX8R33/3A7Fk/psJ9Pi+LFi2iceOj9vtzWveGZq0Uslpnsvbv35933303FT784WHcc/ctSAggAezqBIL1wct6vlxBhdiTFb28Z+wIFVXYHeVvR9cPdCiAA03oDB50OePHlrhUefzxR7j99rsIBovZQbXbpzhgyep0Otm2bRvt2rVjxYoVAJzevSXTP34XQ4QIhQuQZD2DrOUq1BSyyZhZgSs+JtGKl57vHT4wC1Kaz9iK378E6c+wyFrevenhZcVJf9+SdKVSZnGl42SGV4SdiVMWsp+1I2Q/R0GSnPg9uWzYtI1WLTuydo15PutZZ/VkypSpxGIJEomytw/uD9gbZK2oRu8xmMcXmjN5Fpoe1wS7aiMWCyHJOkLoycpvVkJDGBhCRzc0dEPDEHqaCFMMSCR0PB4fOd56qKoDTTMwhEA3Su7V9ESG6IaOpmtouo5uGOiGQcBTDY/HmxFWnmiagcfjJ+Ctjq4LdCPzeebvknQ0XUeSZALeHHK8tcnx1sbpdJW8R5lC6rduCBRVJcdbjxxvdXTDSF4n+WxLQDcgx1sdvzcH3bDSsURKivV39jMtMYck/16y082W7PiW6OhGlOLwdmrVzuG4449O1ZtoNEIieW7twYZKIathCBRFyTi3RdMSCBIgGUmNmq0NzL8VWUYpc0LB1EyBQDW+++5HHnzkHv75Zx0ejw+QkSUpJVYalsiShKooaX/LvDHyTT799DOcTldy3Fy2dpAlGbfbzeefz2T02DEoiprMn5XndI1n/nbYnfg8Ocz8ahY33XYjjz31CKtWrSXHl4ssqWX0EjLhcDjZti2PR598gOkzZpDrr5O8TzFFyCAUFFlFlhTeGj2Kj6ZOx+3yoSq2ZNpylliavTyhjLCdlZ2514pTVlwAA0ky0BJRdL3ksGJZkahwOPwfRlksqBTIkoREiTWOVMbamZz2dzr5TJGx252AzH33PsAD90xg1KhxuGzVUGQ7UNpvULpY3Q/VZkOWFR5+6AXGj5+Ix+5LzjZmk69EXDY3EyaM57HHnjDJqqjJXJaOa7Op2Gw2brzpVvqdewNzvv6Wt0aMoXPns/nyq7l4vdVBKGmV1EJJGk6Hk61b8rn79nGc1etWvv1hCTne2iBUJGxIkg1JUlBVB5KkMnz4s7z99hicNi+SZEOW1KQoOyk7jl+a/Jmyo/tNkcsIs8LNumFkdRN3pdsopXmE/C9gn5HVQtkFaZKx/HGn2QK7nW4WLVzM2rXr6dajMZMnfci6jWtxuTzJLqLVdS3pKprfOrsVlwgE7Hg9gdTflnbNrkgmBC6XB5/PD8hlTHRYRAO/y8/773/AS8/NYNSoZ1n0wzKW/7WK0049maFDr6WwsAiHw5l1X8n9JCuoItvwJrN38813EE0kcDk9yU+Y+S4+nx2vx49IJ5CQQMhIkoIs25LjQks7Z2pa06Sx5F5JUpJ/W9etsighm/XbIqp5T4lklvnOiPkumf9av9P/Lg1JknA6nXi9XmRZOiDNFctCeWyoVFgtabrmBClJgtKtNkjmyeA4Gf3OGBo3PorXXnudoiL44IMp2GVfsuKkfXyhIEsqLpeXgKcmOd5a5HhzcdtdCGEgDCmZdonWkCUVm81JjrcGOd665Hhr4Xb7ATuy7ACRXtkzKzzJSg925s1bwKFHmE67E0YxEj6GDLmMf/5JsHrVKmw2pVyimpDQDQNVhSv+dyaLFq7mqaeewWUPpHXBS4YSFtEkMjW2arPhdnvxu2uQ461PwJOLw+5OkhZAYAgdn8eL3W5HkmT83gABTy6KqiJJMi6XB0mScTrdVPfVIsdbkxxvDVxON7oOiqzidnsJeGoR8NTF5wmgKLbUGHlnYQgQAuRUQ2GixOMjpcpJlmU8HnfKjejrr7/Om2+OSJp0lniKTJcDCfsFWXcVkiRhtzvYvG09n3z8BX36nM0Rh51Iy5ZNGDduPJF4cbJralZaYUjYbA5yvLVYtuwv7nvwXs67oB+PPvkYa9ZvIOCpk6FlhDC1R463Olu2bOfZF15g8OWDuP2u21m8eAlQHZvqLBkvpooxnahWV1vQqFEjCvJh69ZtqLKZrxUrVuDxQG6N3KTNa8UVWQgIhaBPnz7cddf/uO/ut5jzzSwC3mpmhPR1Y5HeaJhzBi63G7fTzcyZXzLslhu4/KpBPPP8C2zfXkjAUwNZtiHLKjbVwYiRI/nxxyUEPHX49rsfuOaGa5jz9XxAZcWKNTgcXgoLwrzwystccMnFPPz442zbWkT1QG0Cntos/HEpt9xxM1cOvYw33xpJPK7jdu3K4VolJDIJlU0q62/zne12Oz6fD4/Hw8qVq3j22Wdp06YNV199NfXr18fj8aT8LxtG5o6dA4mw+4ys/6aQhBA4VT8ffPABwSD06NkDgIsvvoiFP2zmp5+W4HJ5UhXWbnfgcnm5f/gDtGvbn4+mfMy2bQW89+4Uenbvy5TpH+P15CDLapJoMgFPLu9+8AGnndqdF158jZUrVjJnzjzOPnsQzzx/Py6XN617R6kKZY2tgrEiLrroYgIBeO65F5A4hMVL5/HII89x/fUDaVi/wU5vdtY0KCoq4r577+XY4/0MGXI5xeEgXq+vXCMQIQQej4ft2/M5v/8Azjvver799ntWrVrDa6+9QfPmHRg1Zgx+dy52mwchVN54bRRLlizjwYcf4owzLmfB/EV43Lls2lTIxRddwYcfzKBPn/MZO+Zd8vPCvPD8O7Q8rTO//Lacke+M5/LLr+Gnxb/x5x8ruP66Z+jVszf5+YW4nM7ULPCegMvtxufzI0kS06dPZ+DAgXTs2JGbb76ZX375hfvvv59zzz0XkkY5fr8fv9+Pz+dLidfrTf32eNwpN7D7I6z+T6WjfMukHUNRVBIixISJEznzzLYcVv8IYto2unXrRo1a9zBx4mRan3YaiqwihIHP5efl115n+P3jeO7F67nm2qHYJAcGCUa8PYrbb7+T7dvCNG/RHAC/O8APi3/gggvvpl+/5rz66qvkBmoABl/P+5rbb7+LTZvyOOzQQzM0WCZM0sfjCRrUbcTo0aPpf/5g8vMK+frrWZx//pnce9+9hKMhNE1Llke6xsiEVb9jsSgSOYwZ8w7NT+nLAw8M55knn0dRQmbbm+pqmmnZbXYURWHIkCv48Ye/mDr1DTq074Bd8VEc3s4tt97GZYMexO/3ce7ZA4jFtlK3XgMmjJ+MrhtMmzaWdm3aIOFgyS+LWL9+Ow8Nf4Sbbh7GZZdeikyADZv/ol3b9rRq1YsTjm/I2LHjOKXZKYDMtz/MofVpF/LC8y/y+COPEovFUxpxd6EqDlQFNm7awJSPpjJx4gTmzfsmI44kSWzcuJGHH3mYUBl+ftMnqmrWrMnRRx/N4YcfzpFHHonL5cYwdMLhyC5NaO1t7DPNKtJsMXZFyxpC4HF5+O6771m6ZCMDLrgAgwTRaITaNepy3nln8tFH09i4dSuK4sBhd7J63RoeeOA5hl53BjdedxeGEaMwtJlYIshVQ67huuuuZPtWq56rGOjcddfdHH2Ug7Fj36FawEdhaAtF4e10bNeTl15+jn9WWQQr62NKyaJVcLu8AIRCYbZth5FvfUr/Af155cVRRKMhtEQcp9OJItvSZoVLl4fVuAkhEORzSrPWPPX0UJ596kM+/mwqAU+N1OcsqWAyTpufD97/kM8+/ovR77xEt069iCdCFIbW43QpvPHKK3To3IBHHnmEmBbC7faQn5fP779vYPToUbRv04lQtBCDIEIk2LIR2rZrw+WX3kA8ESIYXU292odz083XEi6Gy68YxCnNmlMU3kQwupFWp3bmvAtOZvbsecQ0A0Wxs2MznPJh6AZff/0l199wLae2aMHQoUNTRJWSs7/WDPCbb77Jvffcy+OPP15KnnjiiZTccsstnHnmmbRo0YLevXvz8ssv888/a/F6vTgcjv2GsPuMrBbKn/EtG7IkIaMwdux4WrQ4nDO690fGT8BbG6jBTcNuYesWmDb1E7zOAE67m4ULFxGJmr6NBIVEIiHAIBYLo7GN8847h5xciMcTgMrGzZtYtGgV/7t6KHbZQ0FRQdK4IkYwtpaTT25Gu46HEgmHy21ohAF2mxOn6ubaG6/h7L5DeeaZm7jw4va8994k1m/6A4/TiyEkYjENTTPKJWo2dKETTWznhhuvp9kpOVx15XUUFBfgdnpT43Qwl8YSIsLod97h1Fa16NqlC8WRzcRiEXQ9QXFxISAYNuwGfvstn4ULF2KTHUSjMc7s3YGmx5xAYXAzup4AdHQ9jtMD3bp1AQqJJyLJNdACfD43/mrQvn0b4kYBmh5D12NAMV6Ph2AwTCL1jrsP3TCYO28ub731FuvWbUiFWyS1iLU7BAuHw3zxxRdcd911tG/fnmeffZZYLIbf78+Ouk+wa0zZD+B0OtmSt4VPP5lFLKbz+ogXeea5x3j62Wd4/sWHmDr1E4SA9977kJimIeFhxYrV1KmtUqduXaLxGKRMBQWalsDldpGb60yS1cbGDZswdDj22KZoxNOWZgS6pqEgcdhhh6HpWrmVQlUVPE439w9/kLff/oypU19k2PUP8Nobz2EYMfr1Ow+JAFu3FHJO3/P5++/leDye7GRKIRaLIYRBOFKMTZJ5++232bAObrvtTmQ8qDZz7dnsNquEgiGWLVvOaS1b4rA50DUdRZGRZQlZlogbYU5sdiI1asDq1WsAGYfDwdHHHI2gxP+TgWl15HRCrVq1AIEwRLIcTSutGjXM75NIpPuNMn/HYjEM3fR08W/gcDi4797h/PXnnzz99JN06NAeMF3gWBv1DcNAVVWOOeZojjvuOJo0acKxxx5L06ZNU3Lsscdy3HHH0bRpU3JycrIfw9q1a7n55ps599xz+fnnn/H5fNlRKh3/ruT+BaSkVZI1K7ezcKpePpsxk40bYcuWLTz22CO8+NILvPTyCzz73FO89tpL1K4js2DB7/z222+Am1g0TiKhZXS9LQghUt0mMx9ycr+kqR1L8ma12AYSCna7vYz1VROSJOH1elm0ZBHDh0/glZfv4Yzu51IUXobf7eaLL2ewbNlGrrvxCpb9/ifff78ap9OdplmzNWz6b5FcpjHYXriFk088jWeeu5YRr89k2icf4XHUTM5qW/eY/6qKioQ5gUZytppkJXe73DgcJM34zIbMMCy7W5HR1RfCKhOLqCV5Nc0djQxjluRdAGUut+wqDEMnHg9Tv/6h3HzzrcyaNYuZM2dy4YUXUqNGjVS8RCLBNddcy+LFi/n666+ZPXs2s2bNSon19+zZs1m0aBEzZszglltuoWnTphnP++KLL+jVqxfz53+Dz+crtydVGag0smaT0iRO+Wtd2dVWAlTFhi4SjBjxFqeffhTL/viZX35ZyNKl3/LTkm9YsnQevy37ntmzLe06GbDTqNHhJBJm666otoylDVlW0BIa8XgsWZl0PF4vkgRFRcWokukfysq/yXeVYNA68s/Mv2VIYJr8yai4mDNnDjnVoGvXLsSNbRhGgoLgNg5veBTvf/A6Y8ZM4aqrrqFrl1M44vCjiMe1rGUXS0hVcrtdRZElZBkk2SAU38iwG66lU9dGXHbptWzY/A9eTwDdADBwOj34vF7++Wet+b4Z/q4Eqmpj/YYNrF8P1XICgLmcYZqGGqkeiIxptmlZfgoMcxwtSH5HObn5wlpfLsmzJIMQOmZwJvl3F7FYmFA4SCKRoFu3bowfP54ff/yRF154gWbNmgHwyCOPsHnzZmrVqkVOTk4pCQQCBAIBGjVqRI8ePXjqqaeYP38+r7/+OvXq1Us9a/369ZxzzrksWrQIr9ecg9gXqDSyloZVYXayxRXgdrn54YdF/PD9FgYOvBgVG4oisNnAbpewOySEiHFkoyPpc3ZzJkyYiMYmjj/+BLZuhaVLfsYu52AkbWlBwaHksHLlGv5ZZWC324EIhxxSD68XvvzyCyTMQ48REsKQ8HoCFIULmDd3fpqZIRnEMiurgdvtQUuYY2GbbIfkYn9haCtdO/bnrruuYcsm6NixEz53bXRrTFeKsOmwKrspiXgEQYJ33hmJIeDaa68nkdBRFRUDA6cth7Zt2/H55z+yftM6fO4AwjANTiRJQSWHzz+biaLCMU2OwaD0MlLpno9IaneRXN8tQWmtWtYEYnZ6uwdhCOLxOMXFxUQiYQ477DCuv/565syZw5QpU2jc+EhGvzMaIQSJRIJ4PF5KYrEYwWCQ4uJigsEgHo+Hq666ii+//JJTTjkl9awtW7YwZMhlbNu2DZfLlZGPysI+I6v1AYWwWu8KIMzlGhkPo0aOpl5d6HF6dyKxAhLxGPF4nEQ8QTyuEY7EECS49NJB/LMGpk6ZSrPjW9Oly7HcdNPNbNm+ger+hgR8NcnxHkZRKMhtt90DyfGwRoLcQHUuv3wQr7/2KXPnz8LvbkhuoDY1cg7BLufw4AOPsGEd+P3+jIqcXlFjephWrVoRicITTzyJhJMcb22q+WoS8DTg59/n8e6774EMzz77NL/9sZAcX/U0c8jSkKSkBk9el5NWOMWhIhrUO5zXXnuMj95fwE+L1uP2eNANA4hz/fXXE4/Dgw8+iISHHF99crw1CXgOZeFP87nzthFcdGEXjj7iOCKxSPI5IKX1fKxnmvmQkoSztjWWfENJMr9pCUruK036XUdZQxkATdNThHM6nfTp04cvv/yKiy68KGOjutVDyu7pWdcikQjBYJAmTZowe/ZsOnfunLq+dOnPPPbYY6iquk+8VVT+E5MwCyp772V5MG09/1n3NyPenMsZZ3SlWk4N4vEoYFj6DEmYEolFaNOmNfUbwsMPPwiEeeaZJ8kvSNCiRQvGTRzFNwu+ZfS4N2nbtgMej5dTTq3L5s0bAUE0EeXa666hfYcGdO4ykMeevIe5C75h6sdTOPPsnsyZM5dLh3QlWFyAYSSQJIs45iysEIJoNMqJxx3Pww8P4a03vqRH726899F7fPPttzz+1AOc2uIscnNzWL5iFg0PrUvPnr34Y/nvuF2uUg6tJUnCMBIYCYgnwkhJrZausUKxrfTv159Bl5mVq6hoO6BRHM6nyVFNefvt4YwY8Tlde7Tjw2mTmf/dAp55fjht257PSc2r8eDwB4AYhqFRWJhHJBI0iSglNSgC3dDIz4OEFk3mwRJBLBYmLz+7u2v2DILBYvLyMb+VVFZvIRvZdSL974rvF0IQi8UoLi7GMAzq1auXMYzZGQghKCwsxOfzMXr0aBo3bpy69tZbb7F48eKdmgzc01Duv//+B7IDsyFJEsuX/8348RNSYQMHDuTwww8nHi/ZvlQeHA47BQWFjBw5kqKiIgBatjqJHt27EksUI0Rpr/NZ1RWHw8Eff/yBLG/n6qH/o1o1L4lESZfN+oRSchLC7XZRt24NbDaV45sdy5GHHcn5A87kn3/+4Y033mbkyA/57deFnHPO2Tz77NPIMhx11JE0bXoskWgEt8vNeeedh9OZYMKECYwe/QFz5szkpJNO4o03X+fwwxvi8To5+eQTkWVrssXKCWblFhod27fnlFMbMXfOPEaNmsKECVNZvfp3bhw2mGeefYLaNerRpVtb1q1bgSQJmh53LMKw9vaWJBmLRZGUPDp0aEvdQ2qRSFhjbBOGIVBsMi2an0QospZ27VvS9Lij0I04cS1Ei5Nb0KXbScyZ8zVvvDGZMe98xLJlP3HFFRfw+huvEgh4CUeLzH3F6JzY7DgaHlYPTUtgCAMp+Y6qrZD27dvgz/Eky18g2yTisTjVqtlo1eY0VEXGMHQkQFYlNE2jUaPatGp5GiT3KpfqGWdBkszelKLamDTxA1b8vQWAI444nAsuuACQ0lyTlp2YNUO8O5AkiXg8Ts2aNTn88MOZMMGs+5Yf47POOguRnHkuC6keiSRht9vZtGkT77zzTmpPd58+fTjppJOy7qoYleIpwuNxs2bNP7Rt25YNG8y1sWE3DeHZZ56gMLgaQTTVelvIKP5k11BVVTwuP3EtQigUKmMsVAJDgD8QQMVFYWgbQoDH40eV7GzcsplwKELNmjUJeP0UR4rxJG1X8wvzU+k6HA48Di8Fxflsz9uG2+2mRo0a6JqGEDqKqhAMFqcmXTI1gPk+iqric/qJG4INGzaRiMepVbsmAY+PULyYaLJhcNk8FEcKUzOy6RBCYLfZ8bkChOLFJOKmFVDJ60vmco0AVbXhdXpJiBjhsGm5Y45PZXwec5fQqjVriEUT1K5Tm9xALtFEiGgsnNSS4Pf6iWsxwhFrEs2EIssEPAGKI8UktFjKm4chwG534HX4KAgWZBjsG7pBTk41VFTyikwvCUgCJWVQkl13zESFAJvNhc3mpkf3vsz+8g8AOnfpyKeffApgzvAne2h7C06nE0WROeOM3nz2melepkGDBnz77bfJU9CD2bdAFlkPKE8Rum7g9/szug6zZ8+hoGg7AW8NFMWebEVNUZN7RFVLVDVpsymIxIpJJOLY7So2m4LNpqCqUoYoqoRqk4hEiwjGtiIrBooKkUgxoWghNWvmcFijejicEsWRfIRIEI4GCUWK09KV0fUYxZE8XG6Vhg3rkpvrIxYrJp4Io+kJYrEoNpvppNsUM9+KoqCoCoqqIgyD4mgRuh7lkENq0ujwBjgcMsWRAgxDw263oekJgrFCJBlz/6tqiQ2basNusyPJEsFYEYZuoCgKqq2kvBQ1WV6qDYBQPEQ8kSgpT5u56yQcDRHXIhx66CEcc/Rh+Hw2gtHtaHoUVVVQVRuqaiMcDZNIJLCptpJvoKjIskIwZjYANpst+Y4KNpuKoesUR4uQZQlVkVEVBVVRsdvtRCJhgtEgNpvNFNWWmfcskWUVRXHgcdRn2e9/s2ihSVSAOrVr43C40paW9i5isRiyrDBw4MBU2Nq1a/n+++8rVBZ7A5WiWc2tSx4GDx7MO++8kwq/4qrzeeSRe8jN9WGgpVpZCfNnWUVhjT/K8k5oTT6YNu3C7EtBMsVssZDuCdH6N5lu6hnZz0pPp6x3z46/O8jOZzrMpZSSZ0hltLsVPV+ktGjJczLvN5LXRVo3z1obL7m/5PmlNZy5rFNyj7XMkxzfp+Kll1VJuUrYWblmFRddOIjvFph+uwBGjnqLSwcPIRQOJo0yUpf2GqyeYfv27Vm3bh0Aw4YN49lnny33pIC9oVkrhawkdz3MmzePLl26kEiU+NA5/Ih6tGhxCm63C00rGbvuOM0dXS8LZVX+ssLSUd5zrPvKu/7vkP3+O27Fs6/vKF/pBEn/18LO3m8h+/5sZF/Pvt+ElJyoy8vL45tvFlCQHzXXaQ1o2LAB333/PbnVqxOPJ0qV0d6C3W5H0zT69u3LF198AUC/fv2YOHEiiUQcTSut5Q9oslra9YknnuCOO+7IvlyFKlQIu93OBx98QO/evXe6zu0pqKqC0+niwgsvZNKkSQB0796djz76EEmSM5SPhb1B1uy+016DEOYC9u23386zzz67Ty1B9ldIKcuhKqSjfv36vP/++/Tu3ZtQKLRLFXxPwDDMZTKbzZwTIGnOaJ5MX7oLvLdQaZrVamlsNhsOh4OlS5cyefJkvvvuOwoLC1Obfi1TNWvKPXvN8b8GSZIRwmD16jVs2WIuT+Tk5HD00UdnVISd+Ez/GYikB4fc3Fw6derERRddRP369feZF37LSf3FF1/M+PHjAejcuTNTpkxBVZX/Xjc4fcxlvQDJFspauyJtrGbF35m0D2RYZ9P269cvdfL5RRddxOjRo4lGo6XK5b8Oa7LGOhbUZrOhaRqRSMlG8PS6VBkoi6ydOnVi2rRpKIr83yZrephlumWlsa8+SDZ25p3+Daz3s3oUvXqdkSLrwIEDeeedd9A0rZRnvn1dLpUFwzDQNC3lMykblVkO+wtZK23MWhZE0sA6FjPte7MNrK0zS/eFxGKxvSrpz8me2bQqqnU9PV+RSOSgkFiyt7UrlflAwu40NvuUrIpibnR2OBw4HQ4cdjvO5G+73Z66VrbYD3BJvofd/Df91AFFllFV1SyTciU7vWzJjp8t2fGzJTt+5YrT6cThcOxWpT4QsDuN0D4hq5TcnO1yuRHJnQ4Z2iMcIRaJViDJ69HIfivRLMm4HomSiMeTkiAWiSRNCE1Eo1HilkYNR8qQ8E5K9n176v69K7FIlKKiIhKJRMor4f4GqdQBYLuHXWmMKn3MqqoqTqeTtWvX8tZbb/HZZzOIRqKp7WU7k5YJUe7C+v4CK3elP0fJBm1rNnjFipUUh0w702qBAIcd1mgHywIVvb9U5lMz8W/v37uIaxp2u51evXoxePBgGjduTCgUSk247Uol/7coa8y6p2aD2YU6X6lkVRQZl8vNxIkTGTZsGJs3b86OdlBDSX5gfSfK82BCbm51XnnlVfr3708wGMQwrK12lYP9hayV2g12udyMHj2aCy+8sIqoZUAXooqoZWD79jwGDBjAiBEj8Hq9lUrU/QmVpll9Ph8rV66kVatWbNmyBVUGzYBGdb20OvVkfF43WiJhOiQTpHlttz5M9jOy/95/UF5VKukWm93M9DfLroCGEBnpZFyX2LlubEWX/839exmy6qAwFGfpr8v4c9VGZMnchhcIBPjuu+846qjGhEKZ2/f2JsrSrJ06dWLq1KmVqlkrhayWXfADDzyQdC1i1oNL+vXiyUfuoU7d6mDoaZUnvSKlV9mKn7N/oqzGJln7SPpPscpPSm4Otay2BKWvWxeSjszKRrofp7JQ9q6lEuzo/r0MWQXVRV5+EdcMG8akD2al6swtt9zCU089Ve5ul72B8si6J9ZZ2d/IarPZkGWZ3r17p3YtNG5Qi1mfT6P+oTVJFGxFxkDKIKn5ISTkbJ9c+xyiAqUjke1DrCyy7gFIO6ioYgcjnH97/16ELiQMWcWWU51//llD+y49WbPBNJbv3LkTn376aXKNvrSHkb2B/YWslfJFZNncmbBp06ZUWItTTqL+IXVIFGxHaFGEFsPQ4hhaHKHFEFo8KTEMfUdi3mdocQw9ga4n0PW4GW5dS/87JYmUmPdk35v9nKRYz9ISZYqelm7GNT2R9fwy0rbeZ0fxtERaPrIlUTp+tpS6J0uy81PqenqcMq7vSMp7Lz0GRgy0CPHCLTSsX4v27Vqm6k0sHjWHSgfhuLVSyGoVbCJRspaoyhIIDQkdSdKTmtTq2pktjXmX9XfZIiXP6pRk0yeurDpQbA4kWUFY53DKlru+dJFBkpEVFVm1IclKKswUyrjHFPMfM55qM70eZN4rI5BMSfYoZdWGrNiS4SB28J+c9MyQ/b5W2STfHklW09K1xEL2fZlpVIys+OnckEpfl2QJWVV27sCxMu7PSAuBhIFk6Ahdx5G220XX9KTXxoMPlUJWC+lHJxiGDoaR8tSXKbsyWkrz8ifJ4HSB04OsmgcglaSYCQHIqgoer3mPLJeRi+wQU8z/S2YubXYkxWZ1gEGWUZwus7FI3SGBagO7I42sFQs2B6j2kueUyj2AhGSzp6VrSmacPYFkrqT0sW5m+pIkg92R8vBoZjvtnnQp4/5MpDU7wkDXM7u7+9uwqLJQqWQtD7tb+BZJhRBIDgcbt27liiFXcMmFF7N2wyZsHh96GYQVgOJwEIqEuf2mmxl08UDW/PMPqtNhprsT2kFN+gt6dPhDTBg3HtVjngiuaTqhwsIMH0Gqy8VH73/AE488CpKSPNe1bKg2FUPAbbfezpsjRqK4vQiLAGmQJVC8Ht4ZPZo7b7vdPBndZivTyfaeQTrJMj+Y7HKx5p+1XD3kCpavWI2c8rWVfU/Z95cNM152d3dvvd2BgH1O1t0tfLP7m3b8hqpQVFTEuCkLGffZL3z8yWfg9oGspI4YtKqJJMvgcjFr9hyeHDWL8TN+o7AoBIoNIVmazNJSmZIKk2QkWeGLL75i0eKfwO5A8XjYtGkzfc/pxw8/LEJ1+8y4Dic/LlrElKnTzPvl0uRLQTbPqZn+8df8sHAxqPaU1k+HJElgd/Djj4uY/skcswGQZQyRrvl3hOz3K0E2tSqkmM3O1m15jJv+C9vy8sBmLyN2dko7kuRdQqTOpqXMnB482GdkFZilnv1JdxWpmbSkE65DcqCuC959/0PCW7ZjszlNkz6pZPwoyQokDCa/+yE1VWhYDXQhg2IDSUEgIzCP10gnrPlbThIKQMLr8+P2JL1eKAoJzWDZH4UEw3FQHRjIiHCYPn3O5tbbbkM3BLpewVsn38fvt+F2e1LdxlLVWJhdBo/Xj99vjlnNPJoxzPKVkVUV2aYilermWx1N2XS/JivINjuyzV6qC5/skJY8X5KQFXMMjqSAAElR8SvJoUWywSiB9VdmDsqX9HuqYGGfkdVC2e36bkCA0E3v/P36dWP1P1tZ+NNP4HIltaUJSZKQPB5+WbyE777/nYEDe2O3S8QTeionqs+H6nAmNbKU8oMrBChuN4rPb1ZgCQRSKh7+ANWq5+LxQrXcWpBTG5vDRTAU5rT27TnniisQQuzkBElJnpNPL1WdS66n5UGSEJKE6vQgV6sBDjfIdiRvAMVfDRQbBgoGMgYyyDYUfzUkbw4oTpAdSP7qqN4cDEnFkJQMUTx+5Jwa4HCBw2U+w+NHICfnCNK/5O6SLz3uHqkd/wnsc7L+G5S1PhUMQctWrTix2TFMSDq3QjIJJ4Qw18Rsdj6aMpXcGm7zhLd4Mh1ZIR6PM3XSZP74/XdsdrM7Zw1hVaeTJT8s5OP33k9paIGEYrNDNMYHr7/Bq6+9QTgCEyZM5M1HhrP051/w1azF1zO/YMxzzyFJ5mlsO4LYxeMezB9gGBI2XzXy84p4/tGnOKfPeXTu0pMrB1/FvK++QfFUB8VBwpCRVAeKx8+Xn37B5ZcMocfpZ3Jm737cPPQmlv38F/ZALQzsGNgRkhN7Tm3WrNrEvbfeyxm9+nJGr77cfdMdbF+5Fq8/BwEYGYvQ5TUvO4N/c+9/EzuuNZUAkwtldbjKEhPlVWRNA4/bzUUXXsjMmfPYtHY9NrvT7O4JGbvdSXTLNqZN/5jzzjuPunXrEo9hpm1T0XSdhx95lG/mLwCPB5E0/TOEAJ+P9z74gAeHP4ysqKCqCElCUVQSmsa4CROYMPEDEhp8/sWXPPfcSyxbtgz8ucxfsICRo0cjKQqSYnYzy4epKRXVDk4PqtON6vaiuj2obg+K2wMuN7jdqDZrxlgGZBz+ABtW/0PP3n14Y8RYjjjqGLqe3oOCoiDnD7iBl59/EZvXj2p3ojpcPPno41x62a3oBnTo2JmWLVvx48LFnHHmhXw3dwHOpNZ0+Kux+Nsf6dz1LGZ+OZvTWrbmtJat+fnX3zi333ksXLQYtydpmJX8insO6akdvATeL8gq0kZcFRPWjJ26L3UamNmttLqr0WiUM844A1mCqdM+AXcASbIjUJHcfr74chbrN+pccOGFaHoieZYpqWbD4XCi2Bzm+FWSQZaRFHPt1eZwYHe5TA0imaSLxmPYnA7ee+9dpkydTLXq8PwLz/Pr70vp2/csKN6G6rBhd7rM9JJLWGXO3ErWGNJOQVGYbWvWs27tJv75Z0NK1v6zno1r1xFa8w+FxaGSLq3NDrrgqquHomkG876Zw1Mj3uSuJx/j3Rmf8Nrrw3nk0RF8MeMz7PUOYc7Xc3js6Qm8+ML9jHp/Mnc+Npy7n36cufO+pn796jz9zDMgBC6vh+0bN3L55UNoeeqJzJ83l/ueepz7Hn+E6bO+4PIhl/LQw08SDGH2Msp6r91Cen0oCStdJw4O7HOyplEvI7xsVBAnTdPGYjHc9RrSsX0rJk2cjBGOoqh2VJsDhMSYcRM47bTDOeT4E4hEI2aqyfUjWZKRZcU0jRUly0MpyOZkTMassTBAllA9buwOO7phnpOj+P3YVDWVb0mWU2NKWbUjuzyoLq8pHh+q3QXISJKCx+tj6vRv6dCxM6f3OIvTu5/D6T3ONaV7P7qefh4tW3Xl3fe/wecPmPnxeJk3bx5Llqxn5KjR1Dj6aLTteSS250MkytlDruSsPm0ZMWIkxBP89ttvdOnQmDPPOhNCxej526EwH2rWoveZZ7J8xQqKgsXg9TBu/DjWr9d4+pmnUb1uwhs3ENmyCSM/j4uvvYb27Vqy3SBpyLGnyFoRDj7C7nOy7g1YBt7nnHsuv/66haU/L0VxOVHcLv78/Te+++Fvzu/fHwAte8HdWrsty2RakpGs4wON9OM5kgb4Sf9RhoF5wFQsVip9MA0Itm0vZPWKf/hn5VrWrlzHmr//YdvWApBUBBKhcJAO7ZswetTbvPnGi4wY8Swj3nzalBFP8/ZbTzF+wht06nQUoVCRmW9FYc6cuTRo4KZ69eqsWrSYFStWs3rVWv5c9jfb/lzOEYcfzeLFv7Phjz+54IIBjB41EtXtAkXFQKI4GOSfxQuZ+808kGVkRYaExtx539Cy1RHUrVeXWFFhatksHo9DPEHfc/riArQyHF7vKgRJ++vK4PwBhP8cWVMKNlxE23ZtOaS+janTpoHdAXYHk999D7vD3DxMOGhqT5K1IxsVemrYGYg0LWP+K0kSNp+PSZMm0b7d+XTvcR6nd+9Hq1bnmd1OtxtJhmg4RIP69WjRvRttu3SkXddOtOvamXZdO9O2SydadunCCV16UL9+faLRqElWw6AgP58lf4fp1LE7XTr3omePvnTvfjY9e5xNy5ZtefbZt9F1iMXjVDu0EXFN452332bY9ddz3fU3cPPNt3DPPfeybdt27MkNGFo4zNq16zj6mGPAbjO3L6YXVzyGz+fFltJzZTR0VfjX+M+R1YSAeAx/9RzO638e06dPJxEshmiMj6ZOp2/fntQ5tCFoCRCgWKWgl7i9tKyY0o8vBHOcXNEJZqZbVbIqrFWzzQOJtWARfc8+k3HjH2fkyKcZPfoZ3n3vCYYMGQTREIauISEwtAQUFaIVFRMvKCBhSWEhRmEhhIrQNSPZFTefVxwsplljJ5Mnv834ca8ybuzLjBv7CuPHvsboka/wySej+fKrqRx2+OF8P+trunXvydRpH3PccSdw8UWXcNvtdzB69Gi6n3460UjEzLlhJPcaC1AVhCQwhF5ycLJsWl4JrAOtqsi6N/CfJKvVVTUSCfr06cOGjVF++OFHfvjxRzZtinHOueeaRE2rVBad9ORsk6IkjfOTBLVQVFSEmmZYvnPI1Nq6rtHwsIa073E6rbp24rQuHWl7elcaH9MYtOQGfJOCYE2wCAOEuY0wqaNT3QjrfZFl6tevj6LInNyqJa06tqd1+za07tCWVu3b0rZbF44++kh0QyMSjXLXXXdzYrOT+HDadIZcex1tu3blyGOORa5WvaQMdQPV46HhoQ356++/QNOS41IL5ix6Xl4eUfbg3FIVSuE/SVYL0WiUJk2acNJJh/Lee+8zevQ7NG9+BM1bnGKOtWSlxHFZUpM6XU7iiThr1qwGlzM1Y6u43IQ3bGD2rLmp81LLgumUGux2GzidWRU7edyhJBGLRtEKC9GLitCLitCKikgkT8WWJSntgObMxsKa/bbG1Bn50DTat+/Ar3+E+fLjT8DuIFJcTLgwHz0SAruNO26/k2E33kRBfgErV22gU6dO4A8Qyc8jWlhoOgEoKmLOvLnmLhpFBoedrqd3Y8685az6eyVObwBFVpAVGbvNDsCEiROIgbkDqQp7BQcoWU2NUyKAbM7KCkDoCSRJoGsJFKedQQMvYdLEmUyc+DUXDBiA3evF0DTAQBI6Qje7ehgazpwAjY88gtGjPmLLn3+i1qqDrXZdcLh4/vkXWbcOauRWR+imZwtD19MmmwSKIhMMwvLlf6MV5KNpCXMGWBgYyXus5QhhGGaehWGegypSA2jMP/UKxs3JdzcMMHRz91IkTNvWrWh+Yg433HAba3/7HVfNWrhr1kbJrcnn777H5MnzuOyyy6hX/xDcLonp06Yh8rbjqlkLZ40aRMNhXnrpJVat3ISqqKYGj8Xpf/751KoBt9x6K+HCIpy16uCoWRvJ4+PVp5/j++9/oVG1PTPBVIWycQCSNZuoJSKhYwCyiIOkI6NjhIN0aNcWpx1yfNCrR3cIh0BPmETQ40RjgNBMraJp3HP33cgCunTsxZ1X/o97h15P745dWLV6LffcNZCCvHwMQwOhE4uGScRjgCARj9Ogfj26dTmW2299jqMan8yHH34E3hpoiTiJRBQJA1kyu7gSwpxFNjLXl00ig6FbXfUSzZqCZJjLTUacRAwkIwFaBMVtZ8Qbr5MTcNK5Yx+uGzSE+4bdxiVnnsOFl9zB0KF9Ofe8fmBTeOCB+/jsy19p06oNd153PdcPuZy27TuwaNEiXnnpSdauCXPJRZeQt3EzNRvUZ/y4kfz682+0bdeOW66+lluvuYEze/Zm4uT3eOqpB/H7ZJOs6Rss/i3K8M9bXq/mvw7l/vvvfyA7MBuSJLF8+d+MHz8hFTZw4EAOP/xwszu5A6iqiq7rjBgxgm3btgFwwjFHcM7ZZyASYTAS/2plTpIkJCGwKQrNjqvHaae2wOt2gdDRtTh+n4dTTmpK3z49OOqoI9DiUWR0FKHhdNg4pdmhHNf0WLx2G4lIhFoNG3Bmjw4Eg3n8+cefFBYW0rpNG+6/7z7q1KlNzZq5HNvkaGQMGhxyCKee2pxa1auhJWLYVIUunTtxUrPDaHbiUTRvfjK1c33UzAlw8knNOLRBAyRhJPfyloY5PhUcfsShtGnTmro1czEMc8KpBAJJAlnXqVWjFq1ankyjwxoiS6BHwuQ2aMB5ffqSk+Pmjz/+YMXKFdSsWYN777mBy6+4HD0RJRYs5sRmJ9Cu9Qls3bqFv/5ahqbFOeus3tx+260cf3xTjjvuUGrWyOW4pk1Q0WnQ6DDO7t2TRDzGb7/9Sn5+Pi2aN+fhh4fT4pRTaNigPsc1bYrbpiIZZs9ltyGZa9qK3cnU6Z+x5Ld/AGhQvx6DBg1CkuTk/II5ut+bkGUZm83Ghx9+yC+//AJAo0aNuOCCC5BlqcwT/qzGSpIk7HY7mzZt4p133iGaHOr06dOHk046KeuuilEpPpicTifxeJwWLVqY5nfARWd3Y9yoV9DDW0ELZ1XG3YFkjg+r5UAoSCwazdjsbg9UA0OQKCoEqcQnmaLawO9HFBSiJRKpMabi9YGimhNRsgyKhAgGEcJAdjpJJB1y2wIBSCSIFYdSH8jucoLbBaoKxcXEQmEcXg/YbCQKzfssLVoWJElGycmBeJxYKGiOczPK2LxXCIHN6we7HS2/IC09CdWVNEk0DNMGUzUtsYziEJquYwgDWVaw+wPmfYk4KAqoCnpxMYmEhjMnBySJeEF+au3a6faC0wnW+rGiQDSKFouj+gMYwSCJeAxVSnbNdwOC5DqromLzBLj0yhsY/e43ALRu2ZyvZs1CkhXi8USlkPWg8sFUWTAMHX37NvRoFEUiaYRnil6wHb0oDxkdWehIwkASBkYihrF9G4YWT3ZPTe8VRrAIgoUQDWOEikgUbCeRiGAYCfRwMZIwkIWOXpCHHipGkcznKJJAj0bQ87ahb9mEHgmhyqCHQ+iFhcn8ZJvQZUIIg0RBHolwMNmolB1XkiQS4SCJgrwslziCRCSEVrANvTgfEQ2iF+eTyN+KoUeR0VAlA0kkiBdsRS/KQ8RDGKFCYts3oyciyCRIFGwlkb8FWSRQJR0VAy1cjJa3FSNYgBEsQC/YhhYuBj2Blr8dIxFDkSp+vyrsHv5DZDUrqdXOZnsSSYWnRDI9JyInf1vefK122pw8+j975x1fRfG18e9suf3ehCZFsPfeFRUbWFBABRUFEez+7L0LioqvCgqKXbEgTUDpHcWKooDSxIaF3tNu3915/9jdm5ubBAJCCJKHzyHJzOzs7Mw8c6aeMYw0lmkipLQ1XLk4sv8uHXtWHMatxJvXOLnprwxCSkfrZotjLscykaaBaaSRlumMkZ0JKctEsUxUaYFpYKVSSCONBmiAKiWKI+473IZMYCFNA2na43z7u0r9lCp8Xy22HP8hspZFWRJVhIpdy8JlifNT2tsQpWWT0UZlb6jMvXQiafsih8CZV2Y3KBU1LoBjYLxiKR8+N66sl9ViG+I/S9YdgW02A1qLWlSAXZSsW0YqW3uUdmcrQ1UnClyU11qblq3Ftopn86jVqNsTuxBZ/011tZ8pHdvmdvy2PM5cAm1KthW2R5ylyOl212KbYxciK5VWV1HJIr57EMeueqXPuiO2rSXqlmL7v6EWOwN2GbLmtvtldEAohKhbB8U5OSIdoro/cQntHB7Phr2PV62Q7NsLqqqi5OziURSBVicfzWvbPq4Itfpu58YuQ1ZySSoEKCqKx8cXk6fx+nMvUFBQjOLx2WZLs58TdngRDKFopVdg2HG67p6MQfHtA1uHSykRuhclEEE6Zmc03UM8nuKTgYP47Zdf0XQPStZJgEyjVEvYnRq7FFlLYXdfFW+AkmiKu+97hJt7fsjU6V9BKM+2mu9OKEnQdS/FJXF6PtqDOXPnoYUiCKGgebxsKCji8UceY8Hi3/AEHROlDrUqW9DIFufinPLuZWATVRGgh8N8NGQYr/d/A9UTAsUHniDReJq77+nH11/PAn8YKZVKu/3l46/FzoBdlKxO9Q+GmDxlOoYpOOXAPAa89wEkUqiqfV41sxlB00ibFh8OnsiCnxeD7sFCgq4TiycY8O5kfl/yFwRDGa2cTVghlDIicazyK6WGx7OJqiilYcuSTYA/yFdfzWTY8E+w0Gwj26aFrnu5+OJT2G+/A8GxgayUuXajNF1UQNjcxsIdx4vNNiS1qC7ssmTVdR0Mg+HDh3Ne63Pp1esp5s5dyY+z59gmYJzBqiIE+Hz4gwHq1FcJhsMQDKB5POD1Es6LUKcuBINB8HodA2ml0LxelLw8lHr1Ueo1QAnnoekeLMs22m2aFoqioPl9ttE1vw9Rpw6ifgNEfl2UQBghNEBBqB7wBYhE8ohE8tCCYfRAgGQiRSgU4YXX3+DUFqeRisXBsXKhCIEWCKDVq4dWvwFanbqogUA5EqpeH6rPB4qKGgwh6tZD1KuPqFMX1ecMDRyp+AhCLbY3dkmySgB/gAU/zObbb3/h/PPPp8VZZ7DPvn6GfTQ8c7+MotpGvNcs+YtFi36huNjkz7+X8c+8haxYtZZ1/yzj58W/k0zCX38t5Z8f57N6zQaE0EHoaJE6JONpxgwZTvfb76XX/Y/y/effgC+M7g1iGCBUncKiGKuWr0YL1WH1ijW89UI/Hrjhf7zVpy8r/voHEc5DKB42bixk7fyFrNuwkWgsxu+LFvL3H38gFEEileT7Lz5n5aqV6B77Bj3N40OJ1OGPxb/x+nMv8Mitd/FW3/78s2QpSl5dVN2HhYpUdNau2cC6tQWo4Tr8uug3nuvek+533svwdwdSuLEELZiPhWbvbN4G157UYsuxy5FVcWd1FY0PBw3mgIMacGLz48GjctHFFzJs+GTWLluB6vXbd98oKg8//Bht29zM8tXw/PMDOfHEi3jt1be5996H6djxdjZuhJ49X+O44zowfMRY1Lzd0PJ3Y/bMObQ8py09nniO+Qv/4MuvZ9Ol6x3c2O1/FBWl8Hgj6OH6jPx4HPfc+xijho2h85XX8vGo8fy5dDlvvvsep515CZPHTEA0bMyYCZM48eR2jJ0wm3kL1nDKaRdzVbeuWEhSRorb7ridb2d9iwgGUXUfqF76PfcCZ57djaEjxvDnsjUMHPIxp7e8gr7P9gNfPpovDy1Un6efeYGHH32KD94axLXX3cY338xlwYLfeax7X04/43x+nv8rnnC9TJWp7RpXP3Y5slpSonm9rF+6jHHjptK2bVu8eXmQStG2XTs2FMG0Tz8DfwAjnSadNnj88ScYPrw/++8Z4M47uzJx4iCuv+EGevZ8kvfe60t+Pjxw///4/POPuPjiDpAyWPP3cq7qdj1Nmu7BtE8/45PpnzLxsxkMHvI+Mz7/jkcf7YGieUHTEULj228X0b//6zz40CNMnDKVjyZP5vMvv2S/Axtyy+2PsP6PP2l30cVMmTacc887liOOasykSR/wyquv4vF5SaXTpE3TNvAmBEogSO/nX6BHrw/p2fMOpk2fzuDRo5g2bRr33ns9D/b6gFdeegURzAPVNoA+ZcosJk2exgsv9mPU1Kl8PHUqkyZ/QioN993/MOlYAk1z7E9ljbNrUT3Y5cgKQCDI5MlTSaXgoos6YEbjJONxDj74YE4+sRkDP/gQYjE0TUcIQdMD9+OEE45BUS322KMJR53WnD2aNWKPg/fh6GMOwx9QOOTQAzn4tNNosnsj8Ki83P9lAn4PQ4d+SL29miCL10O6hGNat2To0LeZOHEG38+aCX4vHo/G31G46aYbaNWpI9JMkt6whkDD+vzf/z3FxkKY++Nc6uyxJ/uddAr169clHA5x9KmncNjRRzoHoE0010yj38+fv/zGiy8OocdDV9LtrtvRFANz40o8Xotbuj/IQ7dcSK9eb/DXokXgD+DxeFgfg7vuup3jz2qBWbwBq2gde51wJD163Mvs2X+zfNlylC02FleLbYVdiqwCiaapkEwyesxY2rRpRbOjTkAN5+GN1IG6Tbjhhv8x98dlLFq42L4pDSARp6SkGMsySCRiUFRALB7FKikiWlKIZVnE4lEoKUBKk8TGDXz66XSuv/56lN2aQiKG0OwD7BQXcHSLUzjgwEbMmPEZKDrxeJyjmuqcc04rWL+WdCph22uKFlOvbl3ywlBUWASpFMSLSBtpDCNNuqCQZDRqr70K+25WhADNw7jx4wiGoOtVV0FRIemUfRY3HS+B4gKuv/46ACZMnACal2QywSnHNuH4k09EFm3ENFMYZgqKC9lrrz3QdYgn4pn7Y2tVavVjlyFrZu7T7+OPRYuYOfM30qbF4P59eatff97q/ybvvdiXhYt+ZWMaxo+fDLrPXmKhdJO+APve0zJLK9iGry0DRVPZuHEDq1ZFGTT4Qy498xQuuqAdF7e7mPbtLqZ96zZcdn5bvvhhFb8s/hVQMAyLvLx8vF4vGKY984sAqaCpOrrqWLYwTZAgpLCP6kkJFgjsdIjMreqSH3/8kQMObELdevUwU8mse2cVSCRp0qwZBxxQx7biiERKk0gkbNsIzlg+sElpmKaz0qQ45k/Lr93WYvtjlyEr7jKM18uo0aOJJWDOD9/z/HPP8uorL/PKKy/z4gu9GTVqJLsF4JNRoyletQaPxza1CRVdqWFvnLDh+tmmQi0TmjVrxlFHHcVhhx3O4YcfzuGHHcahhx7KgQcdyGP3XE7nzp0hEUdK28qFYRql9mayCJExelimtGx/IRziZk/2SEnaSKPrGrhbKGXpM6ZlWzaPRCJZ2yQlppm2D6dn4nd8ynx3LUl3FHYpsgqvj+Tqtbz/3if87/pz+PqbL/hixjS+mDGVLz6fzBdfTOb7779g5Ig3WPx7CdOnT0f4A7nRVA5hG972er34A3B5x4488uJrPNX7OXo+34snevfiyT7P8GSfZ7n/0UdocVoLu2u7GWzq5F3usTwpJQiVxo0asXbtWgzHQJdpmY7NYYmiKCSKili2bBk+nw9wutAVQQiEImwDE243uxY7BDWGrJVUlW0Gd8fS+PETWbUOLu94Gfh0Ao4E/Tohvw4YHH/c0Ry8n48hQ4eAYYGiZSqzrnmcC6rcS6rsLQIeTQehYBkmdevWY//9m9p37EQ3kCwqIrZxA/EN6yCVILFxA+e3asmHH34IrsGySqQMNdxMkhaqoqAqpd3xzNE9x8TLWWe15Odf4syeMwctHAGnCyxREJE85i9YyB//mI6FvWzribk/S3dyZcJUUFgVOP0rbOv4/guoMWQlp5r+W+RWeUXTIWUwcPBQTj6xEYcefRSycAPSSGEZaayULUa0BPw+Ona8lC+//p0lv/0BHj8SQSJlEo3FIa8OPl8ALIEiwUhCOpmEUB6K5kH4g1xy6aUMGfU9o4YOxduwEYE6dfHXrQ/59Xm5/2vMm7eGFqeeClYa6dwbYxv1NkttKGVsKTlEEfaXqYpCYWEhqqajh8J24yEdukoBiQSnn346B+zn5aGHHsaMxvHX3w1fMIyvQSMS6zZyz733c/jBeVxw/vmQjIK07Rnj2DR2r+vAvfldYtuOyhgdd7vppZK9FzoXmyvXsuVVi4pQI8i6vQoqE58iEKEQ337+BVNnruKqrleBV8c00hlCuNUMy4JUgg4dLiaZhncHDACh0KB+PfbZqylPPtGfLq3P5+MRI8HrpVHDhuzRrC533/U4V59/LmNHjQJF0KnT5VzS5gg6XdeD5x55lE8nT2X6pCncdfU1PPHcEJ75vzvZ98jDIR4lmYxTXFKElEYpWbDJKaVFYQmkUwnbsLdlcNBB+zNr3npan9OKx+65GyuVwKOrFBWlMIwUpJL4QgFeeqkfS5du5LTTTmPkBx/yw6wf+OidAZx22mksW1bI66+9ghb0QypBtKSYWEkxuHRzDbEJsCyDgiR2fpXhYXmSukTNLsfKfs91y5RXea7XoqaQdfugtMUXUkAqTWHBRu6+4Wx7iaS4qIJmwhYrHmX3xg15vtf1NG7YALOoAFVT6dunN9df05aijRtIp1Jgmmg+Py+//DKXXno20WgJqVQSkrYp1HffeZtXn72NcWPHcN2193DjDffy62+/Muz9nnS57mqswg2QiHH88cdydbcuaKpAGrY9XoF9E57f7+XmG89m/wP2tc2iFm3k8o6X8mbfOwgEdBLJEtJGAq9XpdtVF7H/fnshEyXEiwo4vvkJTJsynCMOO4SnnupF5ytupE/v5znl5OZ8PuMTDj3mCNLFGyEZ4+yzW3LxRRdC2r6pwM09SqI0adyEu248j7z8CBipTZtbzEKGfJW4V+Zfi4qxg418v4oZW4s0YmWKzm1Yt7aBdWPJ7o5ZlsTj80MohFVUZF+nuImqoqgqSjgCKYN0LIGUEk8gCMEQmBbESkgnHfdQCHx+eyYoGiWViCGRaLoHNZxHbN161m/cCAKaNGmEGvBjFRdjGgYg0AMB0DVSRYX2iTkAZ1ZZCAUtkoeMRjO3H3h8PkQg4Byvk/YVkKaFN5KHUVJiL7U4Y1ndZ1+UvH7lCkpKSohEItRp1BAsk0Q06nRxJZ5ACFSddFGRo9ltwkop7UMLoQhGUSHSMjJkrhxuvlaev5uEu4xba+S7DHagZi3VfBVL+Ra4qlIRFEUgzTRW4cbNEhXAMk3MwkLMeBSBicAkHSvG2rAWq3A9Ziru3FsjMaLFtlHvjba7IkAVEmkkMQvWEfBrNNujMc2aNUaYKdIF67GMlNP9NjHjUYzibKLacCewzOIiTNOw1zoVSKeSpAoLSBcVYBQVIaS9Bmo6DafqWPBXpMSMx5DxEuo1qMOe++5BnXoRZKyYVLQYTbGbNEWATMYhVoQipENUu1OrCIGZTmMWbERYlmODeXPkcP1zy7SKUtHF1rXYkWSlgmUAu7Bs0mVGblsh9rO5ME0zc5NbVeDe8JZt7d6yDCzLcNxL31g6SVQ2vJQmRiqBESvBiJVgGelyRrnd56R010vdf/bvViYdmZSBc/OcZbrPWvYlz9K+jU448QokWCZWIo4Vj2Il41iW4WhUm5SZ7zJdg93lczQzAVbFvCtHwC2SWlSEaiVrdoVTVQ0UtZIugFtguYVYVbHNsGQOdlcgW4rKjKptLXLTUwE9kFj2T2n/dJFJhbQvsZIOOTNPi1yiWfZTUrGlNIZNoLTJyDQbwpEqE3bbINtEjVXpFZj/fVQbWaWUZW7bMi27AkmhYQkVSyhYWQecpVDKiO3v/p0drrxYwh115RKgVKxcsmxS3Lhz3SuTTYe3hJOGjDgHuh3LEfZPe/HG/h6QmcWcir8r18/9PhMLE4nl5IvlHB6348v53UmbLbl/Z8XvfsM2F7f8FCQqEhV0r7OF0qlHbgJyGuddAdVCVtM0CQT87Lnnnhm3b2d9z99/L0Ov2xBL8yM1H2hepOYFzWsfANd00HSk89P+Xcv8bqlaheL6q7oHoemVSu5zlYuKpSpbKGoF8ZRNX2laNPuWcUVxLCgqCEUDR4Si2TfaOZL7Hbnixp8tUlXLCY6UdVfs2+80vUwZZKc3N+5tJ9nv9eLJb8CG1RuY9d3sTL0JBsMoqpa1fXLXQbWQ1TAMFEXlrLPOAuelfyxfzyPde7J86Sq8ofoo/joo/rqo/rrO7/bfrpstdTKiBeriCdarUHTHTwvURQ/Wq1A29fz2Fj1Qd7Oi+evgCdTDE6iHHij7jOavUyXJzq8yeVeJ5Ibb2vBbKoovv4xo/jp4Qg1Yt2Ij99z7KPOXFOHq1hNPOAmP14dl7nrd4WpZugEIhUL8/vvvnHXWWSxbtgzhdNf233M3TjrpBISiYjoXDDujTkdKUa4ddTf1uCGzAsjMhvSKIbLGQTsjtuX4eXtgc+lz9ylXBE0oJGNxZs+ezeLlG/EAKSAvFGbW97PYf//9icXjle9n3saoKUs31UJWIQSWZRGJRBg4cCBXXXVVbpBa1KJCqIBLhVde7s/Nt95CtKSk2ohKDSJrtagXKSVCCJLJJF26dOH9995j98aNc4PVohblYALhYIDXX3uNm2+9hXgs5kxO7nqoFs3qQkqJqqoEg0F+//U3Bg8axMyZM1m7fi26xzahUtW4FEXJtGpVfSYbm+umbW/kvt+yLFRNRVUUUql0meWKiiByrs+oSbCXeiWKoqJpGul0OqeMyg9xXAjHoJ2RNvD7AzRv3pzOnTtz6KGHkkqlSCaTuY9sd9QUzVqtZHWhCEEwEARFkE4kSaQSSGztWxpX5ZXR7/czf/48Jk2ayO2334FlWeUqP5vJhIrC7yhI5wzsDz98z7Jly7jooouJx2O5wQDnTOlmvm1HQgiBtMDn87N27Vr69+/PQw89RCDgJ502nHx3135Le13lIVBVzbbHDMTjMUzT3jhS3agpZN10872dYElJcUkxJcXFmJaJ1+vF5/Pj9XoJBIO2BCoXXffw1ddf07Pnk6xevZpIJB9N09B1vYx4PJ5KJTfsjhJNU/F4PHi9fsaMGUO/fi+h6zqRSB5+f6CcBANBQsEQwUCwRkrAHyAYDBAMBvnpp5944YUX+Pvvv/H7A/h8PrxeL16vD5/Pj8/nw++3f5YVP35/AF3XicdjFBcXb3UP6r+EHUJWAHeroWGaJFNpkskUyWSKeCxOPJYgHo9XKKZpkkgkGDb0I5LJNO+//wEApilJpdKkUrb50JovadLpNIZhoqoqq1evYMiQocyc+R3Tp09HUbSs7zEzv6ecvCofX80Rt1f0+uuvI6W0D9kD6XSaVCrldGc3LYlEgmQyWaHW2lWx48ha4chFbLL7C+D1evnyyy/55ptvABg+fDjr1q2zjY05z9sNsBtXTRYbuu5l2rTpLF26HIAPP7S7WpqmAe7QIPfZmis+n585c+YwefJkAEaOHMmaNWvw+32Zb7ZR/llbalERdihZtxSaZi+NDx8+POO2ePEvzJgxA32ns2drV0xdtw2yDR8+MuMzZcpU/vrrL/xbYv+phsCdGBs0aFCm2/rPP//wySefoCh2+e3q3dmtxU5FVp/Pz5IlS5g0aVIZ9w8++AAppW3Nb6eCrYV+/PHHMt+0atUqPvnkEztEhZMvNRder5f169czbNgwcC5+Bnj//fdJJBI7YaNac7BTkVUIwccfj2Tp0qVl3CdNmsScOXN2Ok3kaqGBAweWW5IYPHgwRUVFZUyh7gzQNI0xY8awfLndpXe16MyZM5k9+wdnuFKLrcFOQ1av10sikWDIkKG5XqTTad5//31wCL2zaCO/38dff/3F4MGDc7344YcfmDp16k5FVl3XkVIydKhdRm5j5JbH4MFDIGs4U4stw05DVo/Hw4QJE5gzZ06uFwCjRo1i5cqV+P3+nWJMJIRAUVSmTZvGqlWrcr0BGDJk56rcPp+Pb775ms8++wwqGJuOGjWKZcuW7XQ9oJqCnYKsbmV1W2yyWmv359KlS5k0aRKapu0UmlXXdSzLLDNZlpvucePGMW/evJ2icrtadPDgIaTT6TJuLlasWMHo0aPLuNWi6tgpyOr3B5g5cybDhw/nzDPP5Prrr8+02k2aNOHBBx8kLy+Pfv36UlxcXKPHRS4hvV4vU6dOY8qUKRx66KGceOKJmW/afffdadmyJclkMtNFzq34NQ3BYJDFixczYMAAjjzyCC6//HLbjI5lkZeXx9133004HObVV1+t8WVUU1Gza4BTuS3LZO7cuTzxxBN8+umnHHbYYRl/VVV56KGHWLBgASeffAoLFiyo8RVbURTS6TSTJ0/mjjtuZ+bMmRxyyMEZ/wMOOICpU6cycOBAfv31V5YuXVqjZ1GFs030q6++4s4772TOnDk0zjqosfvuu9OnTx/mzZtH8+bNmTNnTo3+npqKml2rHZSUROnUqRPdu3cH4Ouvv8747bbbbui6RtOmTXnhhRfYb7/9iMfjWU/XLEjnHGcsFuO2226jb99+aJrKDz+UWkPYe++9EUJw5ZVX0r9//8xm+JqM4uJi2rdvzzPPPEM6bTB27NiM3yGHHALAXnvtRf/+/Tn44IOJRqNZT9eiKqjxZJXORm+v154V/fPPP/nqK9uGLMAxxxyD3x8gkUggpUUgUPPHd9I5fbT77rsDMGvW98yfPz/jf8wxxwBQUlJCgwYNyM/Pw6rBx8LcMnJ3KH388cf8/vvvGf9zzjkHHEJLaREOh8pNPtVi86jxZHVhOmY8Ro4cwYoVKzLu559/vuNvYppWja7UuXC1ZfbSTSQS4dRTT838nUgkdpr9sbruIZFI8Morr2Tc6tevz7nnnpshp2GYO8331DTsFGSVUhIKhVi+fDmvvvpqxv2QQw7h1FNPxTAMLGvHHJ/6NwgGg8ycOZP33nsv49a6dWsOPfTQcpskajo8Hg+apvHkk0+WGaZcc83VNGvWjFjMPvLnDgNqseXYKrLmLjFsb9h3iMLTTz/Nn3/+lXG/8sorqVevHgnnDtKdCaFQiFQqxYMPPpi5FgPnmzRNw3DuvNkZYB/x8zJo0CB69eqVcd9999255ZZbkVLuVD2emgpla3b8VGfL6PP58Hg89OzZk9deey3jfuihh3LNNddUYIWg5iMcDmNZJnfeeSdffPFFxr1du3ace+65JJPJneKbFEUhHA7j9Xp57bXX6Nq1axn/Pn36sMcee9ROJm0jKG4LvjnSClFWCW/vyuRWBF3XeeaZZ+jRo0cZv759+9KwYcOdRqsKIdB1nXA4THFxMddff0OZxqdRo0Y899xz6LqeIWtleSyEQFEU9M0csN8e4h4YD4fDBINBFi5cyDXXXM3NN9+MaZaORe+55x46duy403XnazKUFi1a8Omn0zMOLmmzhczZylK462RVqTCuVYRsyQ1jWxDwEgwGMhVh8eLFdOzYkYcffrjMu/v06UOrVq1Ip9Pl4q1p4vF4CIfDhEIhvF4vn346nbPPPpsBAwZkvkcIwdtvv82BBx5ISUlJpevEmqZm4goGg6iqimWZ1SZSSoqLi1mxYgVTp07l9ttvp3nz5rz7bumYG+Duu++md+/epFKpGr/ktDNBuOe/zz33XDp37swpp5xCw4YNCQQCZTTtuHHjaNu2bebv6dOncdZZ9i4bd+rehZQSwzA2qR2oYMugYRgUFBSwePFiBg0axKhRoygpKSnzzLPPPsv999+PYRibHNeVvcipop7BvxtDVSU+RVFJJpP8888/fPvtt4wYMYJPP/20TAUOBAIMGDCAjh07Eo/HsCw7z7LzzW3MLMvkl19+5YsvvmDx4sX88ccfrF69qlxatgfcMopGoxQVFbFy5coyY22cXVmPP/44999/H5Ylicfjmefc73F/bqoXV9NQU2wwZcjqIhQK0bhx48wOFCEEmqaxfv16fvzxx0y44447jkaNGmVImQ0pZRlDarn+VFBYpmmQTCZZvnwF69atK+Pnol69upxxxpkZK3e5cWSjonfuCKxbt44//viDwsLCXC+aNGnCm2++yQUXXEA0GsU0zUxvxm0AQyF7TXLKlCm88847jB8/PjOzWpNwyimn8OSTT3LmmWeSTqczw5Nasm5Hsm4K2Rlc1RfUomJcfXU3unfvwV577UU0Gs2Q012Cck22Lly4kEceeaRGboDPz8/n9NNP5+qrr6Zly5aEQqGMFcJc7Mz1pcaQ9auvvpQvv9yfr776KnNguDLktpK1qDrcHUstW57Fddddz8knnwzOLiWcvJVO99etHKNGjeK6665l/foNZeISQtC0aVOaNm1Ks2bNylSM7YHs8g4E/DRq1JhDDz2U4447jv333w9FUTPj08rqRmXuOwNqDFmlE3Lt2rXMnj2bH2b/wIb1GygsLHR2BZl4PB7++OMPPv/888yDLVu2pEmTJuXGLS4q2qTg/u2uuSmKkvko0zTRdb3cRJYLtzJXFdur4lYVblojkTD77rsvxxxzDIcffgQNGjSALDu4ud/lFu5bb73FDTfckHHHmczr1KkTHTp04PDDD6dhw92q7ficm8bcfI3HYxiG3X3fFLak7GoaXLJ26dIlY6nRJWtl+7a3C1kty5Kby2iAGTNm0KpVq8y46ssvv+CUU07FsuxWJdtWuJJlLb6qkx+maWaIWtXEVwR3oqeq793eyM5byzLLmNfMzXdVVfD7AwwfPpzLLrusjN/ZZ59Nr15Pc+yxxyGEyGix6tpskJ2v9i3rZSfCcr/l35RhTYOiKASDwXJkHTt2LKqqVhtZFZzAm3vAnbrHCZ9K2QlMJpMkk0nS6VRGXLctEcMwiMdjxOMxEon4Vks8niAeT5Rzr0hisdh2l2g0SklJCcXFxUSjthZy4ea7m69+f4DZs2eX06h33303kyZN5LjjjieRiFNSUpKxq5t27A9vb3H39Lq/59aZ7G/ZXF3a2aCqqlM/S09z+f3+jDG46kIZ9ZOb4dkZn2sR3V0AN00rU5AVSW6hb0pyn90acbvfpmltViyreqQqldfj8ZBMJnn44YcpKCjIuN9999306dMHgKKiIowaYpm+JqShuqAoColEgpUrV2bcIpEIXq+3wiW77YV/3VesiYWW29hUJjUJHo+H8ePHM2XKlIxbmzZt6NWrF1JKSkqi5bqatageuHM28+bNy7gdeeSRCCEqnPneXvjXZK3Fv4em2d2st99+O+MWCoV44okn8Hq9xGKxSnc11WL7ws33Tz75JDNzr6oqp5xyClSzsqqtATUAfn+AefPm8eWXX2bcrrrqKo455hii0WiVu9K12Pbw+32sXLmSjz76KON20EEHcfDBB2cmV6sLtWTdwXC7tt9++22ZrZXubLBVTbO9tSgPTVNRFJXXX3+dn3/+OePeqVMn6tevTyxWveaDasm6g+GS9Y8//si47bHHHhxwwAGb3Ptci+0Ld2119OjRPPvssxn3/fbbj6uvvnqHzHvUknUHw10WWLJkScZtv/32o06dOmWOnNWieiCEwOPx4PcHmDhxAtdffz3JrGN+Dz/8MI0bN94hZ3RryVoDYFkWsazN+Y0bN8br9dZq1u0IkXMMVFEUfD4foVAIRVEYMGAAl19+BWvXrs08c80119CtWzdSqVS1a1XcHUy5jrkQQjBlyhTOO++8TCKnTp1Kq1atKC4uzg1eiy2ArusoikK7du0y95l27dq1jF2mWlQPioqK+OKLL3j77bfLHZy4/PLLeeONNwiFghQVFaNp2iYJuz12MNWSdQejIrKeeeaZ3HnnnaRSqSpPMFW1wP8r2FZrzkIIUqkU338/i08//YyFCxeWy/MuXbrwyiuvEA6HKSoqyiznbCrPa8n6H0QuWcUWHlioxfZDOBymZ8+e3HLLLQghMofpq1I+24OstWPWGoaqFlwtth/q1atL586dnetN7sA0zRpxy0OtZt3ByNWsOPntml91kUtiXdczrXeu366AfztTrihKZrOJEILGjRtzyCGHcMYZZ9CqVSsOP/xwcG4RqEq3NxfbQ7PWknUHoyKyXnTRRTz66KMkk8lKK2Xuria3crioagXYGSEcS5G53+z6VeXb3TCmaRIMBmncuDGNGjXKxOmeanLPXFclzmzUkvU/iIrIeu2115bZJ1wRcm1fVVRxq1oJdjYIxy7YprC5b8/NLyll5vSXdM4JC2dJR27FBojtQdbaMWsNRCKRwLJM4vEYJSUlFYrb8ruSSCTKSe6Z4f+KJBIJiouLK5XcvNqUZD+TTCbLdI2poAezI1FL1hoOt1WvlbKyKWzOn6x83ZlQS9YaippilqYWNQe1NaIWtdhJsMPJKiq4rmNXlIrzxJ6J3FWlFmWxw2aD3SNItbBxwQUXMGHCBHAMgA8Y8G5ukF0ShmGQSCR2uvGl29iIbTgbXO1kdRMvpcXixb/www/fs27degzDKGPC9L8ON9vdDeFvvPEGv/32GwBHH300nTt3Jp1OZ/ap7kqaRkqJ1+uladOmHH/88eyzzz6ks67k2Bmw05NVSkkkEmHZsqX06NGdjz/+hIKC8nfA7KoQAhRVwTSqtnl/V0DTprtz7bXXcs899xAKhSgpKcG+9aVmY3uQtVrHrJFIhJ9++olzzz2XAQPeqyVqDqSklqg5WLZsOU880ZPLr+jIunVrCQYDbMH1TP8pVBtZvV4vGzZs4KabbmLRolJ7NrWoRVUwYfwk7rrrLhRFRdPUXZKw1dINFs7Vhf379+e2227LuDfboy733ncH++63B6aRRMqsfbBi08mqyhhuc90LmXVu0coKq7hdGEUpE8Z2lNugogiQyia6cxKEtQ3es7XYXPq2LxRFQ0rBnDk/8UyvV0lnXaf0xZczaHHq6RQXF+2w9FUF26MbXC1k9Xg8SCk577zzMpdbhcIqw4d/yHnnng+UAGkgmxibI8Wm/KhCQbrPVxZPZc9XFD7XrbJnsyEqCOf+LZ28cOPNDpcdxkXu+/8t3LTlpq+6oAAaEOT1t/ryv5uezFSHO+64lb59X6Yk6/7fmoidlqzBYIBVq1Zz0kknsXTpUgA6XHI2I4YPpCSxGsNw7Q+VJsX+1s0mDSklqqqhaSrptJGx5eoqXjfTKsoPKWVGo3q9XizTxDRdu0ebrqia5kEognSq1JgWWe+r6HlFUdA0FUtaGOlcOz7Zmqx8YoVQ8Hi8GIblnMRxyVw+rO7xON9S8YmdqqF8vNUHgWUphMP5GGnJ8cefxsJ56wE4++yzmDBxEkbaIJ2uuTaqtgdZq2XMWrpMUXqRz7777g1YWFYSMAC3AlZFJFJaSGllSJ1KJVFUkfnb9jexLAPLMpDSLCNgIYREERKwSCYTpI1UBe8qL0KAaaYdotrP56YvW6SU+P0B/P4gsVgC07AIByNoul4ubClJSv8WQiAlxGJJFEVH0zw5xC4ryaR9EKC0wdtayf2u6hNFMUkmo2i6oEnjhm61QVXVzDBlV0O1kBXs0wvZSty0XHJWDFnB5u1sAYGi6ESC+fTt9xKHHXYqn3/+JZFgvvNZuVIeQgh0jwdVUbnuuuvp+2I/QqFIZl+u5WjebAEIB8P069ePW265BVVT7YPMjn9uOqWUBIMhfvttCV2vupYjDm/BySefSb+X3kTgR9OCgA5SB6nZggaombT7/WH++Wc1Z7e6gLvuvB9d86PrPoewrkZW0D0+VNVD16u68cwzzxIIhFEUvYK8qOkiMo2RWcFFxdnzC7sSlFyH7YlsdW85F/qIzNay7AJwW/ZNQeDxeFm3sYBhQ0ey7C944/W3MSRomreCgs8WG1JKFCFQFJWffvyFP/74Cw0vQqjY7Ur5ZwAUNP766x9++mkBAhUh1Kww7k87/V6vl1WrVnPFFV1YuPAX7rvvDlq3bssjj7xCzyd64fOFUBRP2cqa8+mKomKkDeb+sJG3Xp/Ce+8NJuithxBamTQqwk7LokVLmDdvEUJoTtoqyodcguSSJdctV3Lj29ZCph5Y1XhTW02GkuuwPZFN1mw3+9q87O5X+XC5EELg00JMnDAdy9R5/oVbmDrlF2Z9Nxuv1w8IR0O6BW9XAiEUdI8Xr9eHx+NxGgpBIOBB1/3lKqMiVHTNg9/nx+v1OuEVNC2IpgZsrYhNViWLtG4j5NcD9H/5Vf74I8qUKdO587YneP6Zt+je/WZeeukjli5djs/nt3sZwnSkfLdQKJL8ehDJh4ceepIFP88nL1g3K632cENK8Pu9eL1BjLQESm+XB4miKHi9Pnw+vz3uFgpIUUZ03Yeq2hpZUXS8Xr/zt5un9hha03W8Xi+6x1Omy60odo/F6/U6Xf2KkFveFYiQCEWSfSeXlPYsvhD2vISbz9taaiKqjawVEbU8qkZUsLWNhcl77w3klFNO57bb7qRePRg8eBi68Ds3dJfGZUnw+QLkBeuSTpkUFpZgmgKfVgdd92GZAkVoTpaoIBU8uo+8UF0UxUNRUYx0yiISrAsEsUyR1VUVKFlH2twKbdvu0Vi+fAWNGupEInlEk8uBEo4++miEgI0bClAUdyxfQYV1JJVKYZrQq9djNGhQh9tvvxMD6XSHyzZKtiJSMhpfWiCESiiURziQTzSaoLCgBCE08oJ10T1uHLbEYnFSKRO/P0w4kE8sliKRSKGqHiLBOmiaj3AwH4FGQUEJRtoiL1gPVfXi9QYIBfJJxNMUFcXQVC+RUJ2c3oqL8t9ZuWw5VFXZrEWJnQnVRtZtjZA/yHfff8fs2b/T6Yor8Gq7c9llHRg7dgIr167G6/VljW0E4VCEjRuLeLh7d0488TSOOupMzjjjHPq98hKmqeDx2NoYFKQFgUAIIXReff0tzjjjHI45+gxOPeVs7nugO9FkCaFgpMIWONtNSgtJmnbt2rF0aZqZ38wk6G0ASAYNGsQhh+zGvvvuUyXLeVJalJTAHns25c03Xuezab/xTK9n7e4was49oe46qf0tNikbsGjR73Tpei3HHXsKRx55KmecfjZ9X34F0AiGIqiajiXhlptv57NPv6CoMMa119/IUUeexLRpn5NKWbzQ9yUSCYMPPhxKq5bnc9JJZ9Kixdm89OqbhPz1iccF99z7CKefdi4nHH8657duz9RpnxMJ5qMqbs+jfL5tS6iqbV3f7w9kbjWoqKw2hS0NXx3Yackq8DN0yFD2aBbihBOOBdZx6aWXsGI5fDr9U3xawO7WIQgGwyxbtpJWLc/hw4HD6dLlKnr1epQO7S/h7bcHcNuttwMiM8vq8XhJJU1uuvFm7r33BY479jgef/wRrrvuembO/JbOnTqzfsMGvF5flvauSBMISuIxLmjThosvbs6jjz3GP8t/4ZHuDzFx4gx6936eYChIKpXcbP11tfWaNas5vUUb7rirA927v83ced8TCdXJ0q6lGhYEQqhEQnl8POYTTj/tIn7//Q9uu+1WnnrqUU47rQUPP9yXDu07sHFDAUF/GFXR2bCxgNmzf6RDh0v59bffuOWWGzn1lFNZvnwlvfu8ykMPPspbbw6gbdsLeerJJznl5FO545YXebznk9x26x38+ec/3HXX3Tz66COA4Lxzbmb8pEnO5N/2g6ZphEIh/P4A69evp1+/fnz44YeOnavNZPBOgJ2SrD6fnzXr/mHc2Il06nQZQb+fkth6jjn6cI4/rhHvDniXRDqFrnvRNA+q0Hjg/odZvyHFp59O5NEHn+bqLtfw0P3dGT9uFL/8+jM/zt7ojB0V/J4wb731Nh++/w2DBj/Pa/0/4PprbubO2+7hsxmTady4PoMGzcDvDzgtsEvQ7HGmTdh02iDorcdLL/VjwYK/OeigFkyfNoNhQ9/jjBZnUlJciKq4cVBpt09admWzu7gGTz3dk/3207jqqm4UlUQJBsJIp3EC2xqflJJwIMySv/6iS5d7aNXqeL786jPuufNurrv6Gvo8158JE99k8oRf6NfvJRTs5SRd89C//2COP/54ZsyYzoP3PUKzJnuiqSoFG2HOnB8ZOnQIDz/wJF06XcNr/d/nqqtPp2ePd/H7vYwaOY5ru13H9dfczKTJY9hjb3jnnXcR6E6Xv/z3VRW5wylVVQgE/IRCITRN46effqJHjx6ccMIJ3Hnnney11154vV5M00JVlYy4Y9Psv3E0ak3Uquy0ZNVCTBg/iWgJdO50JRIDRQi8eh433ngj33zzO/N+mo/PF8Tn8/PjvHlMnDibF/r0Yr+9D6MotpSCklUURpezx+778X//9wwA6XQK0CmOFfHmW2/T+armtG93GSWJZRRGl1IYXYZH8dC9x2Pk59uGzUoLNpdk9tponUhd/lz6K3fffTcNGwZIJKBlq7M564xLKI4VoigqoXAYVd3U2KpUY9rvixLyh3njjddY8FMRPbo/jk+3tWL2NkFbG/v44IMP0DXo06cPqoCCkpUUlKykKPY3Z5zahsefupIB7w5m2crfCHgDrFu3nj33jNCrVy+ktNhQtAKDGCBJJODKK7vQrMmBrC/8h4LilUCcc887B4Cu3boiibGhaDmF0aV4FD+tWp7GX3/+RTwVzxqfbx2EEAhFoGoqoVAQvz9AUVExo0aNokuXLpx++un07NmTf/75hx49enDeeeeBc5O8vdZtSzAYJBi0n3f/DoVCeL1eVPXfpXF7ocaStVRHlBWPpiMxGDx4OGeddTJ7NDuEdEoihAeQnHtOa/w++PiT0ejCg4aPefPmE4nAsccdSyJdiGFYGe0TTxdwxOFH0HRPSKfTgMo///zNmjUpLrywHZDO7DaSUlIU20jjBk1p0eJo4rF4VksvsrqiClJCMBjh9yV/0KplK5Yu/YfPPvuUDz98nl5PvcuQj14nHGhKYWEJn3w8mrVr16Fp2mZbdeF050oSBZx1+nnc+8Bl9HvxEz77YgZ+T32EsPfVSmlvIEiZxYwbN56zzz6RPXbfh1jCvgLCNnJtAkW0bdOWgo3w448/ItBQFEHbtm3xaiFi0WimEbIsk0gEDj74YCDq9AgswCCVStGkGezepCmJVDJrws1EUVWisRiGaW72+zYHIQSa6kFTPSxe/AvPPvssrVu35uKLL2bo0KEUFtonuXRdZ8mSJTz88MPcddddlcpDDz1E9+6PMWDAAGbNmkUikShzm1xNQs1KTRXg9wVYvHgxn322hG++nknLlqfSslUrzm51Ni1OO4X2HTqwYT2MGzuO1evWAAFWrlhFJOIjPy/PtgeLqwgFlmlhWRY+n+4QT6W4uBjTgHr16iFxFuUdTtrLTBb5eXmQ0WHub6Wie7wkEkm6dOnKnnvuyZQpk9i9UTOu6HgJt91xEddeey+//D6HFSvWcM01D7Fs2QoCvmCF2yLLam37d8s0SMtievbswVHH1uWGG26ksHg9QX8402hoQqMkGmXdug00a9YMsDANM9PwKIpCwojTqHEjGjaCdevWAzaRw+Gw3VCZRuk7pYXPBx5dRzo7wNxufzKZRNNskgAIxe0FWFimmTFRU/otFX5oDsoTW0rJxInj6NqtC6ed1oIHH3yQb7/9NuPvdmMty2LgwIE888wz9O3bt1L5v//7P5588imuvfZaTj/9dM4/vzXPPvssCxcuJBgM4vV6y3W9dxSqlaz/7qPtZwV+hgwdRn4+dLmqM8cdfxQnnXQsJ59yEs2bn8i557bi9jva8cviYr6b+R3gRSCQpgWWREhQhFKGWqpi/205GldTVBThhnP/SYSU2IrNRFUU+zkJIoeoQih4PV7GjBnDvPnr6N27Nz7dz4aipcSSG+n34rOcffbhXHppB0Z9Mpa6dXV2b7InadN+f0WV1D2FZCsm+/dYrAS/x8M777zB778k6NHjCQT5zq4lOx5N1ZDS7TVkzxjb5SGExLIMjLS71GQveaXTWXusnXVfu6ECRRVIDCRG5nSQ4oz/7C2gMrOl014jdt5nSefTqlIPnHXfnLxIJpPMnjOHyZMms3atvV+4ImxNXUskEnz55Vc8+OCDtGzZkp49e1JcXEwkUvHMf3Wj2shaceaVjq82D9vUx/qNKxn4wXA6dbqAJ3u+zLP/14fnn+vDc8++wHPPvsDjPZ6nX9++7LOPzoB33gEM9tl7X9asSbF69Wq8Xm+ZvaUe3YORNijcmHYqq6RevXqoCvy55E/AWyYNihBITJYvX77JlGv4+OvPv8jLg8ZNmpA0i1EUi3Q6jkmKDz54lzp18vi/Xu9z6aUd2XevA0gmUplZ38phayV3I0lhdD3HHHkCPZ++nn4vfsT4ScMJBsIIoWJIk3AwzP7778uCBQswMFGz9mcDeNUAf//1NytWQKNGjZw92qVLF9mTqC5Z7TS4k2iVacmyYaQlt6Csy5PUhaqpPPpIdxYsWMA777zFeeedRyBQasvL7TVomsaRRx7BiSeeyLHHHluhHHfccZxwwvHsvfde5bq8q1evpkePHlxyySXMmTOnRnSLq/XtZQnrFkjlBZMLnx5iypRpLF8Bl112KZZcQ2HxKgqL11BYvJLC4hUUl/wFSLp06cy06fNYvmIRLVueha7BiBEjUEQYr9eDIkDXNTQ1n/ETJrBmDQT8ASBFs2bNOPTQ3XnnnXeQJO2CEgJFCIL+BsyfP58pk38hEAzmJjELBocdfhhr18KC+QvwqnmZwjZNk7zQvrRqdTYA8VgcsO9vqSpsTtv5GU9t5JGH76d1m8O57rrr+Pvvpfj9AUzTRKBy+eWXMuOzP/jh++8J+eqjqipCCMdgnYe+fV9m//19NG/enLRVcYOhUDpLWpGWsd1yJct/Gy6dGGaK+vV345prrmPMmDFMmjSJ66+/ngYNGmTCpFIprr76Gr799lumTJnCxIkTK5Rx48bz5Zdf8dlnn/HEE09w1FFHlXnXjBkzaNmyJVOmTCEYDO5Qwlbbm3MvqC2L8oWbC03VMGWS119/nROOr8+JJx5PMhUrd5rGkgYWCS699BKSSXjr7bepV/cgbrm1K089+SHvf/Aqmu4hHKpPwBdmxMgPeP653uTng2GmgTSa6uXRRx/m669W8eCDD5JOm4RD9QmH6vPjT99x1133sHtT8PnKj2fclj2ainJaixYccXiEa665ge9mf0UkUJ/8UEMMA7o/cQsvv/w2l1x2Mm+/PZIX+j2H3+OvkAg2JNKwT/vkarVkKo7A4sW+vYlFJatXWmgOIRPpEi677FJOOLEhV17ZmbnzvyXsr0skUB/QePTxhxkxbC73338f4UBdkqk4qVQCw0jYWtbtfjsTcslktoYthWmZJJNmjpa1y9UwTJLJ1DY5uK8IgbQkqVSCaKwEyzJp0aIFb775JjNmzOCFF17gzDPPBKB3794sXbqUunXrEolEykk4HCYvL48mTZpw2mmn0b17d6ZNm8Zrr73GPvvsk3lnQUEBV111FZ9//jnBYHATZbR9UW1k/bfwen3MmTOXuXPXckWnjmiqSioVz6q4NqSUxKJR9ttvX8499yA+HjmSkugSHn30Ya6/4SxuvfUpzjm7NVd06kSrs1vz0IOPcc8993H+BSfbmxOwiCeKOOfsc3jzrfsZMOBjmp90Khe370Dbdu1p374Txx9/CnfccYtzBK/8qRApLdKpFKFwkHffexuPB846qzPnnNeWy67owmktzubVVwfz+OP3M3zYJzz+xPU8/vjLjJkwGp/PV0FlsPfHRuqA3+9xuqpZY0IBRdECDtz3IF7s2x0Ar09DCPvoYCAYYMiQQTRp0pizzrqM1m3bcOnlV3By8zPo//JQ+r58F9d060oivQ7LSpFfJ0ggqGLh5i9Ip+sdDIK9+uLmuZ1WXVcJhT1ZaXJvXpOEQkFCIR9gbdXxtoo0vZR21zqdNjJ3/xxyyCHcddddTJkyhUmTJnHUUUfx/gfvk06nSaVS5e7McSUajWbuu8nLy+Omm25i8uTJnH766Zn3rV69mptvvpnVq1eXu46zulAth8/9fj9Lly6lRYsWLF++HIB777+B55/tSVFsGZaVyNIUNrKL1J680Fi1ahUrVqzikEMOwePRM1vJymtmYe/E2bCRZcuXceABB5Kfn4+qanz99TcMGjSYVatWc+ihh3HZZZdxxOFH8fPieSiKoGnT3TEte/YyFAyxePEvDB8+koULFtG4ye5cdNFFnHZaC1avXs2aNSvZc6+mCGEhK9AaQigEgyHWrFnP9GlfMnnyNBKJOMccczQdLmnPgfvuR9KMIwR8990s/D4vBxy4f9aZWzs+RdFIJFIsWfI3uzdpSp26dbAs1wyO/e1SClRVR1F0fl60mEAgRNOmTZHSQEqLSDhCLBFnzJixjB83nmg0ztFHH8PF7S/m8EMOpSReQDqdQhGCv//5m2DQz267Ncj0iBRFpbg4ytKly9lzzz0JhfyOlgdV1Vm3biNr1qxlrz33wh/wYllp21qjorJixWqiJXH22WcvhGIi5eYOjdvfpGkevF4/bdt0ZPKERQC0bHUmE8ZPcCbBjJxyt+uqrut4PB7S6TTLly+nbt26mQYwuydUvlG0IRwzROvXr6dbt26MGzcu0/jceuutvPzyy8TjMYwKju+5yB4ybKvD59VC1mAwwIoVKznxxBNZsWIFAF26XsgH771BcXwFpmkvuFdGVhe6phPwBYnGo6TT6XKZLbNu/5JSEgwG0FSdaCyKYVjouk7QH3JC2zOfpjSIRUvwB+yWPxaPuxRBSDujVZF92NsiGitBUVU8uk5xSYGtTco1/u7kmcTn8+HT/GV8U1aKeDyOlBaqqhLyR0gaSRKJ7Lxw80OgKBqhQJhYIoFhpJxlE/uUjRsmO1zaNJyxcCl0j07Q60digTPHnZYGsVg00/DZO4ICmKZh36rmaEecRjMUihCLRbEsd0nHPiTh0b34fH6iUdfcSqlfMBBEV70UlRQ6hgbKd6PLwv4Wvz9IKmVwyslnM//HAgDOOacV48aNw7KsCsmaDfc6zS2xN5xLsuXLl9OuXTvmzJkDgM/nY9q0qZxyyqmbrPu58ew0ZHWPop122ml89913AOTlq0yZOoYTjjuBtFyPlKUL5g7dNlEMFcOy7LXD7IpuSctZoHfOibrHqlDtrpSUdkjXQFlmosRewrC7bQJ7cac0Y6W043bfJcodQ81mrx3ObVvsONz3uG5ud6807dlkLf3p/u5W+Oxcyg7n/Mwsf9hHztxus4KCmTFQZ48Dwd4dlA3b3X22FOWVUjmHMumQljspVnbYUhlUoaIQ4YNBb9D1yscz7jfceB1vvP4WiYSr2Sp6bymqSgQXuQogFAoxdepU2rRpQyplW27r2rUr7777LolEvELtmh3HTkdW4XQr+vTpw7333ptxP/iQZvTp8ywHHrQ/yWQcHBMo2S3zlsPNqNw4KirU0rDZIUspkpXp5Z53CACVpDU7fHl/Nx+zewLZ4XIrTVnk3sS96bClKJ+OrUNl8ZStpGXh5ldlz5ZCCHs74cyZ33Lv3fexfl2p34QJY2jdui3xeBTTdOvK9oPX60XXdS688ELGjh0LQNOmTfn888/ZZ599HKPjlWOnIytOV3jjxgJOPvlkfv31VxQVLKdhbNK4LpZjU6lUc1WtBS6PbLJWHZsLXZ6s2walJN1cCrIh7BRlJnE2hcr8q/Y95UlnY1PvreyZqkIIQdpIsXF9lg1SoG3b1gwfPhwQpNNmJbu9tj3C4TAjRozg0ksvzbgNHTqUjh07Eo1GN5sXOx1ZcT76m2++oV27tqxfvyHXuxa1qBTHHHMko0aNolmzZhQXu1do/LtGoaoIBgP8/fc/nHbaaSxbtgyAe++9l+eff554PJZzlrgstiVZy02LbE+UlJRw8sknM336p5xxRum0eC1sCOEui9TChdercVXXzowdN45mzfasdqLiHHPcbbfdnAMMNv766y8Mw6hwWWl7oVo1K05coVCIZDLBp59+yty5c0kkkpimvTbnrluWH5NVfcxTM7C5dNr+qqYiLcmgwYP4+y/bpvLhRxxKmwvaYJpGuVbbngByJ46qgsrSUdXntw7/5rC3ZdlnT3fbrQGntmjBCcefgGVZlJREnS721se9NXCvJ73yyisZNGgQAGeffTZjxoxBCEEqlaq0678tNWu1k9WF3+//T9nH+bdo2/Z8xo2bCMBVXa/k/fcG5gbZZZFIxDa7TLM94ZK1c+fODB48GICWLVsyduwYFEX975PV/ThVrUo3IjcjspNcWfJzn6lpsHsJqqqhqAptLmjD5MlTAejSpTMffPAByWTSOS2Ti+rXLtUPO39KK/KO+2aXrF26dOHDDz8ER7OOHj2qWslaFaZsF7hZLy1729imxUJa9rlT11h4RjIGuK0scf7ODpcl5ePfOsmNd4tESixpF5Rlls6Cl82h7JzKll0DNYGo2aiMkNWFHaZZdVVF13XULThp8l/GBW0uYML4CQBcd921vPXW27lBdkmk02mSyWQFjVn1QVEUgsEgV111FQMH2sOTli1bMnr0aDRNy2yWcJFN6m2pWXcIWf0+H5qus3H9eubOnUthoW2LqLJN3pLy8yllP9DuMm0aWa2zewY6C5W9uyJInCscMo9U9P6qaQNVte8bffLJp5g5cyYArVu35s4773S2I5aNd0e37lVFbrq3BMJZP/Z6PRx//AnUr18/sxF/R8Ala9euXfnggw9gM2Qlq5x2arKGw2GiJSW89+57vP/+e3w/ezY41VpWUr03m8CtREXvqgq2R3rcClqLsjj88MPp1KkTt956K6FQaIvr27bAlmpWthNZq3XM6p5k6NS5M7fefluGqGQRwNVR2bK9kPueqsr2QFULbFfD/Pnzeeihh7j2mqspKiwg4Pchtlsp1GxUC1mFEGiaipQWd955J2PGjCnjrwBeFbwK+FRb/DniU+0wHs0RxQ7vVcDnirDFdfc4khsu1z833ObEo4CugK6WiraFkv3sjpBMPlYiueGrUzxa+V7PR8NHcON114Jl4PVouyRhq60bHA6HmTx5csaOK0DAJ7j++q6ccvIJ+DUV6Vz+KwAh3Y6xPTasSKvZ4cr85fwunfOlpcj5MzMGdp1zK8fmYG/9t0U66bNRmoZNQbgflftiaftm/WGjwnBbC9uo26aw9Xuz/z0UVSVtSL6b9QNvv/ku66OlfuNGjeSCC9sTLSl27s7Z/qgp3eBqIav7sTfccANvvfVWxv2Vl57m5luuASMOyQSlO7NLiVAqOcjsZMmuxRVU8u2KnPe47Yv7e2XIfqyyVqTUoXxcUpZ79ZajTAtTFoLy37alqGIFrBgK6F7wBhky4H2uveFRbBsecFWny3j/w8HE4wmMTezJ3ZbYpcjq9XpJpVKcccYZzHbGqS2aH8WEcSNRlRjJ6EZ8loXqxG13cSznZ8XJy2RGOcLayH2qfIgsCPeguJtxspJuVmkBuIfqhPNMRaE3B5uXMisu+1uEBPueQ9tdSsv9zQnnnjPdDCr76ApMfObC3tZoryeXz81NY9Mxbx6WUDDR0P0hVI+fNu0uZfzntqWIM05tzqTJUxCqRjJV0YaRbY+aQtZN94W2EYRjdDkaLT37t3vjRgR0BZmIoltpFAyEI2DadnqdA+gVia1dbLtAuUbTpDRBmo6fveEg+/by7KwxLAuhqohIPiJSB0vVMYVapqkopYjAlBJLgIiEEeEgJhZyE+nMpLcC2EpVOEfb7QZDOEpTSomi6iheH9K2LZgVzm1cKhcpSnOwnIjK/S0JWjCE6g8hUUFRkGV6MVWV8i5VFUVaaMJEpmMgDBo32i2TZ/FEEtOy95HvaqgWskrH3Er2PSeWYYBlolgmmjRRsiz2uVXn36I0jrJxZbdkmq6xoaCQqeMm8enkT0lbKii6U0FdlKZI0TQSKYPPJ0/js0nTKC6Jo+ierLBbBuEYYXAFQCgKQtH4/fclzP1hDtKybRmVDZdbxbdE3JdnbiQGIRCKgqpp/LboZ+bNnosQqjO2zX1+c1LmLVsM4RBWkSZYJoaRpbmEPd4uvc5z10G1kBVKuwW5ULbzrV02zeyfFUGEQixYuIiLOz9Ih8vuYvGvS9D9oTJZ42pXS4ASifDpZ5/T8rKHuOl/jxCNG+AJgNi2Z9uUcIQJEyfTs+dToKiIajg7J4RADYbo27cfDz34sGOAbfu/d5PYBUlZGaqNrDsWbke2goIXAsuSqEABMGnyNPAFEYpaqt+dE2mqqoEF4yZMwgQUHSzc29JdrWJ3U+1bx+3fZdZPW5wmRMn+3X2fyIQ3LIl92ETLNDuZ8NiasPSnk1AnXhAgSuN3v8UWJ45srepqUNW+mDmZNpx0bL4hLa9Xa7E9sAPJuiVnMrcFSgmb+1bLNKkbgbOP35vJk6cQXbcBVfdmje1siECQ3xYs5suvfqB9yyPxBcOknQlJU2JXbkVHhPIhrz4ivz7CH0KoOhYqMluEQPH5UfProNaphxIIo+o+e5yIbX1NUTT7WfcWczc9QqD5/KiBEFJRMCwLSwikoqD5A2h5ddHr7oaeVxePPwQiuyEoJaru9aJHIuh16qKFIqi+IKCgqB4UzWNbJt7EpHEuagm7fbFjyVrtcKtd2epnSYmRhksvvZRly5YzbepU8Aey0uhYJvR6GfjBIOrWq8e5551PyjBtkkpbMyrhPGJJg08nTeOtfv15t//rzJs7H+ENonn8Gc2qaB60YB7L/1nO8A8+5PU+LzJx9Dhi8RRaKILlaDRXy7riUkELRthYUMT3385i/cYCUDSk0NAj+RQUFDFq6Ee88UJfRg0dzupVa/CE8xzC2oJQ8UTqkEqZTB4zntd6v8iYER+zfvVaCOaBomJKysySbw5VC/XvIXbhbZk7kKw7ChUXdCIBBx90MEccfjiDhwyBtFHmXhNVU4mtXMno0eNo1+5CdtutPul0CqHYRNJCEWZ/O4sL2l3MbXfex2tvvk3vvq/Q5sJruO+eB0mbEkXzgKqjaF7693uFVud04MlefXj7vYHcekcPzm97Eb/+/At6KFLBWE0ghIpWpz4r//6HDh0u46X+r6J5/CiaB29ePpPGTaTVOa158OFevPnOuzzw0NOcc15bJo6dhDdSF6loWKh4I3X5YeYPnH1uO26+tTsD3h/MY48/xfltL+KLUWMJhvNcu6G1qEHYgSWSWxmrE+XfbUh7PbhLlyv5+qv5/PPHEhR/qFSrhSJMmjSZ1auh42WXYhgpLMtASFACIZb8+jtXdL6Rfffbn/ETx/HZjM/58usvea53D94fOJk33nwbNRhCz8tn5Cef8NTT73DbHTcxY8ZnfDbjc6ZM+4QGDRtyRecurFq2HHz+jHa1pECiotZpwMLvfqDdhe1p1LgJL77Yl/r166OHI3w+7TO6dn2Y0884i2nTx/PNzJl8NmMibdq24ZprH2LqxMn4w3UJhPNZvOBnOna8jnr1GzB+wgi+/PIrpk2fRteru/Hs88/xzcyZBAPBSju22a7ZI+FS2bbIXlPe2jXt/wJ2GFmFcI1k1wxIIB6Pcd65ZxMOw4QJk0HxItFQVS+kJMM+GslJJzVjj6OPIhGLgnQqq8/L8BEjkMBLL/djrwP2xR/wUKdOmMtvvol27ZozcuTHyGQaFMHECRM46shG3Pzoo9Rt1Aif18u+xxzNiy++yIoVab76+hvw+pzxsoqielHqNeTziVNpd3E3jj+xOYM+/JD6DXcDS2IUl/DoY49xxpkH0+e112i63754vR6a7L0HT7/0Ii1bHkavXv9HKpYE4eGJJ56iye55jBw5jIMOPxhVtWhQP4+bH32Ibtd04ZvFxaiabk+USftmglzCkmlKqoewLqp1mqOGYYeR1cb2LdgtRTKZwL97Ey44/1yGDBlGsrAYXfOg+AL8PG8+M2cuoUuXLoBFOp1wqq+E4mKOPvoY+vR5kmAoCOk0Ho+GUFVIJjCMNLFoHNMwQVXZa689mTdvFYu++AJ0HT0UhsJCGjZsyOBB/TjyiCMgEceSFrruwVenHsMHvEeXrrdx083dePXd9xGqSrK4CLwefvj+B5YsKebe++4HX8S+s8Idc+t+7rvvfv76ax1//7WUNStW8eUX8+ja9SpEOEh043rSqQTxeAnWupVceGFbjtvPQywez9rpVJ4hpS7br/zcd+S+ffu9sWZjB5OVGkFY9+C5ZVlgmVx08UX88utGfpr3EyLgB4+HsWPHUb8etGrZElLJMmvDRiLBOeedR7vOnVm2dCmTJ01k4MCBvPLyS9z7v/8xY8YPBENBe2IkkeDmm2/mmGN25/zWnbjjmmsZ8t77zJk9F9MwOfOSS9j/gP0gEUdTVVRV49U+L3LzzY+xIgp77703aArJeMxOg6bzzz//kErBS/1e5sZLO3Bdl6u5rvNVXNu5Gzdddjm9ej3L0iJYu3YtS5cuxZJw9NFHQzyBmjUuT6VSeHw+Dj74YEzD2KETORU3Ebs2FOne91IFyUauX1UkF/Y1gjVD7G+ykMVFHHvM0Rywf5gRI4YjPV5kNMbHIz/h3HPPIdKkMTIezVQl0zRQAwGKCgp46NZb6da1KwMGDGDWrO/ZsLGA5s2b06rVyaTTBqZlIpNJ6jRtyscjR/L00/eRSCQY9OFAbrrpRtq0uYC3/u9ZUikDqekEgmGmz5hP/1f68/57vbmr23nccGMPFsyciScSsXdcWhbRWBzTBMOwL2tKGwapVJq0kSYRjxOJRLjz6tbsudcerN+wDilB0zSkaWQYkckLRUPTPFl5Uj6vqltyketfXZKLXP/Nyb95Vkp7PWCXh5sRKkA6hS8vRLt2FzBp0jRkYRFz5vzIylVpLrnkUkilyvQGVFUDReHhBx/m02nT6d79MQa88w4vvfwSj/bsSfvrbqFho0bEEwmklFiGSfGKFegeD52uu5bX336TkSM+4v333uGE44/jgYdeYsTwjyGYRzJpULcOvPvuW7Tu2IEnejzC/nvp3PK//5EuLkHRNJDg8foIh6FPnz6889FHvDfwA94fZMu7gz7gzUEDef6F52myx+4EA150HQoLC0BT7UMECmTuTrUkMecm9lrULNSS1YGdEc5xtFSS9hdfSDIJ38z8liFDhnHMMXtzTPPmGPGY84RNVr/fR8GKlYwd+wUPPvggLS66CJ/XQyqZxIhGIVbA33/9jVAEPp+PgoKNdO3alQnjxgOQKomiqSoHHXkET7/2CpdcdCIDPxgIyTSGaXHAAfty7HHHYG5Yi79uPu+99y6//FLM448/gRaMgBQcfvjhxOPwww+zwDJJlBSTLC6yx7SayvxvvqbNeefy++JFHHDg/ng88ONP8yAQyjrXKvB4fcSLYyyYvwhN2/r9zrXYPqglK86poMwfYCbi7H3AAbRsdQLP9HqGSZOm0rnTlaCp9iSRO8Z1ejbpdBrLgsLCIrAsFL8fT9CPVq8u30z/lMmTZxOJRMDnp26DBhRsLLCPWgkFT36+rSGFAuk0RUVFmKaZWWdVhCART2AYJokNGzjo+OPp0+de+r49iUmjx4LXz6GHHMpRRzTi+eeepWT1Cnx16+D1+fFG8sGUPPnkU6xdu47GjRtTf/fdadmyOa/0f5s1v/2Bt/5ueL1+/Hn5EArz+htvsXCFRSgUKtd1q8WORS1ZhcBIp4kClpkCITFNA3SVjpddwoTvlxOPw5lnnQbREvseVwFGKkm8BNLJBA2a7U6rVkfx0IMv8tFrr7Hs99/5bcEiej3wIE892ZM2bY7n18UrGT1sCPh89HzySb744lduuvJKvv/iS1YsW86C77/nzmuvZcqnP/O//90IXo1kIko8VgTSQGAf9zM3rqdTt6u48sJjufGGB/nt+1ko+Xk899wzLPmjgAvbteGrKZP5888/mfvtLLp2vIKvvv6Nvv1eJBgOQTLOo48+jM8LZ7c6hwlDh7FkyV8s+nE+9//vVj4eMYIrzj2SRLwEsm5fr8WOR5UnmCpCbpjNSeXP2opkh0g8Qf16+bQ9tSn164aR6TgSCytaxGGHH0LHM/fhppsupU6dIMlUiX1eNp1gr6aNaXX6ISjSRJop/q/XU5x7zqF0f/Q5zjvnYtpfdAXTpkzlgQfupc9z/8fppx3KkEEfUrhiBaec3Yr33n+WX3//na7dbqT1+e244oqrmf39bN545UEubN8WWbCOfffcnVObH4ewkgiHsKlkHJmO8UyvJzn5pH2YNHEscuNajjj+aIZ/1A+/z8P1191G69btuazj1fyzfBnDPurPSaeeTCJaSElxAbs3a8LoUSM5/LBDuPeeR7ng/I5cekk3fv31D9584zW6dL6M4445HGQa00zt4DKy31153ale+TdpyEWu/+ZEGIZRPpYcCCGYOnUqrVu3zrx0ypQptGzZcossRTRv3pxFi+wT/5e1a8XAd/tjxdeAEbdVvJOS6pi2t0/F2BkmhILweDANA8u0rfojJEJR8Hi8ABlD00LYx8BVRQUpnJvEBJ6gD4C/fl/C+g0b8fmCHLD//uiRMCTioGmkYzFM00RRVDzhMKlolN//WEI8FiMUDLLnnnvgywuRjkYx0gaqKlBVzdb0VrZNJIHH5wVpTwZpqooEvJEwpEx+/vkXCkui+P0BDjzgAHyREMnijZmyk1LiDwVBCv78/U/WrltH3br12XffvREeFSMWQ9M00qkklmmiCJyND+7b3fKR203zCiEQqgaBMNdcezvvj7JtKp9wwrFMnTodXddJVbOliK5du2auzzjrrLMYNWrUFlmKaNWqVcZSxDvvvEO3bt3AKY+qoLYbDHaFs9IILAQWqiBTQaWVxkynEFgoQjphTDucKtFUgSIsjFgUmUqw1/57c+zJJ3DoUQej6xZm4TrMZBQSJei6QFckKgZWSQEeTXLIEQdxbPNjOfCwA/B5FdJFhWCm0RQLTZEoGCjSRBESxUmXIiRGMgHSIODTURXQhMQsLgYrxcFHHMxJp57EkUcfhk8Ho3ADimWiYqBioAmTdLQYmYyy9357cMIpJ7DfgXsizDjpogKENLCMJFKazmm7qlWmWmxf7MJkdSugREoLK51GmkZm65xAgrQw0ml7D3DOqVDLNLAMwzYh41i5MA0DIxrFLCrELCnGSiUyxLbMNFYqmWkQkCZmKoFZXIhRVIBRUoSRSqIKiYKFgkSaBpaRzj7Y5oj9t5FOYxhpcCwRCiysdAqrpBirqACrpCiTBgULIWWWWJhGGiNaUvr+tJ0+aRqYpt14ud+2PbVoLaqGXZysln2BsbBJoGQRAWcVp0Jx6mypaZHsTnt2JzGb3uV30JZ/zo3T6UJl/rm/l/qUPlMah216TSKxysimiZbr56RWlqZeyOwwlcVTi+2NKk8w5farc/2qIrmw3bcurm0tWYnKSO6tcRmp4PnSxxyjbBVOlFQkLj+y3ivtxiL3+bJhSnlmx2MbhiuV7Fv17Jv1yr+7Ysm8x3Ik42Zl0ld9QpkGorx/9Ukucv03JbnI9a+K7MKaVTi61Nan/xbSMXyRfSrE1XtbI1lctOPKMayWGz5bthVy490e76hF1bGLkrVslSvf7m0a2V3S7VFx7fRk2/x3GgLXr8KXljq6v+USrKpSNrZsZLtuaa7V4t/iP0TWiqpcRe62XykRSv933StGbtxlq3OuOVHKTEmVH69uSkpTITPvlI49JEuUn/Kxp57sd7qS+8VbKuXhuooy6ctOQ7bUYtvjP0RW28CY4g+j+EMoin14unw1LK2OQlFQAgFEIIgQik2NLANppciuqGWrs+r1only99HmElWg6jqqz1+OmBWLQA0E0Lz22m15/1JRPR5Un6/CtG17lI1bZn4KFEVDLZfvtdiWqNYJpvJxbH08uYKikDAMVi1bybqV65FoWFJgWu4cSe4zgFCJF5SwbsUq0oYBisiaiMmez3H/znofAlAo3LiRosJCBApSgiJU1FAIVVWwLHvSRwDFxcUUrLOPpwlso18ViU03QeG69RQVFGbmg3PD2fEoFBUWUrBu3b8uly0Te9bazR+BQjJlsG7VagwTQKngmX8h2ZWm2r6xvOQi139zkotc/83Jf0azCp+PFctXcEHbDpx2Zjt+mDsfNZSPheKYCc3uigqUQJC169ZzQdv2nNXqEpb8vQyC4axrJahUW0kEiqajaDp33XMfb7zxDkoojKrplMQTLP5xPsXROKqqI4SCEsnjg/c/5M4770TTdHvjfiVQdB3TsriqyzX07t0PJRAstQPsQGBv8FciEV566VWuufYG+4oNVc8KUT7dW4/c73fz0xYlGOK33/6gbdv2LFywCMVv91RqsW3x38lRRSGdMli+Cn4thJFjJoLuR6oalhC2XV2nclkICIaYMHk6X/waY/l6iCYB4cGUwpnVtX+624ayK6er/xAqK1atY11hMWg6IhBi1Zr1XNrpBn6c9zNKJN82tiYUkqk0GwuKy2mJchB2+v5esYE1G4tA82bu3cmGImyD3OsKCvl7xTpSFlmGwskZApTvPpcldEWkzvETCmTlIdl5oagkkin+WAYlsZh9AW0ttjn+O2QFQNCgPhzRLMCU6Z+xatkKNI+v1DK9ayDb68UsLGbY8I85Yo8ADeqDYQmQjl1fRctoBrv7UvY+GEUtNZrt8fqddzi2gzUPiSS27V9FRwoFs7iEyzpeTu8+fTAMC8M0KyGIDQl4fbodb4YcOWEcY3Oa7sHr9WSs+GcTSVF1FF8AJRhC9dlXfJTaIS4lm6JoKF4/SsAZ73t8Ze64kYjMWi1CQdO9aIEQeiCE7vEDCkLV8KmgOr2G3MalFv8e/ymyWpZJPAEd2ncgkUjyxRdfojomPbMhgmE+/fRzfv19FZ06dwahYFo2KSUC1edH83iwLHfDv/O8BE33ovptM53u2M2yLFB18AXw+vzoGqiKBqEQuu7FMCwaN9qd/Q442CaUVZ58ubCcTQ6bgxAC0xkbOy4gFNRwBFSN1StWsWTx75QUxVAj9dA8fiwpnA2NAtXrg3AehRuK+HXeYpYs/p10wkAEQyia6ty6Zy/sClVBDYUxTfh7yd/89cffJFMWhFwj4mCJyjR1Lf4tqnWCqezzWXFsi3+OBkwm4OCDD+LUU05h2LBhSMNEKGpml6ttlBtGjRrN/vs34fjjjyeVtuwKr2qkTZMXevfmyy+/wuMPlHmHFgwyZvQYevfqBUKxrRcCXq8Hq7iE+266kZtuvInCQnjq6ae46vzzmThpEp569RkydBjdH+2O0FSbBLnpz3yHcwze2WEhpdMlL93FX3qNhhRYlqv5nDxQFZRQhB9nfc9V3a6mdZvLuLD91VzQ5kJeer43sUQa3R/CkALVFyAWT9L76V5ceNElXNbpOi69/GraXtiBkYM/QnoCoOmYQgFVQwmGGT9qDB0uu5yLO1xBh0uvoGOnK5g6fAS+QAhU57LOTJd5G/yTspyazq1X1Sn/Jh3/5llZXRNM2/OWuGxY0sI0Qdc0ru7ale9n/crPCxbh8QacToSC6guy8vc/mDrtO2688Xry8kKkU3YvFlXDNCw+GvoJCxf8bN++na0lfH6++24Wwz4abburzoVRDr/q1MnHF/ChqBCKhAmHI/gCPvDo/L5kCV9/+609/nTGw+XF1mBSgGlJvP4ARPLRQ3no4XzUcJ4tkTxEOB9CddA8fgwLUFWkoqCG8vhs8mTaXnQrqtdHv1f6MGz4e3S9uhv9XxvCTbfegWGp+AJ5pNKSm26+g/cHfsINN9/C+x++zZsD3uDEU1twy119GTZ0JGqoDige1GAd3nvzXa664WkOPeww3njzFV57/WXOankmPXp054OBHxIKgxD20k1V7nquxZahWshaXZCOxBMJTjzpJOrX0xg+/CPQdRRFs8dzHg9jx4xBCDj9jDOIxkpKc0FKJIJIJIjX4wNpW4PPtIpSEggGyIu49+DYRE6l0gifj4d69+Gll/oRisA999xD/6Efc8aZZ0EigdfvJxAIZtLqjonLN2T2uxRF5c+//mbaiBGM/Xgk4z8elZEJn4xhwiej+fzjkfz5zz/4fHZ6hM9HwZrV3Hf/Y5x3/lEMGDKMU88+l4OPOoKr77uPUaPe56tvFvDOu+9D/UZMnDiF8VN/5t133+SKm2/miGOP5ZhTT+XxF/py+hkH8c67AzESaTyhfObNnsuDj7zBfXdewlOvvsJxLU7h+JNP4rbHe/DSS/0YNXoya9aDpnr+a9WqxuA/l6uWtMlD3d1o27YNY8eOI7pxI7quo6sasriYjz/+mDPPPJb8PfYkmUra/WMHrg1hwFG37q/2BJNN3tIHJNjdU1WBkhJKikuQEhKJBBSuJZmIl4kH52SN7vXZt7fl10HPr4MeyUP3B+3xARAMhfnqy8U8+MBDPN7jSbr3eJruPZ6xpfvT9OjxFPff9wCfz1iI3x+wJ3+8Xr74/AtSaXi+93Pg9UA6ab80EefgUy/ghhuuYNQnn0BJEdKyuOPmCzn66KMwN2zETBuQToPHz0EHHcS6deuIJ+Lg9zH8oxHkReCOO26HokLiG9cRLykgseIfjm15Jp2v7ECh072rxfbBf46s4Co8i3bt2rFihcXMb78Djw8lFOH7OXNZ9HMJ7S5sB2bFhqzdGVVwlm+yFj3sGdRKss1yZkwB07JPqFQEXfeyaMFCxg8bzsThHzNp5CjGDhvJnO9+sCeqEMTjMS6+uAUzPv+MCRPHMWnSWCZOHM3EiaOZMHE0kyaO4csvP+eSDmewYcN6O72Kxg/f/4DPC998/S3jBw1m/OixjP34E8Z9NJwZH7/HurXrWbR4Jf/89isXXdKBx555BkVR2FCwgX/++Ye5P/zA+IHvMmXKVFRNQ9c9EIvz408/ceYZx+HLy7cPvtsjZSzTgGgJp7doQX0BpmVkege12Lao8gRTRcgNsznJedp2R2Z2wvw7seMSAvscZ6yAo446giOOasioUWOQQkcqOkM++phme3k4o9VZSCMJ0nJo6B4xszWfKZz7UKVtqExKe0oIodg7o6TMVEl3IkSaJlLKrFNlNu2llCDBlLaxNen18fkX3/DIo8/To8f/8XiPZ3jood6MGTMRqdvLJtI08Pt1go12Y7eGDahfvy4NGtTLSN0G9dEbNiQQ8NobJISCNEyKiqMsWw5P9Hiaxx57iscee5IePXrRo8fT3H33/UydMpX99qlP2jCQkQjTx47lmuuu4/rrbuDW227jzTffZu7cn2jWbE9UVQchSCWTrFm7jrr16yFNE8OyrS9K50OlaaDrOkLgWPK37CHENpHcemO77Qj5t2n4t89XoiJ2dkj7igu/l86dOzPji2/YuH49xes3Mm36F1x8ySX4QmFbs5I9h2RnqHRsLWXHJ12iIRCKWsY/85uSO/4sX9mklFixEjp16sRnn01g6tRJTJ4yiW9mTuG+++6HRBLLdCwZmgbEoqSTcdLJGEYynhErEYdEHNNMZxo+VA0pJYceWoep06Yxbdo0Jk2cxKRJk5g4aTITJ0zgq6++YNq0Keyz7768/1I/brntAfbaa0+693iMN19/jeeee4ZHnn2Go48+mmQyiWGa6LqHQCBIMpUCRSm9UExKe9ggBEgL04Ly2zdqsa3wHyWrM95MJjnrrJYkEvDlF1/xxedfkkhAhw6XYiZTjhEyF6WVzDLtpRwUe2lGCIGmayAlS5cuzXqk4oopcse+DpTMRguLUMBDfp0QkfwAkfwA4Tw//oDumP+saOKpcgj3gmEpOfCAA9m4fiMCkzoN6lK/Xh4N6uVTv26E3fbeg18WL+Stt95g44b1vPjCy3S64kIee/Fljj72aJo0qk/Ap4GZprBwgzOasMDn44AD9mf2D7PBMPB6vJlGyLIs8Pv5888/iTr32NZi++A/RFa7cjsjTcAikYzTuFlTWp51AsOHf8Q77w7gvPNOY6899yKZSIB09vxIbLJKC6/PiyVh/vxF4PXj8QYQigeR34DVf/zNtOk/4Q8GnUkjV+xlIZwNFKYJPp8PIhF0zVPBEE7a9o8SsYykEzGMdBJbdwPSdL7DNatS5nHnv1LzK0i7N3HaGS1YtRoGDRoMgQBCCAzLQHh0QNK9e3c+mz4dgFgcGjfZHZCk4jEMy0SJ5FO8ciVTJk9FCMe6o6pywQUX8NPiIr7+6muUOg3QPX4U1Ys/vwEUxXj/fdvqn5rZn1yLbY3/CFkFSIm0LAwJlpEALKSZBmFx+eWXMGrKT0z96jfat7/YXpO0LHsbYtogFcM2WWIaeENhWp5zDoOHf8WUEWOQ+FC0MCt/XUb3Hs/QsGGAUCjPXttUVBLJNKmUCWhgCsLhPNIpGDJ4KD9+NoM1a9aB5sE0rU2aznQ3/+FYVUwlJVY6YZtEtXczl7ES4ag9hDQxkykULEjEOPSII7n8itN44Ik3GfHOe1hSQfP4iRaV8Mhd9zB/wRoefvQx6uzejIMOakr/l15l0ZdfoXtCCMXP3Jnfc+dd9xEK5RGNpli8+HcoitH6/PM585S96Nr1dmZN+xzNUwePpy6r/tlA16tvQeJl34ZeEomU3e7lfmAt/jWqPMFU0dhrSyUXtvvWxVVe7K5ngwh4NRVp2Vb/jGgRxx17NCccGuGkw+tw7DFHYSZKEJZtxU/XBLvVB10RSCOFlYxx8/9u4vTme3Pjjfdx/gUX0KHDpVx+RWcOPPAgbr/jNizLwDTSSMsgPxIm5PchTYNUPEb9+nW47dYrmDTpS9q2uZapUyYhfT5CIT/16jh3p1qb+GZLIqVJ3TpewkE/0jJsrZllC0m6dp7MNKGAj3r1QkjLwDJTyHSCXk8/ydUdW3D33U9xwQWt6XDhhZx79tmMHjWJ/i9359Ajj0RGi3myZ098Xp0LL+pMmzbn0+6idlx/7XXsvc/evPpqX/IjXh5+8H7Wr1uL6vPyWv/+HHf0/nS76nouatuWiy9qT/v2HfDoOr2ff5YmjRsisCecKGcT6l9IDvXL+Vej/Jt05CLXf3Mi4vF4+VhyIIRg2rRptG3bNvPSCRMmcNZZZ1XJyLfP5yOZTNKiRQt+/vlnAC5t25J33+qHlVgLRsxW8U5K3M7lFkGopNIGBRsLCYYj+Hy2cW4pJaqm2eufQDgSIW2k7X33wl6TLSkuJhgK4vHaYzGvz08ykeLzGZ8zZ85cfD4/p5xyMsefciobVq5g+YoVHHDg/qiKwob1G1BUlfz8fEzLRFUUNI/OqmXLiEaj1K9bl7w6dSgsKMY0TSJ5EbtCy4qXOBTnZMuGjQWomkZ+fr49uWU53WP3KUUghKCosBAjbZBXJ99eB5YWHl8AFJW5389h5syZbNhQwN577cXZZ7dit6bNSJaUYFkm/nCEog0bGD9+HL/9/it16tXljDPO4PCjjgTLZNXSZRQVl9C0aTM0XcfjD4Bh8vVXX/P1N98ghODUU06heYtTQSqsXrGcQCiA36MhpG1reWshXCPf/jDX33gnA0d/B8Dxxx/DxImTd4iR72uuuYbBgwcDcOaZZzJixIgqG/n+6aefOO+88zJGvt98802uuuoqcOpoVfCfIatEoCgqwh+ARALDMMr4az7b6kI6kUDizmJKFEVF8fmwEgkss7RyabrHvj1c18EwwTAwYzEUVUF4PRjRGCDRAgEwTYyks/kAUFQFxeO1W4N0GiuVdv5WMRP2GiX2gk/mmVzY8dp2i+0xbGmeSNwMshsiFIV0MoG0JMKZkVaEYh848AXsh0wL0knMmH31pAvN6wWfFzyqPRSIJzATcaQ0bT9Fx0wksEz7GV33gN8PHt0On0wiEwlMU6L5vchUCtNwDaZX/n2bQy1Zy+M/Mma1x3nSMrCixViOgepsMRMxzEQM+7yJ4y7tLpsZjSJNM9NICMBMpzCLCpEb1iOLCjCjxfa40AnvjjHNWBQzmcj8bXcDTax4DCsaxXLuc7VSSSzn/S5ZNwUjFsNIJuzJJXcSyRF3QklaFulkknQ8ntG8GTtQloUZLcFcvwZz/Rpk4QbnG0wERkbMZBSraCPWunWY69ZhRkvANMECI57EiJY4eWPnmZFOYBRtxNywBnPjOoySQkwjCTKNESvBNFxD5pv+vlpsOf4zZC1FaaWuSGxClZLSFtetlHC2WPZFVNKurNm/VxzPpnoFOWSr4JmKpSxRMyKdSadNiHtyVUGCNMv8zBYhLYS03DntcvFUlC9YJlj2jLXrVkrSWqJuD+ywCSa7SMuH2XGStVNps+KGz42j6pKzTWezIuxMr7q4Brq3VnLj20LJ/d6tFreyuPUm178aJRe5/psSN/zWPOvKf1Cz2tjUpoJN+VU/KtCaWbWzooKuKiqOsWqoUJtvVUy12Fb4z5IVh5QVSUXIrY65Hb+y4vrnPlN5da7Y3XWp6OnS0LktbFWIK10bw+XOzG5eEO7UV266ctNYi+rEf5qsW4rc6liepLmErViqBjdkRU9U5FZ15KYn+01VldKnalFTsMPGrMiti2N7iWVZWJZlG+MOBhGIjN3fbSHuWM6SMmNfaWvGvfbzpSKd87HZIoRA8fsQW1lONU1yketfXZKLXP/Nyb95Vv6Xx6xbAgkgFBRVo6iwhD8X/0bSsOx1PntqpwxUTUOL5KNk/EtFC0dQvX6s8mWbo6sqCLAZuE9ka0A1GELzBzPaHqGQSqdZ+fdSUikjc3hgy1H+u2uxY7G1JbnTo2yXVkEoKqovSK9n+3BoyxuYNHUGWqQeMmOL1zY1qukeNm4sYuZnn1NUnEBoHixhmycFhTkzZ7Fs6Qo0j9d+JvO+LUM2IV3JhlDs9Pzw7ff8+stvqLoHiUANh5kz9yfaX9yVlSvXojiWGDeHsu9yw1f+XO5woBbbH7ssWcmqcEIoqF4fq1es4osvv6GBAh98OJhUNGbvZHLObEopIRBk4aKfuf6Gh1m6bIVtj9ex0WtYkoce7s6kSVMhGHbuz6l8fFsZXLLkhs9+TtV0EAqPPtaDIUM+QgmEEI7lfolAUe2et7tyWlk63Pdkv8/+vSqELR9HLbYfdmmyZiAAf4BPRn1Co4YNGfDO0/z44wpmzZplb190gwnboqGUEssCTdVtMyxCAdXWupZ0KrqqIdTMXilb62kaWjCAFgmhBgMoup6loRySabq9bVIoaLqGFg7b4vOhqgqKY2gcVUPTbe2tKCpoOqqqYkZLOOLwI/j446E0btwYK57I2PRFEfZFVsEAaiiIGvAj1PJVQFEVFMVuaISiovgDKKEQit+PopQP76KWsNsXVZ5gqgiVueei4niy48/Mv+wQUVQNo7CQkSM/4cwzz+Ssdm3Ze68gHw37CClBKPYlV1KC1HW8Xj+6DqrmQWoehFCRQs3cf6PoHqTHC0J1yKqgBSLgCfD3H3/zw9ez+HXhb0h0lGAeltAwpS1S8YLmQwTzsKTGornzmTPze9asWgf+MELzkDYlUvMgdQ+KpttdYE1DCBXDlGi6h/oNGqLqHgxLYloSqagooQjRWIr5c+cz6+vvWPr3cgjlowTCmFJBOhd5SRTweFECIfD6WfLLH8z+6juW/LIE6QkhfGEsqSKdZywptsU+ikqk/A5q1726UFH9rcgtG9n+lYXL9d+cVN5M7iKQ2PfefDrjC5avSHLueeeCz0u7tm2YPu17Vv29HFXz4vEHWL9+A/+7vBM9nuhJNAa333kPF59zHjNnfsfbb71F69bn8/c/Bbz/wUAuPO0MXn71DTSPH09ePf75ewU3/+8uLrm8G92uuZ9LL7+JS6+4hlnf/oiW1whL9aJ4g7zY9zXeGzicOT8s5Job7qBj51vo3PUezrmgIz0ff4aEAd78urz2cn9an3Muv/+xkdFjx9P29DPp3acfnroNWbjoFzpfdTUr16xHDwQQmo4WymPUR6No3+Fyrrzqdrpd8wAdLunCXbfcy/Kla9AjdUHV8YQjjBo7nhdf7M/ypau47+4HuLzzDXS79kHaX3ID/7vpbtauKUEL5mEJBelcyVG6UbEW2wu7PFkVVQEJw4YN5+ij92H/Qw6B4mIuaHMBiSRMmzYdHBvCqu7hkEMPpdkee+L1wkEHH8Sxxx1HXn4+jRs34bjjj8frhd12a8iRRx3NXnvvgxLOY9mSv2jf4TJ+/e0PevX6P0Z+MoRXXn+ZYChCt6tvY9bX3+DNq4Oiepg150cGvPcBvZ55lsOOOJJhwwcxbuIIrr62G73fGs9zfV4AodFk96Yce+xxhCNQv8FuHH/Ciey1114gBLF4ggUL/iIWT4CuowWDvPP6m9x6R2+OO+EkPhj4DmPHDeOJnk8xa9YPXHJpR/769Tc0XwA8fpYtX8WgIR9z3wMP4fUFee21/owb9xH/99xTjJs4m3vvexAs0DR7UqsW1YNdnqyq38/y33/nu29/oX2HDqDqpEtK2O+gA2hx6v58NHw4RjxJKmUQCoe5reeT3HTzTaga3HXnHTz64osccujBXNC+PU+98CKNGtalTZu29Hzlddq2bw+pJM8+9yyqKvh45HBatbuA/Q/Yi1POOIX3hn3IscceSPfHHiVZXIzweIhEIvyypIRuXTtxz+MPcfBh+7HPAXtw+2MPcHvXlgweNIEVf//DhVd05qmXX6Zx40aceuqpdO/3Opdc1QXSSSzLwud3uopeLwvmzqXHEwN45KGuPPXKSxxx3JHss9+enHfZRYwZPZxEzOT5558H1QOKRiSSx8+r4bDDDuWpfi9yzMknscf+e3HulVfQt88DTJ2xgJ9/XoTi99kj1dLr3muxHbHLkxWPj88++5xGjQJccEEbQEH3eCGST5eruvHjT2v4Yc5cPIEgphRQXEhhUTFpAwoKC2DDWox0ChmPEVu3FsM0iMaiULgBmUqzevkKvp/1A7169SKy96GQTiM8XruS+yP06NGDv/7ewNy5c8DvJZlIcNgBYc5vfQ6yYD2paAGJgg0QK+bYY48mlYKiwmKwLIz16zHSaRKJOBSvxSopcXqiEilB0zRQVAZ9OJh99/Zy3bXXQuEGkkUbSEQLSa5eTr199+LRR25nxoyf+G3hItB1EokE+0SgW7dukIiTKtxAqrgANq7hqKMOx6vAyhUrQFFy5phrsT1R5QkmmTNAzvXbnORCZiYKtjyubSP2biVZVMLQocM58shj2LihkD8WLeb33/9k2cLFNGzSDN0DIz8ejVR1hOpB4k4a2Ya8pZS2mRbLsr/FqbhSStB0/vrrb4qL4OuvvuHNZ7rzUp++vNT7RV7q3ZdXn36S4SM+prAE/vrrL6Sqkkwl2WuvvRGahmEYSGkvvEjLQBECXcceJ1q2qVLXqLiU0k6P/XbAPjQto1F+mD2b4449Di0UJBGPY1lm6Qmi4gKOPvooNB1+/e03pKqSTqdpukc+eZE8rEQMiWmLmUJVBQG/U4buRI+VeyJp20p5lA9THZKLXP+KwlbkluteVdm1NWswwNw5P/LjwkKmTv2Ki9u3p2PHy+l4eScuvPAirr32WtIGfP7FFxSs22hrXGenEk6Gg2N2NKss7F/tTQvxeJziEpg0eRLDhn/EqFGfMGrUKEaNGsWI4cOZOnUKhx6URyQSBiNtm3WR0rbs4MbtxiptMpbeKm5TszIoigDTorg4SjgcBkDK7MPvEtJp6tSrQ726PhLJJKDYhwBMyzl07tLfuTRLmmTXu3KWF2ux3bDLklUI+x7TYR8N49D9gwx45yV6P/d/vNT3BV7u+yIvvfgir/Z/mRd6P8CqFWk+mz4NzR8Aga1XHQNtmc0SFUFaCKHg98Nrr7/CtBnTGTt+dEbGjB3FpEnjmTp9CmeddSZmYSFCUey0KcJuElzbSwKEY8fYiRxLZhO3LEwLLMu+AlLXVdv0iChrnBzstdd4LM7GwgSqUDLkt0ldOSqyi1yL7YuKS3oXgBIIULxiBZMnz6Jjx8s45rxzOfn0FjQ/7VSan34qJ7c4maObN6dDx8s45KB8hg4eAsmEbfjbIadbXzOEseztD4rNaLAsGjbaDeGO8fw+VEVBVQSqIgiGg2ws2MCjjzzML7/8guqzJ2wUxbFyn9HewtZ4TtqlNMsYKBeZXUr2X27X2JImeL3sv/9+zP3xR0gn0TV7I4a7u4pwPr/8+hsFG6HpHk2zjIy7VcPuSdhNhy1SVq7PK3PfGmzLuP4LqBayVqp5qhVZlQ0FgmGGfjQcw4LW57eGdWswS4owigtIFW4gXVxEev1aEJJuXbowa9Zf/DR3Hvj8CARpE1SPBsEQqqZm9iCZaQNNUyAUBEWw3377se++9Xju2d5YG4vwhvNRFRXdo0NeHm+/M4APPphO3Xp1MwQVwraDrEibJi5ZSyljd2UVYd/2jmKTTg8E7PGj87mGZYFH5fJOHZm1cANjRo1GqVMPrz+A7vHhq1MfWRjl6aef46QT9+KYY46BRKI0DS5RpQLSXkt1ibqpMpVZsrVwTxTxL+OpKSjXo9kKVNsEU+7zVOvEkvsuWykquk581So+GDiMFqcdTsM998RMxB0r+M70kTRBmsh4lLNbnYWqwMjhI5DSIj8/n1gCBn84iM/GjGbpsmVIVcXn9RIM+Phk5AjGDhzID99+ixIM8vDDDzH/9xJuuOFGViz5k1TKorCwmIEvv8Kbb4zm8cdvYPe99kQm46RSSdKphDM2zJqwAUwzTSwK0jKQWGiaSl4kwtTJk5g0+EPmzp6DVBUM0yQRd8JFi2h1dku6Xdacu+7qxfB33qVgYzGxWJJf583n6quv5Zffotx+5+2g2RdipZMp+8YCnEkzJ+Pc8W4sDum06ZC2tBxzj+q5buXLYwsk1wpktdYbW9hE45QbdlOi5NyFlOu/OakWzbpj4WZQVkZ5vcyfPw8p4ZJL2oOwZzLtcaA7AWPZlTWVpE6jBnS8rAW//roIc/Vqjjz8UB6853ImTZzO7bc/yoKFi8Bnm+d86MH7SScT3H7rM0ycMB5SSZqfeQZD33uKRT8v4rzWF3PuOefT+rx29HqqP3fd1Zmrr+6GEY0hzTRNd29Iw93qgTNjm9FRZpr8vAj77K2hqQqkUggBD9x7J+Ggl//97wk+GjYEdA+RUJD996tLwKtBKgFmmuf+7xm6dTmXHo+9wAXnteGC1m259JJrWLFyBcOG9ubEU5qTKLaXhPLzI+y99x7OPVvu7mYTpIWua+y/r49QyLYhnN1jqVj+vab99zqpZsCq6NzkFkAUFRVtNgYhBNOnT+fiiy9GOi3MmDFjOPPMMykpKckNXg4ej4d0Os0ZZ5zB4sWLAehwwVm8/cYLWPGK7QZn//x3KK00pU6CRDpFMmUSDkds3ww53GcygVEUjZRpUhKNEgj40XUPejBA0foNxGNJQqEAPo8OUqIG/MSLiigqKiEcCaPrHiwp8dbJY8Pylcyc+T2rV60hGApy3HHHsO9B+2Mm4qRTCYQQ9kSQlHg9euZSOreA0qZBOm2h6x6EsNPqD4SIR6MUFRfj9Xrw+wOYpkE6lcLn8yGEhWWZ+Pxh0LwsWfwb3343i+LiYvY/4ABOPPE4gpEwyWg08yb32kavx+OMjW2qCaFgSoV4IoHH60UVAgXTadjK5XImPlczVrVc3e8Vmo4SDHPT/+5h0JhZABx37NGMGz8BTdNIp8vaht5eUBSFQCDADTfcwJAhQwA444wzGDZsGKqz1JWL7G5vMBhk/vz5nH/++RQUFADw2muvceWVV4KjYauCGq1Zs1vkbSpS4vP6qFOvDgom0kyXX9LISoVppvF6NOrXr4MqwDJSmNESIuEQDRvXtzWYZYA0MaMl+P0+Gu7ekIDPg7AMVGlgbFxH3TphLuhwAdfcdj0du13OvvvviRktwkonUIU9hRQOhQiHw2VmWwUgpYVH08jLC6OrElVIVGGRihfj92k0bFSfSNiPkGk8miAvL4Qi7O68IgSpRAwzVsQ+B+5Np+u6cOPdt3HW+a0IBrykokUISocAPq9OMBjMIqqdCint9+bl5+HRFGfs7KawFKXNYzY9S13LlUclOV8RtsXYb2dFjSRrbuFtD7FMEyMexzLNLNfcFNgQwh4vGqkkimLP50jTsG+Ai0WRplHmoJuVSmLFYlhp+8IoBYkiJVYihrVxPeaG1Rgb12LEipFW9rNgpFIYFVl4RyItk3QiljW2lggs0qkE6XgUM21fWSEtg3TSHYPbzwosLMsgHS0ivXEd6Q1rSBdsIJ2Ml0m7QGIaRuZ281xIaWEkYliWUW6bYW5ol7DuP9c1tywqkwqRdTPBroYqTzDlItd/c+I+40L36Kia7vg7ExUVFNi/l4r/WZuR3H+ujSYpc30k5nbaubNpcSd3qiq5z29CqvAvM5GUk2e5+Vi2JNzyyC2jigUBUtXQ9dJrJAUVpLcaJRu5fpuT7AmmXL+qSLVpVpnzoSXFUUCgaD4sNExU52ILBQvVEQ2JhkStRFz/XMk+tqWWF6FlRCh6Gcn4oSEccX/PPJPllgmTFWdVRAjNvs91k+KGL5tmRFY6qyzZz9i/y0rE9cP5zrJin92tKJ3Zz5aWYanYWzVzy6oSERpS6KB5iSVKexqmad9EsDPi304wVQtZTdMkGAxywAEHZNy+/vpbvvryO7T8xnhDDfCG6qEH6+AJ1cUTqoMnmI8nGEEPRtADeeUlmI8ezEMPRGzxOxKI2H6BfLRAPlogDy0QKZWg/bfuD6P7w2i+UBmx3e1wqiOaI+673b9dfzWYhxKIbELCzs88lEAeqj8P1Vf+3Zov6EgIzR/JcitNl+6PoPv+rYTRfWE8vlCFojui+SsWvYKwbpyaI3Za85wyKBXdlVCdisX1C9ZBqduYmZ9/zdRPv8/Um8aNm+APhshp+2ss3DF2rrLaGojCwsLNxiKE4NNPPy0zGzx69OgqzwYL5yatoUOHcsMNN2TcD96zEXfecQuHH3EIQljO2qIdvyKEPRsqnRvf3CskMnHa7UxuJrjum2p9pbQwTHudsCIIp+u4PSFco9pOa+ve/mZb2c4OmJOQLP9sEyumae88qipyX1N1OOkt/bUchOKOwEuNqmfKdRNmYVwoqoKUFnN//IkX+73E4n9KEM7rXu73El2v7kYsGs3s1NreyJ4NHjp0KDizwUOHDt3sbLAQgkAgwLx582jTpk1mNvjVV1/d4tngaiErgK7rWJbFJZdcwpdffokuIO28uW5QR9Ptfa+lVcEpbidM+brlFH6mMmT5SHtctClsbm/rv+yxbBJCCGeaJTcNpW7Ssf9bnhG5z2wdZAUxVw0uDTeF0kmkXLjltJnsxzRTFJSYGIAHSHJeTCYAABTrSURBVAFHHHYY48aNs5enLHPXI2tBQcFmQ7pkbd++fRmynnHGGVUmK0AoFGL+/Pl0uuJy/lm6LNe7FrWoFE2bNGHAgAGc2Lw5JcXFm2f7NoRL1htvvDFD1tNPP32LyDp//vwyZH3llVe2mKyb75NsQ5SUlHD44YczeswYrux0BfkR+9hWLWpRGcKhABdfdCEff/IxJzZvTnFxcYUae1dAtWpWF6FQCCzJ7B9+4Mcff6SwqIji4iLszmH55Ein9bGc6W8hFGKxGGvWrLHtDmW1TmJTR9bKYNMt8/ZuuEWZm8ztTRoLFy3C49HZo9kemFbOGNRNUGXfVpH/5j5iM96VopIkZOCWlaqyfPlydt+9ScYrM6ewibRJKfH7/dSpU4djjz2Wo48+CiEUElk32m/q+W2NmqJZdwhZBaCqKj6/Y3JgK7Bw4UJ69+7N66+/jtfrzfXeKXHdNddw4IEHct8DD+R67ZT4448/ePDBB3n//fcJBErtL28p4vH4Fk+gbUvUFLJWazfYhXRmL6MlJcSjUeKxGIl4fJMSdyThHOEaNeoTPv74Y6ZOnQpALBYjGo2SSCQyYTcnsVhsh0g867uScft7Fi5YwJgxYxkxYiQFGzZgGQbxWOzfSTRaocQciW6luM/nxpuRWAyADz54nylTpvDll19myii3DDYl0WiUkpKSHUrUmoQq72DKZX+u35aKe3TKtCxM08QwjIyYplmpqKrKhg0bGDNmLACDBg0inU6jKAqWZZFOp8vEtSnJjbu6JPvd7o1yo8eMIZlOsfjXX5gwcSJCVTO7prKfrcitUrGsTYob15ZKbjy5ous6GzdsYMSIkQAMGzYMy7IQQpTJg82JtQ1v8dsWkotc/81JLnL9Nyc7RLO6kJWIe/A4W1xomsbnn3+eOb0zffp0FixYsNN1hd3teh6vh6KiIsaPH5fxGzJ0KIZhoGpaubzInBWtIN+qKtsKufFK7HGyqmmMGTuWZcvsGf/x48ezcOFCfD5fbhS12ALsULJuKVTVXoudOHFixi2ZTDJixAhwxgfVOfGwLaAoKtOmTWPBgoWZtH///fcsWLAAj8eTG7zGwc1zV1RVJZFIMGjQ/7d37kFRHPse/86+XzyChIDmxFjxETkaVDS5GCNqxKMpvYqW5FyIqyYRT6x4TZmC5MZjCedEiRZWriYH441alSrfAiEqUfCqmGgJgjFRTKIiRiOCF6Igu7APdvf+sdPt7rDILs9Z7E/Vr5TuntmZ6f5O9/z6tYumMZlMOHL0YZ55qmUY7eM3YuU4DiqVCr/++iuOHz9Ow8A3s27cuAGtVutXBcE5UMSG3bt3Ay6FuLm5GTk5OeA4zqsRP2JCpVLh3LkSlJSUuIV/k5cHo9HoNiif4Rt+UxJIQT569Cjq6urc4mpra3H06FGgh136nUWpVOLcuVKcPHkS4L2O5Prz8/NRU1Mj6tpV+Kyl/I50OTm5buEAUF5+GSUlJaK+H7HTaw4mX00mk8FoNOLwYee3natrHAD27NmD+vp6yGTOLRnFbhzfH5yX9zVsvLfT4fKMKysrcejQIdr0Fx7f2+bpmpRKZ8snPz+f3ocrOTnZcDgckEolrY71F3NFGNeedeZYR287mHxBoVDg7NmzKCsrAzx891y8eBFnz571mze3Wq1GdXU19Wqr1WqaKUFBQQCA3bt3w2Rq9oumI3lpHjx4kLZ8JBLnPq+EgoJCVFVVQaVSt6qVGe3jF2Ilzav9+/cDAIKCgqBQKODga6h+/foBALZt2waHwwGZzHUxbPFBnDHku3TLlixMmTKFxs+bNw//+Ec6qqqqcPz4CcjlctEXboVCgT/++AM7duwAAAQEBMDhcE7aV6vVUCqVqKurQ26uszuH4Tt+IVaVSo3Lly+jpKQYS5YswZ49exAWFgYAsNvtmDFjBtauXYvKykoUFRVBqVSJunBzHIempiYMHDgQubm5+Otf/8NthE9gYCCWL/9P7Ny5E1qtFmazc+CEWOE4DjKZDF9//TWCgoLw5ZdfYtiwYbT1M378eBw+fBiTJ0/GN998gwcPHvhFa0Fs+IVY7XYb6uvrkZaWjg0bNiAmJgYjR46k8cXFxViwYAF27NgBuVzuXCFQxNj5QQ3Tp0+nE/Jb+DGv4LujAGDcuHGIiYmB1drSqtkvNoxGIwYNGoQjR44gKioKFy5coHFjxozG2LFj8dVXX0GvX4jq6mq3Yxne4bWDyRPCNN1lTU3NGDVqFGbPng2TyQSHw4FZs2bS66ioqMCOHTsQFRWF6OgxNI2YDbwom5ub3MKcz9U5csdoNNIXj/B4MRl5+UyaFIvg4GBs2vTf1Gkml8sxbdpf4HA4oFAokJSUiPDwcJjN5lbnEbsJEca3Z5051uFPDibwY0udw9BsmDbtL3j++edp3NatW1FRUQGVSg2pVNrq4YgR12sUc7PdG5zOJCkKCwuxd+8+Gj5p0iRER0fDZGqGxWJBc7PJ7/qOxYLfPDXydgEAk8mMkJAQ6PV6Gl9dXY3U1FQ0NDRAq9X6TeHv7CJaYoDjl+25cuUKUlJSaK0KAMuWLQMA2pQn430ZvuM3YnXF4XDAarVCr9dj/PjxNLyoqAgrVqzA/fv3odVq2/UKE6+s0BjewXEc5HI5NBoNrl69isWLF+P333+n8X/721LExsY6d2ZndBq/FCsAWCwWaDQaZGRkIDQ0lIYfPHgQixYtwunTp6FUqqDT6aBQKCCTSekIIdL/JxQpMRLf1Sb8DY4fS4tWTWJntkilzmsWm8lkUigUCurBzs7ORlJSEp1cAQAxMf+GDz74EHa7DS0tbIpbV+C1g0nYdBHGdbV5Mz3KYDBgxIgR2LbtS9rXCgDff/89EhMTkZKSgtOnT8NgMEAul0OtVkOj0UCtVveKaTQaauRv0l/s2pVBvrkVCkWrc4jB5HI5amtrUVBQgKVLlyI5ORnXr1+n1z906FD8619ZCAwMhNHodKBB8CkjzEt/MYIw3BsTIoxvz7i6urrWZxHAcRxOnjyJ+fPn0x/Nzc1FbGxsh1aK6Eok/Cz+M2fO4L333kNlZaVbvFwux+jRozF06FCEhoZScYgFUlvl5eXhl19+AQBER0cjLi6OekzhYXjlw+O7r9lutz8sZM7WAIeWFhvq6urw448XUF5+WXgIXnnlFXz66acYNGhQr5eNroKUsXfeeYcOzJk4cSJ27drl00oRc+bMoStFfPbZZ0hMTAQ8jMZrC78XK1we5rVr17Bu3TocPHhQmMQvIE1ku8uu5v6CUqnEokUL8eGH/8XXqEavC6HYEYtY/fab1RW73Q6DwYAhQ4Zg69at2LdvL+Li4iBhXQTdTkjIE0hISEB2djbWrcuARqOBwWDwugAyvKdP1KyuKBQKKBQKmM1mlJWV0cH/NTU1sFgsdKQQaT72dtcJuY67d/8PDx48APjhhhEREfy3Cr/3KedcpZ5ArlvYDO6q+xGe19XppVQqMWDAAERHR2Pq1KmIjIwEx3EwmZr7pDNJLDUrV1tb225KItaEhAR64pycHFGKFfz1yuVyOgPHZGqGwSCuZhlp6spkMgDA0qVLUVRUBACIj4/Hhg0bYDab22wSt/UN29V4Or9EIkFgYCBdSqevipRAxLps2TI3se7cuRMymczj8FahWMvLy93EunnzZiZWIc6uBhnvyHlY8EhNRWoM11qrp7DbnfN0ASAhIQEnTpyg/8/Kynpkt0dPiVVYw5Ka284vTudtQfNnxCLWPv9RZ7fbYbFYYDKZ0NTUTM1oNNJ/ndbkZq5pu8OMRn5JUpPTXDPMuYqgDSaTGRaLxaOZzWaYzWaYTKZuNeF1k3CLxeJ1IWN0DX1erB3F+b3YfeYKxz1czoUhXno7j5hYeTgPI5m604QIBQwPTVDG441oRzA9biZEGM+sd81ut7vNOZZIJM49dj2kbcuECOPbM1azMhjtQLpn7t27R8MCAgJ6fDQcEyuD0Q5yuQx3797F1atXadiAAQMgkUjdpgN2N0ysDEY7SCRSlJaWoqqqioa99NJLgEt/eU/AxMpgPALS1CVbPQJAv3798MILL/RoExi+OJg8IUzDrHPGnq34TC6X4/jx/8WpU6do3rz66qt4+umnaf/4o8x1qqen/PVmKigxVrP2Ep66bxjigeM46HQ63Lx5Ex9//DFt7srlcrz55pvgOOd0QV9wFSzJf1/KgddiFc5gIRfvy48x3HH2ubbOAofD4TGc0TNw/JpSNTU1WLlyJS5f/pnGLVmyBGPGjPF5qRqDwYCGhgb69xNPPAG00b/eFl6XCLVa7SZYo9HoFs/oGOxlJx44fqdCrVaLyspKJCcvobu2A8Dw4cOxfPnyR47ZFkLyt7nZXdxkZRBf8t9rsQYHB0OtVtO/79y54xbP6DrIKCelUgWlUsmsm02lcq7VpdVq0djYiL1790Kv16O4+OG2lREREVi/fj369esHo7HJLb+84e7du/T/KpUK4eHhgI81K1dTU9Nuao7j0NjYiBkzpuPatQoAwBtvvIGNGzeiqampR93XfQ3ibdTr9XSK3Jw5c5CZmQmz2dyj/XiPI8TJ89tvv6HkXAmOfHsEFy9edBNR//79kZWVhZiYGBgMBtjt9lafhUJIjSmVSqBSqbFmzRp88cUXAH++oqIiBAUFdY9YAeCtt96iWy7++c+RyM7OQUBAAN3ugeE7nsQaEhKC/v3798q0vceR5mYTqqqqPJbj6OhorF+/HiNHjoTRaPTaV0PiyUII8fHxuHjxIgAgNjaWTrXrNrFu2bIFaWlpAN/m3rdvH15++WXRz2kVM0KxSqU9OyqG4ZmwsDAsXrwYSUlJeOqpp9DY2Mg7/jxPxGgLrVaLsrIyxMfH0xUlUlNT8f777wM+ivXRdbmAF198kX4YW61WFBQUOPt/2mkSMLyHPcveQ6fTYdSoUUhNTUV2djZWrlyJsLAwGAwGcC5rPXsLSX/s2DEqVLlcjokTJwI+ChW+1qwAMHfuXJw5cwYAEBoairy8PAwZMoTVrh1EWLOC9zpOmzaN/55itWx3Ybc7IJVKoVarMXDgQDzzzJ8wfHgkAgICAH7jMJvN1mGfjEajRm1tHebPn48rV64AAMaOHYvDhw+D43e+9wWuurraqyOIYLOzs/Huu+/S8CVL3sY///lxn1+Hp7sgYl24cCEVa0JCAjZv3ixMyugBrFYrrFZrhwVKIEvBZGZmIjMzk4Z/8sknWLRoEdCRmtVbsYIXrMViwezZ/44LF34E+KlC+/fvx+jRo/vUWrE9hSexzp07F1lZWTCbzWhpafGp6cXoGKTcdrb8khpTp9Ph0qVLeP311+nUusGDn8O33x5BYGBgh37H5w8khUKB5OSl9O/GxkasWrUKtbW10Gq1bmkZHcfhcMBms/FNYTuzbjaHh/G7HUWlUqG+vh6rV692mwO7YsV7CAwMdEvrCz6JldxMfHw8pkyZQsN/+OEHfPTRR2hqaoJOp3M5gtFRnA4NVqP6G2q1Cg6HA6tWrUJxcTENnzRpEubPn++W1le8nnVDjLyF1q1bhwEDBtATHTp0CKtXr4bRaKQ1rPBYZo82gvBtz0zcRtBqtbBaW5CWloacnBwaHhYWhoyMjFbH+Wo+1ayuDBw4EBs3bnQL27VrF1JSUmiT2HVnNAajryKVSqDValFfX4+UlBRs376dxnEch7Vr1+LZZ591O6YjdEisDv5tEhsbi88//9wtLjc3F0lJSTh16hTkchl0Oh3rO+wEzLkkLlzzQyaTQqfTQaVS4+zZs9Dr9XRkEiEjIwMzZ84EBC3NjtBhFZEfnDdvHrKysuhWFQBw6dIlJCUl4e9/X41bt25Bo9FAp9NBqVRCLpfTzuK2CiKJa8/8Gdd7aOt+hFsu9uS9C3+vr5s3kHKrVCqpSG/cuIH09HQkJiaitLTULX1mZiYWLlwIdIGXGQC4O3fudOos5Ea/++47pKam4ubNm27xzzzzJ0ydGofJkycjKioKwcHBkMlkXj+gxwW9Xo9jx44BfD/rpk2bAJdMZs+r93E4HLBarXjw4AHKy8tRUFCAwsLCVjPQwsPDkZGRgenTp7sd21m4qqqqTp+FFKQ7d+5gzZo1yM/PFyYBx3GIjIzEsGHD8NxzzyE8PBxarZbWyHaXTujHodlM7lcqlUIikWDz5s04f/48wHsO3377LZhMrTemIs/mcXhGvQkp0w5+PLDRaERNTQ2uXbuGn3/+GeXl5R4FGBcXh7S0NAwaNMgt3FNaX+kSsULw5j927Jhb4WMw+jrR0dFITk7GrFmzhFGUzgq2y8RKIKK1Wq3Iz8/HgQMHcO7cObayBKPPQQb+JyYm4rXXXnPz23hCdGKFh++r8vJyFBcX4/z587h+/Tru37+PhoYGj/MHH1daWlpoZioUCnAc59YEbqs53F0If6+v097zVCgUCAwMRGhoKAYPHoyxY8diwoQJGDJkiDBpm4hSrAShaAGgqakJ9fX1uHfvHkwmkzD6sZlwTfY5Jfuzpqeno6ysDAAwYcIEfPDBB24Dyjub0b7iKe/6MqRLpa37VqvVCAkJQUREBJT8JtLe4Oog7Gwecrdv3+7cGdqhrZtnuLN48WIUFhYC/HBOYf81Q5x0VoC+8Oi6vwsgbyxmno1AJieDbxIT7HYb7HbngH5mvWu9TbeLleEdbRUGiURKN1t2NUbPIxRvW3nWXTCx+gm9WUgY4oCJlcHwE3yeIses+8wVYRwzZqxmZTD8BCZWBsNPYGJlMPwEJlYGw09gDiaRmBASztZiYkaM1awMhp/AxMpg+AlMrAyGn8DEymD4CczBJBJzRRjHjJmDOZgYPYXYZwwJZzU9ynoDjuOYWBldBynIwsItLODCOE9pxExvXSt38+bN1p18jB6DZPyCBQtw6tQpAMDMmTORlZUFPGKeq9jwVIBbWlrQ2NgIo9FI19uSSCSQSqXQarUICgqiy9q40pP3TK77wIEDOHDgADh+7SsSTq7F4bAjLOwpTJ06FXFxcQgICOix6+Q4DleuXGFi7W38WayeBFpVVYWffvoJpaWlqKiowO3bt9HQ0OC23pZUKkVwcDDCw8MxYsQIjBs3DpGRka32g+mJeyf3kJ6eju3bt+PJJ5+kW76Q35dIJLDZbLh16xZsNhtGjYrC1q3/g4iIiG6/RnJ9J06cwP8D/SVkf/MvcUgAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"block.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee77f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.1861, val loss 4.1870\n",
      "step 300: train loss 3.1983, val loss 3.2238\n",
      "step 600: train loss 2.9870, val loss 2.9887\n",
      "step 900: train loss 2.8336, val loss 2.8250\n",
      "step 1200: train loss 2.6731, val loss 2.6745\n",
      "step 1500: train loss 2.6141, val loss 2.6179\n",
      "step 1800: train loss 2.5490, val loss 2.5515\n",
      "step 2100: train loss 2.5044, val loss 2.5031\n",
      "step 2400: train loss 2.4693, val loss 2.4551\n",
      "step 2700: train loss 2.4359, val loss 2.4372\n",
      "step 3000: train loss 2.4136, val loss 2.4106\n",
      "step 3300: train loss 2.3984, val loss 2.3599\n",
      "step 3600: train loss 2.3691, val loss 2.3600\n",
      "step 3900: train loss 2.3453, val loss 2.3378\n",
      "step 4200: train loss 2.3516, val loss 2.3279\n",
      "step 4500: train loss 2.3178, val loss 2.3325\n",
      "step 4800: train loss 2.3053, val loss 2.3106\n",
      "\n",
      "\n",
      "IUUSNI:\n",
      "Al:\n",
      "I ring an:\n",
      "Wile e Tked ther to the iin, I Xhe dours.\n",
      "\n",
      "RAK:\n",
      "Newindely yolouw gref he thare is delt yoow my a of alen went prounetor, and how,\n",
      "Thime: erre with the ouge to canter ant,\n",
      "Thicd chol:\n",
      "Bcrals fucidet-watarelle!\n",
      "\n",
      "Bepest wendan, ind torfs lot nadsteredy fres mat rint:\n",
      "Tit kiseterlob den heed on Ifofe wailp, his lettasun is my youu frarestiund, yiy seruer ghit zisss, hou Mad an Athee your you sroun, son serany ith lusty thit,\n",
      "Sind, all agcesit widn, michep mead pive; you thit \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # perform the weightes aggregation of the values.\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultilHeadAttention(nn.Module):\n",
    "    \"\"\" mutiple heads of self attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x)for h in self.heads], dim=-1)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # This is a token level and all token will do independently.\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of head we'd like.\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultilHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sa(x)\n",
    "        x = self.ffwd(x)\n",
    "        return x\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4)\n",
    "        )\n",
    "        # self.sa_head = MultilHeadAttention(4, n_embd//4) # i.e. 4 heads od 8-dimensional self-attention.\n",
    "        # self.ffwd = FeedForward(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.blocks(x)\n",
    "        # x = self.sa_head(x) # Apply one head of self attention. (B, T, C)\n",
    "        # x = self.ffwd(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05086e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we use deep neural network they suffer from optimizations.\n",
    "# Now we need to implement one more idea from the transformer paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d8e23",
   "metadata": {},
   "source": [
    "# First - Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00ba407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now implemention is like we process the token embedding seperately from the original part and atlast adding the processed token with the original part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57a64108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.4080, val loss 4.4197\n",
      "step 300: train loss 2.5000, val loss 2.5032\n",
      "step 600: train loss 2.3689, val loss 2.3572\n",
      "step 900: train loss 2.2866, val loss 2.2987\n",
      "step 1200: train loss 2.2072, val loss 2.2334\n",
      "step 1500: train loss 2.1882, val loss 2.2282\n",
      "step 1800: train loss 2.1515, val loss 2.1881\n",
      "step 2100: train loss 2.1232, val loss 2.1660\n",
      "step 2400: train loss 2.1071, val loss 2.1642\n",
      "step 2700: train loss 2.0749, val loss 2.1444\n",
      "step 3000: train loss 2.0737, val loss 2.1130\n",
      "step 3300: train loss 2.0485, val loss 2.1193\n",
      "step 3600: train loss 2.0447, val loss 2.1051\n",
      "step 3900: train loss 2.0321, val loss 2.0878\n",
      "step 4200: train loss 2.0255, val loss 2.1049\n",
      "step 4500: train loss 1.9971, val loss 2.0939\n",
      "step 4800: train loss 1.9949, val loss 2.0961\n",
      "\n",
      "\n",
      "ISA:\n",
      "in I to or you mencell queked the you thee\n",
      "in, I rent hofuse warn. Iwing hand love ure, he to courrd'!\n",
      "\n",
      "Sousing your and now yet moother fiere how,\n",
      "To me: ereequrray be of Go'd tanter art,\n",
      "The deaus beectils fair\n",
      "Ot-yataie, and of you weld,', for to froly, nadXINCE:\n",
      "Weres!\n",
      "\n",
      "Morder:\n",
      "Thou the eret.\n",
      "\n",
      "Fir cear it.\n",
      "\n",
      "DUKING ES:\n",
      "Rumeestasuok come you bear herice, of you curre fie ou sTake hand to the fell brust sorces, son sert you holpsey't, the beartall agon it. I'n, my cop me depis arefy the b\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # perform the weightes aggregation of the values.\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultilHeadAttention(nn.Module):\n",
    "    \"\"\" mutiple heads of self attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x)for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # This is a token level and all token will do independently.\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of head we'd like.\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultilHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(x) # Fork-off and do some computation and come back.\n",
    "        x = x + self.ffwd(x) # Fork-off and do some computation and come back.\n",
    "        return x\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4)\n",
    "        )\n",
    "        # self.sa_head = MultilHeadAttention(4, n_embd//4) # i.e. 4 heads od 8-dimensional self-attention.\n",
    "        # self.ffwd = FeedForward(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.blocks(x)\n",
    "        # x = self.sa_head(x) # Apply one head of self attention. (B, T, C)\n",
    "        # x = self.ffwd(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451f4ad",
   "metadata": {},
   "source": [
    "# Second - Layer Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d7889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.2229, val loss 4.2282\n",
      "step 300: train loss 2.5314, val loss 2.5293\n",
      "step 600: train loss 2.3866, val loss 2.3682\n",
      "step 900: train loss 2.2769, val loss 2.2844\n",
      "step 1200: train loss 2.2078, val loss 2.2338\n",
      "step 1500: train loss 2.1705, val loss 2.2066\n",
      "step 1800: train loss 2.1432, val loss 2.1806\n",
      "step 2100: train loss 2.1135, val loss 2.1496\n",
      "step 2400: train loss 2.0920, val loss 2.1519\n",
      "step 2700: train loss 2.0736, val loss 2.1452\n",
      "step 3000: train loss 2.0610, val loss 2.0886\n",
      "step 3300: train loss 2.0503, val loss 2.1095\n",
      "step 3600: train loss 2.0297, val loss 2.0880\n",
      "step 3900: train loss 2.0238, val loss 2.0743\n",
      "step 4200: train loss 2.0141, val loss 2.0865\n",
      "step 4500: train loss 1.9922, val loss 2.0776\n",
      "step 4800: train loss 1.9824, val loss 2.0689\n",
      "\n",
      "\n",
      "ICKENR, I to or you men:\n",
      "Mere you for his to weit.\n",
      "\n",
      "ICKING RICHAR:\n",
      "Aret mest poy you hir tefth theare is detto you my a of all of you more to fier a dome but.\n",
      "\n",
      "GRA:\n",
      "I bay be orge to canter art,\n",
      "To Rity oldsect low, is Ot--\n",
      "Saie, and here wile have is not frolr, nayXeriedy:\n",
      "Mestal or do furd king lebok demed the is for crail more mantias o comes proveer. And and of youe bereofty zersTake hant to sAulas your you stould sonce many to tipshy to the takeladumeged it with, my lor mord pore; you dect \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32 # How many independent sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # perform the weightes aggregation of the values.\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultilHeadAttention(nn.Module):\n",
    "    \"\"\" mutiple heads of self attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x)for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # This is a token level and all token will do independently.\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of head we'd like.\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultilHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) # Fork-off and do some computation and come back.\n",
    "        x = x + self.ffwd(self.ln2(x)) # Fork-off and do some computation and come back.\n",
    "        return x\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            nn.LayerNorm(n_embd),\n",
    "        )\n",
    "        # self.sa_head = MultilHeadAttention(4, n_embd//4) # i.e. 4 heads od 8-dimensional self-attention.\n",
    "        # self.ffwd = FeedForward(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.blocks(x)\n",
    "        # x = self.sa_head(x) # Apply one head of self attention. (B, T, C)\n",
    "        # x = self.ffwd(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a59bfd",
   "metadata": {},
   "source": [
    "# Scaling up the model - first code can be executed by 4050. It takes 15 min in A100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688f5e1",
   "metadata": {},
   "source": [
    "##### A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8692d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64 # How many independent sequence will we process in parallel?\n",
    "block_size = 256 # What is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultilHeadAttention(nn.Module):\n",
    "    \"\"\" mutiple heads of self attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x)for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # This is a token level and all token will do independently.\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of head we'd like.\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultilHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) # Fork-off and do some computation and come back.\n",
    "        x = x + self.ffwd(self.ln2(x)) # Fork-off and do some computation and come back.\n",
    "        return x\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # Final layer norm.\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        x = self.ln_f(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90941a9",
   "metadata": {},
   "source": [
    "##### 4050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c4a079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.3041, val loss 4.3118\n",
      "step 500: train loss 2.2091, val loss 2.2435\n",
      "step 1000: train loss 1.8828, val loss 1.9817\n",
      "step 1500: train loss 1.7023, val loss 1.8669\n",
      "step 2000: train loss 1.6057, val loss 1.7984\n",
      "step 2500: train loss 1.5378, val loss 1.7335\n",
      "step 3000: train loss 1.4900, val loss 1.6984\n",
      "step 3500: train loss 1.4592, val loss 1.6580\n",
      "step 4000: train loss 1.4297, val loss 1.6253\n",
      "step 4500: train loss 1.4076, val loss 1.6102\n",
      "\n",
      "Thy lost allour! she big though woundsdoEd be\n",
      "Vairt'st; and blood; and worny to sweat of His hable held do\n",
      "sener: lone, ladce\n",
      "what belf arms daughter deith: when it would?\n",
      "\n",
      "This diend, this ue not that blose 'tis inhead:\n",
      "My lipperant: hrift there are theseizeldies' wassed souls\n",
      "In pastribbey agains telder'd and inhence own\n",
      "stoist sweet the heats, of I lene one the woo;\n",
      "He have have to rungone to knows, by the minstander;\n",
      "Now this too; crest thouse to your and wrong.\n",
      "\n",
      "DUKE WARD IV:\n",
      "Ne't runt and \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 256\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "# ---------------\n",
    "\n",
    "torch.manual_seed(1377)\n",
    "\n",
    "with open('tinyShakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Here are all the unique characters that occur in this text.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# Create a mapping from characters to integers.\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # Encoder: Takes a string, outputs a list of integers.\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Decoder: Takes a list of integers, outputs a string.\n",
    "\n",
    "# Train and Test splits.\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# The function we used before will calculate the loss for many batches.\n",
    "# So that is a noisy measurement of the current loss because every batch will be more or less lucky.\n",
    "\n",
    "@torch.no_grad() # This context manager will let know Pytroch that everything that happens inside this function will not call backward() function.  \n",
    "                 # So Pytorch can be lot more efficent with its memory because it doesnt want to store all the intermediate variables happening inside because we will never call backward.\n",
    "def estimate_loss(): # This function averages up the loss of multiple batches. This is a very less noisy measurement of loss.\n",
    "    out = {}  # This function will return a pretty accurate loss on train and validation loss.\n",
    "    model.eval() # Evaluation mode\n",
    "    for split in  ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # Training mode. We just use this for practice. Right now nothing is gonna change. But some layer will have different behaviour like when inference time or training time.\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "        # compute attention scores 'affinities'.\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) ---> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultilHeadAttention(nn.Module):\n",
    "    \"\"\" mutiple heads of self attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x)for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # This is a token level and all token will do independently.\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of head we'd like.\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultilHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) # Fork-off and do some computation and come back.\n",
    "        x = x + self.ffwd(self.ln2(x)) # Fork-off and do some computation and come back.\n",
    "        return x\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # vocal size means the identity of the character.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # block size means the position of the character.\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # Final layer norm.\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers.\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B, T, C) This holds not just the token identity but also the positions at which these token occur.\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        x = self.ln_f(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocal_size)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)  \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context.\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens.\n",
    "            idx_cond = idx[:, -block_size:] \n",
    "            # Get the Predictions.\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Focus only on the last time step.\n",
    "            logits = logits[:, -1, :] # Becomes (B,C).\n",
    "            # Apply softmax to obtain the proabability.\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # Sample from the distribution.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # Append sampled index to the running sequence.\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "# Create a Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4f509",
   "metadata": {},
   "source": [
    "##### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1ed58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paen:' then from wrown fray Friatorance' turne\n",
      "Be retently to Lords he uncluctured him withal speak\n",
      "And witness those cutlious mester,\n",
      "and my his bush tinefither's buster friend.\n",
      "\n",
      "GLOUCESTER:\n",
      "He near be as yonest, ittle thousat in the gattorans,\n",
      "Tell me let fledge\n",
      "Than of the both of muntty son: therefore feellock,\n",
      "This mine, veiantructions and eyes bid in it?\n",
      "We Cariol, sir, tell me with Topmen\n",
      "while with coman cused the dewardices: it I dear,\n",
      "Julant requittle comple, holly by dock that\n",
      "reart only to haurds mother,\n",
      "My privain neyI have a seny what reven.\n",
      "\n",
      "MERCUTIO:\n",
      "Trieed!\n",
      "\n",
      "First Servant:\n",
      "Let of goy. Good sire on same son.\n",
      "\n",
      "First Citizen:\n",
      "I would part he\n",
      "This nair of traitor beak. Julrest\n",
      "the comes: if this, we are, Wellcome salt thee tretchese\n",
      "it in the son't; for who the whence, thus Edward.\n",
      "\n",
      "First Senator:\n",
      "Sas brother being thou Moweeps moke him liests?\n",
      "\n",
      "NORTHUMBERLT:\n",
      "Find you, my coke name too me.\n",
      "Award we children, from me, Tutorth: yie, here antituna;\n",
      "What, sping incrance my rey\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdf45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
